{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:29:27.046489Z",
     "start_time": "2024-10-18T00:29:27.035714Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.core.common import random_state\n",
    "from pandas.core.interchange.from_dataframe import categorical_column_to_series\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from tensorflow.python.ops.gen_dataset_ops import model_dataset\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d616227abc4dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T00:37:10.645002Z",
     "start_time": "2024-10-16T00:37:10.639918Z"
    }
   },
   "outputs": [],
   "source": [
    "chunk_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "435202c9b6abac00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:26:30.449636Z",
     "start_time": "2024-09-26T20:26:30.447099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize variables for analysis\n",
    "total_rows = 0\n",
    "column_sums = None\n",
    "column_squared_sums = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "975540a43160cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:26:31.469312Z",
     "start_time": "2024-09-26T20:26:31.465683Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Read the data in chunks\n",
    "def read_csv_in_chunks(file_path, chunk_size):\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b401fcbd7ea719b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T18:34:42.985826Z",
     "start_time": "2024-09-26T18:34:42.480513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Sample 20% of observation\n",
    "labels = pd.read_csv('data/train_labels.csv')\n",
    "sample_labels = labels.sample(frac=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ade08e5e4c931082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T18:45:12.751126Z",
     "start_time": "2024-09-26T18:40:24.363556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "sampled_data = []\n",
    "for chunk in read_csv_in_chunks('data/train_data.csv', chunk_size):\n",
    "    merged_chunk = pd.merge(chunk, sample_labels, on='customer_ID', how='inner')\n",
    "    sampled_data.append(merged_chunk)\n",
    "    \n",
    "# Combine all chunks into a single dataframe\n",
    "development_sample = pd.concat(sampled_data, ignore_index=True)\n",
    "\n",
    "# Save the development sample\n",
    "development_sample.to_csv('data/development_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c917101ada60f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:01:56.955999Z",
     "start_time": "2024-09-26T20:01:35.465964Z"
    }
   },
   "outputs": [],
   "source": [
    "# load development_sample\n",
    "data = []\n",
    "for chunk in read_csv_in_chunks('data/development_sample.csv', chunk_size):\n",
    "    data.append(chunk)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1907398581b9aa5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T18:57:41.316645Z",
     "start_time": "2024-09-26T18:57:39.949939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>0.374606</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>0.044293</td>\n",
       "      <td>1.008622</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.459235</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.414269</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.059667</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>0.413310</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-06-10</td>\n",
       "      <td>0.328983</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.115654</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.416112</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>0.496989</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.419864</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.098308</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-03-11  0.374606   \n",
       "1  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-04-22  0.414269   \n",
       "2  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-05-12  0.413310   \n",
       "3  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-06-10  0.328983   \n",
       "4  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-07-19  0.496989   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
       "0  0.033519  0.044293  1.008622  0.001470  0.459235  0.002339  0.006168  ...   \n",
       "1  0.002516  0.059667  0.123964  0.004374  0.434148  0.001405  0.052130  ...   \n",
       "2  0.003285  0.053418  0.304955  0.002316  0.415906  0.009388  0.048780  ...   \n",
       "3  0.038574  0.049463  0.115654  0.004654  0.416112  0.003223  0.081001  ...   \n",
       "4  0.005552  0.041452  0.133631  0.007363  0.419864  0.003393  0.098308  ...   \n",
       "\n",
       "   D_137  D_138     D_139     D_140     D_141  D_142     D_143     D_144  \\\n",
       "0    NaN    NaN  0.008263  0.006609  0.007370    NaN  0.007171  0.005120   \n",
       "1    NaN    NaN  0.001986  0.004050  0.000796    NaN  0.001802  0.002364   \n",
       "2    NaN    NaN  0.009515  0.008757  0.009219    NaN  0.003134  0.001686   \n",
       "3    NaN    NaN  0.002524  0.007841  0.007421    NaN  0.000728  0.003591   \n",
       "4    NaN    NaN  0.003823  0.009599  0.006957    NaN  0.008746  0.007101   \n",
       "\n",
       "      D_145  target  \n",
       "0  0.007513       0  \n",
       "1  0.003987       0  \n",
       "2  0.001265       0  \n",
       "3  0.007998       0  \n",
       "4  0.006658       0  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(data, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d672127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Category  #Observations  Default rate\n",
      "0                                 All applicants          91783      0.246498\n",
      "1   Applications with 13 months of historic data          77348      0.229405\n",
      "2   Applications with 12 months of historic data           2115      0.378723\n",
      "3   Applications with 11 months of historic data           1159      0.440897\n",
      "4   Applications with 10 months of historic data           1329      0.465764\n",
      "5    Applications with 9 months of historic data           1278      0.435837\n",
      "6    Applications with 8 months of historic data           1169      0.450813\n",
      "7    Applications with 7 months of historic data           1046      0.414914\n",
      "8    Applications with 6 months of historic data           1109      0.412985\n",
      "9    Applications with 5 months of historic data            933      0.394427\n",
      "10   Applications with 4 months of historic data            938      0.430704\n",
      "11   Applications with 3 months of historic data           1158      0.357513\n",
      "12   Applications with 2 months of historic data           1217      0.312243\n",
      "13   Applications with 1 months of historic data            984      0.331301\n"
     ]
    }
   ],
   "source": [
    "def calculate_default_rate(data):\n",
    "    # Initialize a DataFrame to store the results\n",
    "    default_rates = pd.DataFrame(columns=[\"Category\", \"#Observations\", \"Default rate\"])\n",
    "    \n",
    "    # Get the total number of unique customer IDs\n",
    "    total_customers = len(data[\"customer_ID\"].unique())\n",
    "    \n",
    "    # Calculate default rate for all applicants\n",
    "    default_rate_all = data[\"target\"].mean()\n",
    "    default_rates.loc[0] = [\"All applicants\", total_customers, default_rate_all]\n",
    "    \n",
    "    # Calculate default rate for each category of historic data length\n",
    "    for months in range(13, 0, -1):  # Iterate from 13 months to 1 month\n",
    "        category_customers = data.groupby(\"customer_ID\").size() == months  # Check if each customer has data for the specific number of months\n",
    "        category_observations = category_customers.sum()  # Get the number of customers in this category\n",
    "        category_data = data[data[\"customer_ID\"].isin(category_customers[category_customers].index)]  # Filter data for the specific category\n",
    "        default_rate_category = category_data[\"target\"].mean()  # Calculate default rate for this category\n",
    "        default_rates.loc[len(default_rates)] = [f\"Applications with {months} months of historic data\", category_observations, default_rate_category]\n",
    "    \n",
    "    return default_rates\n",
    "\n",
    "# Call the function with your development_sample dataset\n",
    "default_rates_data = calculate_default_rate(development_sample)\n",
    "\n",
    "# Display the results\n",
    "print(default_rates_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "15b8f22df0c015d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:01:51.333896Z",
     "start_time": "2024-10-16T21:01:51.324472Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a756f487fcb57c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:55:02.153395Z",
     "start_time": "2024-09-27T00:54:32.732911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 7082\n",
      "One-hot encoding completed.\n",
      "Shape of encoded DataFrame: (1107082, 235)\n",
      "                                         customer_ID         S_2       P_2  \\\n",
      "0  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-03-11  0.374606   \n",
      "1  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-04-22  0.414269   \n",
      "2  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-05-12  0.413310   \n",
      "3  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-06-10  0.328983   \n",
      "4  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-07-19  0.496989   \n",
      "\n",
      "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
      "0  0.033519  0.044293  1.008622  0.001470  0.459235  0.002339  0.006168  ...   \n",
      "1  0.002516  0.059667  0.123964  0.004374  0.434148  0.001405  0.052130  ...   \n",
      "2  0.003285  0.053418  0.304955  0.002316  0.415906  0.009388  0.048780  ...   \n",
      "3  0.038574  0.049463  0.115654  0.004654  0.416112  0.003223  0.081001  ...   \n",
      "4  0.005552  0.041452  0.133631  0.007363  0.419864  0.003393  0.098308  ...   \n",
      "\n",
      "   D_66_1.0  D_66_nan  D_68_0.0  D_68_1.0  D_68_2.0  D_68_3.0  D_68_4.0  \\\n",
      "0         0         1         0         0         0         0         0   \n",
      "1         0         1         0         0         0         0         0   \n",
      "2         0         1         0         0         1         0         0   \n",
      "3         0         1         0         0         1         0         0   \n",
      "4         0         1         0         0         1         0         0   \n",
      "\n",
      "   D_68_5.0  D_68_6.0  D_68_nan  \n",
      "0         0         0         1  \n",
      "1         0         0         1  \n",
      "2         0         0         0  \n",
      "3         0         0         0  \n",
      "4         0         0         0  \n",
      "\n",
      "[5 rows x 235 columns]\n",
      "customer_ID     object\n",
      "S_2             object\n",
      "P_2            float64\n",
      "D_39           float64\n",
      "B_1            float64\n",
      "                ...   \n",
      "D_68_3.0         int64\n",
      "D_68_4.0         int64\n",
      "D_68_5.0         int64\n",
      "D_68_6.0         int64\n",
      "D_68_nan         int64\n",
      "Length: 235, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 5: One-hot encoding for categorical variables\n",
    "# List of known categorical columns\n",
    "# List of categorical columns\n",
    "\n",
    "# Function to read and process data in chunks\n",
    "def process_chunks(file_path, chunk_size=100000):\n",
    "    encoded_chunks = []\n",
    "    \n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        # Convert all specified columns to strings\n",
    "        for col in categorical_columns:\n",
    "            chunk[col] = chunk[col].astype(str)\n",
    "        \n",
    "        # Perform one-hot encoding\n",
    "        encoded_chunk = pd.get_dummies(chunk, columns=categorical_columns)\n",
    "        \n",
    "        # Ensure the encoded columns are of type int (0 or 1)\n",
    "        for col in encoded_chunk.columns:\n",
    "            if col.startswith(tuple(categorical_columns)):\n",
    "                encoded_chunk[col] = encoded_chunk[col].astype(int)\n",
    "        \n",
    "        encoded_chunks.append(encoded_chunk)\n",
    "        \n",
    "        print(f\"Processed chunk of size {len(chunk)}\")\n",
    "    \n",
    "    return pd.concat(encoded_chunks, ignore_index=True)\n",
    "\n",
    "# Process the file\n",
    "df_encoded = process_chunks('data/development_sample.csv')\n",
    "\n",
    "print(\"One-hot encoding completed.\")\n",
    "print(f\"Shape of encoded DataFrame: {df_encoded.shape}\")\n",
    "\n",
    "# Display the first few rows of the encoded DataFrame\n",
    "print(df_encoded.head())\n",
    "\n",
    "# Check the data types of the encoded columns\n",
    "print(df_encoded.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "469a5414f95c282d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T01:06:12.001677Z",
     "start_time": "2024-09-27T00:55:43.570546Z"
    }
   },
   "outputs": [],
   "source": [
    "df_encoded.to_csv('data/train_encoded_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932d32f61abc07a",
   "metadata": {},
   "source": [
    "***USE THE BELOW CODE FOR QUESTION 6~***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f44bf4fb5408634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:52:20.892343Z",
     "start_time": "2024-10-16T20:51:54.320339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Feature Engineering\n",
    "df = pd.read_csv('data/train_encoded_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbcdb1aec6587c92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:53:17.935355Z",
     "start_time": "2024-10-16T20:53:17.682827Z"
    }
   },
   "outputs": [],
   "source": [
    "target_df = df[['customer_ID', 'target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "536ff412600491ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:53:36.334535Z",
     "start_time": "2024-10-16T20:53:36.329295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e2ad17f4f50b6e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:54:04.426397Z",
     "start_time": "2024-10-16T20:54:02.525589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1.0</th>\n",
       "      <th>D_66_nan</th>\n",
       "      <th>D_68_0.0</th>\n",
       "      <th>D_68_1.0</th>\n",
       "      <th>D_68_2.0</th>\n",
       "      <th>D_68_3.0</th>\n",
       "      <th>D_68_4.0</th>\n",
       "      <th>D_68_5.0</th>\n",
       "      <th>D_68_6.0</th>\n",
       "      <th>D_68_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>0.374606</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>0.044293</td>\n",
       "      <td>1.008622</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.459235</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.414269</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.059667</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>0.413310</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-06-10</td>\n",
       "      <td>0.328983</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.115654</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.416112</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>0.496989</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.419864</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.098308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID        S_2       P_2  \\\n",
       "0  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-03-11  0.374606   \n",
       "1  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-04-22  0.414269   \n",
       "2  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-05-12  0.413310   \n",
       "3  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-06-10  0.328983   \n",
       "4  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-07-19  0.496989   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
       "0  0.033519  0.044293  1.008622  0.001470  0.459235  0.002339  0.006168  ...   \n",
       "1  0.002516  0.059667  0.123964  0.004374  0.434148  0.001405  0.052130  ...   \n",
       "2  0.003285  0.053418  0.304955  0.002316  0.415906  0.009388  0.048780  ...   \n",
       "3  0.038574  0.049463  0.115654  0.004654  0.416112  0.003223  0.081001  ...   \n",
       "4  0.005552  0.041452  0.133631  0.007363  0.419864  0.003393  0.098308  ...   \n",
       "\n",
       "   D_66_1.0  D_66_nan  D_68_0.0  D_68_1.0  D_68_2.0  D_68_3.0  D_68_4.0  \\\n",
       "0         0         1         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         1         0         0         1         0         0   \n",
       "3         0         1         0         0         1         0         0   \n",
       "4         0         1         0         0         1         0         0   \n",
       "\n",
       "   D_68_5.0  D_68_6.0  D_68_nan  \n",
       "0         0         0         1  \n",
       "1         0         0         1  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['S_2'] = pd.to_datetime(df['S_2'])\n",
    "df = df.drop(columns=['target'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14fd115f80b05bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:54:07.969320Z",
     "start_time": "2024-10-16T20:54:06.780068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Numerical Columns:\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebdf49e0a42531ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:54:10.634636Z",
     "start_time": "2024-10-16T20:54:09.277219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1.0</th>\n",
       "      <th>D_66_nan</th>\n",
       "      <th>D_68_0.0</th>\n",
       "      <th>D_68_1.0</th>\n",
       "      <th>D_68_2.0</th>\n",
       "      <th>D_68_3.0</th>\n",
       "      <th>D_68_4.0</th>\n",
       "      <th>D_68_5.0</th>\n",
       "      <th>D_68_6.0</th>\n",
       "      <th>D_68_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374606</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>0.044293</td>\n",
       "      <td>1.008622</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.459235</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.152932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.414269</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.059667</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.154147</td>\n",
       "      <td>0.053474</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413310</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.150513</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328983</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.115654</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.416112</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.148605</td>\n",
       "      <td>0.166655</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.496989</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.419864</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.098308</td>\n",
       "      <td>0.147616</td>\n",
       "      <td>0.117810</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        P_2      D_39       B_1       B_2       R_1       S_3      D_41  \\\n",
       "0  0.374606  0.033519  0.044293  1.008622  0.001470  0.459235  0.002339   \n",
       "1  0.414269  0.002516  0.059667  0.123964  0.004374  0.434148  0.001405   \n",
       "2  0.413310  0.003285  0.053418  0.304955  0.002316  0.415906  0.009388   \n",
       "3  0.328983  0.038574  0.049463  0.115654  0.004654  0.416112  0.003223   \n",
       "4  0.496989  0.005552  0.041452  0.133631  0.007363  0.419864  0.003393   \n",
       "\n",
       "        B_3      D_42      D_43  ...  D_66_1.0  D_66_nan  D_68_0.0  D_68_1.0  \\\n",
       "0  0.006168  0.152932       NaN  ...         0         1         0         0   \n",
       "1  0.052130  0.154147  0.053474  ...         0         1         0         0   \n",
       "2  0.048780  0.150513  0.035667  ...         0         1         0         0   \n",
       "3  0.081001  0.148605  0.166655  ...         0         1         0         0   \n",
       "4  0.098308  0.147616  0.117810  ...         0         1         0         0   \n",
       "\n",
       "   D_68_2.0  D_68_3.0  D_68_4.0  D_68_5.0  D_68_6.0  D_68_nan  \n",
       "0         0         0         0         0         0         1  \n",
       "1         0         0         0         0         0         1  \n",
       "2         1         0         0         0         0         0  \n",
       "3         1         0         0         0         0         0  \n",
       "4         1         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cd5165ccd9c4a6b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:02:20.408427Z",
     "start_time": "2024-10-16T21:02:13.215057Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m average_spend_last_time_period\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Calculate statistics for different time periods\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m average_spend_3_months \u001b[38;5;241m=\u001b[39m calculate_numerical_statistics(df, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     17\u001b[0m average_spend_6_months \u001b[38;5;241m=\u001b[39m calculate_numerical_statistics(df, \u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m     18\u001b[0m average_spend_9_months \u001b[38;5;241m=\u001b[39m calculate_numerical_statistics(df, \u001b[38;5;241m9\u001b[39m)\n",
      "Cell \u001b[0;32mIn[49], line 9\u001b[0m, in \u001b[0;36mcalculate_numerical_statistics\u001b[0;34m(df, time_period)\u001b[0m\n\u001b[1;32m      5\u001b[0m time_period_ago \u001b[38;5;241m=\u001b[39m last_date \u001b[38;5;241m-\u001b[39m pd\u001b[38;5;241m.\u001b[39mDateOffset(months\u001b[38;5;241m=\u001b[39mtime_period)\n\u001b[1;32m      7\u001b[0m data_last_time_period \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m time_period_ago) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mS_2\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m last_date)]\n\u001b[0;32m----> 9\u001b[0m average_spend_last_time_period \u001b[38;5;241m=\u001b[39m data_last_time_period\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcustomer_ID\u001b[39m\u001b[38;5;124m'\u001b[39m)[numerical_columns]\u001b[38;5;241m.\u001b[39magg([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m average_spend_last_time_period\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime_period\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m col, agg \u001b[38;5;129;01min\u001b[39;00m average_spend_last_time_period\u001b[38;5;241m.\u001b[39mcolumns]\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m average_spend_last_time_period\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:1432\u001b[0m, in \u001b[0;36mDataFrameGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1429\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[1;32m   1431\u001b[0m op \u001b[38;5;241m=\u001b[39m GroupByApply(\u001b[38;5;28mself\u001b[39m, func, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m-> 1432\u001b[0m result \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39magg()\n\u001b[1;32m   1433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dict_like(func) \u001b[38;5;129;01mand\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1434\u001b[0m     \u001b[38;5;66;03m# GH #52849\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mas_index \u001b[38;5;129;01mand\u001b[39;00m is_list_like(func):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:193\u001b[0m, in \u001b[0;36mApply.agg\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_dict_like()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(func):\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;66;03m# we require a list, but not a 'str'\u001b[39;00m\n\u001b[0;32m--> 193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_list_like()\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(func):\n\u001b[1;32m    196\u001b[0m     f \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mget_cython_func(func)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:326\u001b[0m, in \u001b[0;36mApply.agg_list_like\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magg_list_like\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    319\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    Compute aggregation in the case of a list-like argument.\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    Result of aggregation.\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magg_or_apply_list_like(op_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:1571\u001b[0m, in \u001b[0;36mGroupByApply.agg_or_apply_list_like\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;66;03m# Only set as_index=True on groupby objects, not Window or Resample\u001b[39;00m\n\u001b[1;32m   1567\u001b[0m \u001b[38;5;66;03m# that inherit from this class.\u001b[39;00m\n\u001b[1;32m   1568\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m com\u001b[38;5;241m.\u001b[39mtemp_setattr(\n\u001b[1;32m   1569\u001b[0m     obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m, condition\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mhasattr\u001b[39m(obj, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas_index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1570\u001b[0m ):\n\u001b[0;32m-> 1571\u001b[0m     keys, results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_list_like(op_name, selected_obj, kwargs)\n\u001b[1;32m   1572\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrap_results_list_like(keys, results)\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:385\u001b[0m, in \u001b[0;36mApply.compute_list_like\u001b[0;34m(self, op_name, selected_obj, kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m colg \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_gotitem(col, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, subset\u001b[38;5;241m=\u001b[39mselected_obj\u001b[38;5;241m.\u001b[39miloc[:, index])\n\u001b[1;32m    380\u001b[0m args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    381\u001b[0m     [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs]\n\u001b[1;32m    382\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m include_axis(op_name, colg)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\n\u001b[1;32m    384\u001b[0m )\n\u001b[0;32m--> 385\u001b[0m new_res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(colg, op_name)(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    386\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(new_res)\n\u001b[1;32m    387\u001b[0m indices\u001b[38;5;241m.\u001b[39mappend(index)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:257\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m    256\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m--> 257\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_aggregate_multiple_funcs(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m relabeling:\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# columns is not narrowed by mypy from relabeling flag\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:362\u001b[0m, in \u001b[0;36mSeriesGroupBy._aggregate_multiple_funcs\u001b[0;34m(self, arg, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx, (name, func) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arg):\n\u001b[1;32m    361\u001b[0m         key \u001b[38;5;241m=\u001b[39m base\u001b[38;5;241m.\u001b[39mOutputKey(label\u001b[38;5;241m=\u001b[39mname, position\u001b[38;5;241m=\u001b[39midx)\n\u001b[0;32m--> 362\u001b[0m         results[key] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, DataFrame) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    365\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/generic.py:249\u001b[0m, in \u001b[0;36mSeriesGroupBy.aggregate\u001b[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m engine_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    248\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mengine_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m engine_kwargs\n\u001b[0;32m--> 249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, func)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, abc\u001b[38;5;241m.\u001b[39mIterable):\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# Catch instances of lists / tuples\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# but not the class list / tuple itself.\u001b[39;00m\n\u001b[1;32m    254\u001b[0m     func \u001b[38;5;241m=\u001b[39m maybe_mangle_lambdas(func)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:3262\u001b[0m, in \u001b[0;36mGroupBy.min\u001b[0;34m(self, numeric_only, min_count, engine, engine_kwargs)\u001b[0m\n\u001b[1;32m   3254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_agg_general(\n\u001b[1;32m   3255\u001b[0m         grouped_min_max,\n\u001b[1;32m   3256\u001b[0m         executor\u001b[38;5;241m.\u001b[39midentity_dtype_mapping,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3259\u001b[0m         is_max\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   3260\u001b[0m     )\n\u001b[1;32m   3261\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_general(\n\u001b[1;32m   3263\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   3264\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   3265\u001b[0m         alias\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3266\u001b[0m         npfunc\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmin,\n\u001b[1;32m   3267\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1906\u001b[0m, in \u001b[0;36mGroupBy._agg_general\u001b[0;34m(self, numeric_only, min_count, alias, npfunc, **kwargs)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   1897\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_agg_general\u001b[39m(\n\u001b[1;32m   1898\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1904\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1905\u001b[0m ):\n\u001b[0;32m-> 1906\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_agg_general(\n\u001b[1;32m   1907\u001b[0m         how\u001b[38;5;241m=\u001b[39malias,\n\u001b[1;32m   1908\u001b[0m         alt\u001b[38;5;241m=\u001b[39mnpfunc,\n\u001b[1;32m   1909\u001b[0m         numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m   1910\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   1911\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1912\u001b[0m     )\n\u001b[1;32m   1913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroupby\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1998\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general\u001b[0;34m(self, how, alt, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m   1995\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agg_py_fallback(how, values, ndim\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim, alt\u001b[38;5;241m=\u001b[39malt)\n\u001b[1;32m   1996\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1998\u001b[0m new_mgr \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgrouped_reduce(array_func)\n\u001b[1;32m   1999\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_agged_manager(new_mgr)\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/internals/base.py:367\u001b[0m, in \u001b[0;36mSingleDataManager.grouped_reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrouped_reduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[1;32m    366\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\n\u001b[0;32m--> 367\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(arr)\n\u001b[1;32m    368\u001b[0m     index \u001b[38;5;241m=\u001b[39m default_index(\u001b[38;5;28mlen\u001b[39m(res))\n\u001b[1;32m    370\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_array(res, index)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/groupby.py:1973\u001b[0m, in \u001b[0;36mGroupBy._cython_agg_general.<locals>.array_func\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1971\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21marray_func\u001b[39m(values: ArrayLike) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   1972\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1973\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grouper\u001b[38;5;241m.\u001b[39m_cython_operation(\n\u001b[1;32m   1974\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1975\u001b[0m             values,\n\u001b[1;32m   1976\u001b[0m             how,\n\u001b[1;32m   1977\u001b[0m             axis\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1978\u001b[0m             min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m   1979\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1980\u001b[0m         )\n\u001b[1;32m   1981\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m   1982\u001b[0m         \u001b[38;5;66;03m# generally if we have numeric_only=False\u001b[39;00m\n\u001b[1;32m   1983\u001b[0m         \u001b[38;5;66;03m# and non-applicable functions\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m         \u001b[38;5;66;03m# try to python agg\u001b[39;00m\n\u001b[1;32m   1985\u001b[0m         \u001b[38;5;66;03m# TODO: shouldn't min_count matter?\u001b[39;00m\n\u001b[1;32m   1986\u001b[0m         \u001b[38;5;66;03m# TODO: avoid special casing SparseArray here\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124many\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, SparseArray):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/ops.py:831\u001b[0m, in \u001b[0;36mBaseGrouper._cython_operation\u001b[0;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[1;32m    829\u001b[0m ids, _, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroup_info\n\u001b[1;32m    830\u001b[0m ngroups \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mngroups\n\u001b[0;32m--> 831\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cy_op\u001b[38;5;241m.\u001b[39mcython_operation(\n\u001b[1;32m    832\u001b[0m     values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    833\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    834\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m    835\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mids,\n\u001b[1;32m    836\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[1;32m    837\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    838\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/ops.py:550\u001b[0m, in \u001b[0;36mWrappedCythonOp.cython_operation\u001b[0;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_groupby_op(\n\u001b[1;32m    542\u001b[0m         how\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow,\n\u001b[1;32m    543\u001b[0m         has_dropped_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_dropped_na,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cython_op_ndim_compat(\n\u001b[1;32m    551\u001b[0m     values,\n\u001b[1;32m    552\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m    553\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[1;32m    554\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[1;32m    555\u001b[0m     mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    557\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/ops.py:329\u001b[0m, in \u001b[0;36mWrappedCythonOp._cython_op_ndim_compat\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    328\u001b[0m     result_mask \u001b[38;5;241m=\u001b[39m result_mask[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[0;32m--> 329\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_cython_op(\n\u001b[1;32m    330\u001b[0m     values2d,\n\u001b[1;32m    331\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m    332\u001b[0m     ngroups\u001b[38;5;241m=\u001b[39mngroups,\n\u001b[1;32m    333\u001b[0m     comp_ids\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[1;32m    334\u001b[0m     mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    335\u001b[0m     result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    337\u001b[0m )\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/groupby/ops.py:418\u001b[0m, in \u001b[0;36mWrappedCythonOp._call_cython_op\u001b[0;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[1;32m    407\u001b[0m counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(ngroups, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmin\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    410\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124midxmax\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    417\u001b[0m ]:\n\u001b[0;32m--> 418\u001b[0m     func(\n\u001b[1;32m    419\u001b[0m         out\u001b[38;5;241m=\u001b[39mresult,\n\u001b[1;32m    420\u001b[0m         counts\u001b[38;5;241m=\u001b[39mcounts,\n\u001b[1;32m    421\u001b[0m         values\u001b[38;5;241m=\u001b[39mvalues,\n\u001b[1;32m    422\u001b[0m         labels\u001b[38;5;241m=\u001b[39mcomp_ids,\n\u001b[1;32m    423\u001b[0m         min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m    424\u001b[0m         mask\u001b[38;5;241m=\u001b[39mmask,\n\u001b[1;32m    425\u001b[0m         result_mask\u001b[38;5;241m=\u001b[39mresult_mask,\n\u001b[1;32m    426\u001b[0m         is_datetimelike\u001b[38;5;241m=\u001b[39mis_datetimelike,\n\u001b[1;32m    427\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    428\u001b[0m     )\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvar\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mohlc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprod\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhow \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msem\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Aggregation For all the numerical columns\n",
    "\n",
    "def calculate_numerical_statistics(df, time_period):\n",
    "    last_date = df['S_2'].max()\n",
    "    time_period_ago = last_date - pd.DateOffset(months=time_period)\n",
    "\n",
    "    data_last_time_period = df[(df['S_2'] > time_period_ago) & (df['S_2'] <= last_date)]\n",
    "\n",
    "    average_spend_last_time_period = data_last_time_period.groupby('customer_ID')[numerical_columns].agg(['mean', 'min', 'max', 'sum'])\n",
    "    average_spend_last_time_period.columns = [f'{col}_{agg}_{time_period}' for col, agg in average_spend_last_time_period.columns]\n",
    "\n",
    "    return average_spend_last_time_period\n",
    "\n",
    "\n",
    "# Calculate statistics for different time periods\n",
    "average_spend_3_months = calculate_numerical_statistics(df, 3)\n",
    "average_spend_6_months = calculate_numerical_statistics(df, 6)\n",
    "average_spend_9_months = calculate_numerical_statistics(df, 9)\n",
    "average_spend_12_months = calculate_numerical_statistics(df, 12)\n",
    "\n",
    "feature_engineered_df = pd.merge(average_spend_3_months, average_spend_6_months, on='customer_ID', how='inner')\n",
    "feature_engineered_df = pd.merge(feature_engineered_df, average_spend_9_months, on='customer_ID', how='inner')\n",
    "feature_engineered_df = pd.merge(feature_engineered_df, average_spend_12_months, on='customer_ID', how='inner')\n",
    "\n",
    "feature_engineered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "675130b07df2c37a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:01:22.447137Z",
     "start_time": "2024-10-16T20:56:20.272485Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_engineered_df.to_csv('data/feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "60b9d40a8b17755c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:02:24.150129Z",
     "start_time": "2024-10-16T21:02:24.146232Z"
    }
   },
   "outputs": [],
   "source": [
    "# Categorical Columns:\n",
    "one_hot_encoded_col = []\n",
    "for ftr in df.columns:\n",
    "    for column in categorical_columns:\n",
    "        if ftr.startswith(column):\n",
    "            one_hot_encoded_col.append(ftr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0daef8b550b1786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:02:36.109782Z",
     "start_time": "2024-10-16T21:02:27.212500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_30_0.0_response_rate_3</th>\n",
       "      <th>B_30_1.0_response_rate_3</th>\n",
       "      <th>B_30_2.0_response_rate_3</th>\n",
       "      <th>B_30_nan_response_rate_3</th>\n",
       "      <th>B_38_1.0_response_rate_3</th>\n",
       "      <th>B_38_2.0_response_rate_3</th>\n",
       "      <th>B_38_3.0_response_rate_3</th>\n",
       "      <th>B_38_4.0_response_rate_3</th>\n",
       "      <th>B_38_5.0_response_rate_3</th>\n",
       "      <th>B_38_6.0_response_rate_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1.0_ever_respond_12</th>\n",
       "      <th>D_66_nan_ever_respond_12</th>\n",
       "      <th>D_68_0.0_ever_respond_12</th>\n",
       "      <th>D_68_1.0_ever_respond_12</th>\n",
       "      <th>D_68_2.0_ever_respond_12</th>\n",
       "      <th>D_68_3.0_ever_respond_12</th>\n",
       "      <th>D_68_4.0_ever_respond_12</th>\n",
       "      <th>D_68_5.0_ever_respond_12</th>\n",
       "      <th>D_68_6.0_ever_respond_12</th>\n",
       "      <th>D_68_nan_ever_respond_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f5235f98b0f47c9d7d8d4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000445609ff2a39d2dd02484899affa5696210a95f6869f26390bd26eeb3b651</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004837f0c785928a29a6f83f70f4a1c54caec483a773ff4b5b317ac251abda0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704029f989240c733b6d0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00050d84c6d26e26cd2b18c3eed83d3130c270e2361470ff272f9409103d067f</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 440 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    B_30_0.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                  0.666667   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                  1.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                  0.666667   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                  1.000000   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                  1.000000   \n",
       "\n",
       "                                                    B_30_1.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                  0.333333   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                  0.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                  0.333333   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                  0.000000   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                  0.000000   \n",
       "\n",
       "                                                    B_30_2.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    B_30_nan_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    B_38_1.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       1.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    B_38_2.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       1.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       1.0   \n",
       "\n",
       "                                                    B_38_3.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                  0.333333   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                  0.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                  0.000000   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                  0.000000   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                  0.000000   \n",
       "\n",
       "                                                    B_38_4.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    B_38_5.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                  0.666667   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                  0.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                  0.000000   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                  0.000000   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                  0.000000   \n",
       "\n",
       "                                                    B_38_6.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    ...  \\\n",
       "customer_ID                                         ...   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...  ...   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...  ...   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...  ...   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...  ...   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...  ...   \n",
       "\n",
       "                                                    D_66_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_66_nan_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_0.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_2.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_3.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_4.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_5.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_6.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_nan_ever_respond_12  \n",
       "customer_ID                                                                   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1  \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0  \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0  \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0  \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0  \n",
       "\n",
       "[5 rows x 440 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering for categorical values \n",
    "def calculate_categorical_statistics(df, time_period, one_hot_encoded_cols):\n",
    "    # Get the last date in the dataset\n",
    "    last_date = df['S_2'].max()\n",
    "    \n",
    "    # Calculate the date for the start of the time period\n",
    "    time_period_start = last_date - pd.DateOffset(months=time_period)\n",
    "    \n",
    "    # Filter the data for the specified time period\n",
    "    data_last_time_period = df[(df['S_2'] > time_period_start) & (df['S_2'] <= last_date)]\n",
    "    \n",
    "    # Calculate the positive response rates for each customer\n",
    "    positive_response_rates = data_last_time_period.groupby('customer_ID')[one_hot_encoded_cols].mean()\n",
    "    positive_response_rates.columns = [f'{col}_response_rate_{time_period}' for col in positive_response_rates.columns]\n",
    "    \n",
    "    # Calculate whether each customer ever responded positively\n",
    "    ever_responded = data_last_time_period.groupby('customer_ID')[one_hot_encoded_cols].any().astype(int)\n",
    "    ever_responded.columns = [f'{col}_ever_respond_{time_period}' for col in ever_responded.columns]\n",
    "    \n",
    "    # Merge the two DataFrames on 'customer_ID'\n",
    "    merged_df = pd.merge(positive_response_rates, ever_responded, on='customer_ID', how='inner')\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "cat_stats_3_months = calculate_categorical_statistics(df, 3, one_hot_encoded_col)\n",
    "cat_stats_6_months = calculate_categorical_statistics(df, 6, one_hot_encoded_col)\n",
    "cat_stats_9_months = calculate_categorical_statistics(df, 9, one_hot_encoded_col)\n",
    "cat_stats_12_months = calculate_categorical_statistics(df, 12, one_hot_encoded_col)\n",
    "\n",
    "final_categorical_df = pd.merge(cat_stats_3_months, cat_stats_6_months, on='customer_ID', how='inner')\n",
    "final_categorical_df = pd.merge(final_categorical_df, cat_stats_9_months, on='customer_ID', how='inner')\n",
    "final_feature_engineered_df = pd.merge(final_categorical_df, cat_stats_12_months, on='customer_ID', how='inner')\n",
    "\n",
    "final_feature_engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "539b6e96f5df1421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:04:13.542705Z",
     "start_time": "2024-10-16T21:03:57.999613Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_mean_3</th>\n",
       "      <th>P_2_min_3</th>\n",
       "      <th>P_2_max_3</th>\n",
       "      <th>P_2_sum_3</th>\n",
       "      <th>D_39_mean_3</th>\n",
       "      <th>D_39_min_3</th>\n",
       "      <th>D_39_max_3</th>\n",
       "      <th>D_39_sum_3</th>\n",
       "      <th>B_1_mean_3</th>\n",
       "      <th>B_1_min_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1.0_ever_respond_12</th>\n",
       "      <th>D_66_nan_ever_respond_12</th>\n",
       "      <th>D_68_0.0_ever_respond_12</th>\n",
       "      <th>D_68_1.0_ever_respond_12</th>\n",
       "      <th>D_68_2.0_ever_respond_12</th>\n",
       "      <th>D_68_3.0_ever_respond_12</th>\n",
       "      <th>D_68_4.0_ever_respond_12</th>\n",
       "      <th>D_68_5.0_ever_respond_12</th>\n",
       "      <th>D_68_6.0_ever_respond_12</th>\n",
       "      <th>D_68_nan_ever_respond_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f5235f98b0f47c9d7d8d4</th>\n",
       "      <td>0.447801</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.477116</td>\n",
       "      <td>1.343404</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000445609ff2a39d2dd02484899affa5696210a95f6869f26390bd26eeb3b651</th>\n",
       "      <td>0.976846</td>\n",
       "      <td>0.974383</td>\n",
       "      <td>0.978897</td>\n",
       "      <td>2.930539</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004837f0c785928a29a6f83f70f4a1c54caec483a773ff4b5b317ac251abda0</th>\n",
       "      <td>0.638958</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.642295</td>\n",
       "      <td>1.916874</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.415254</td>\n",
       "      <td>0.685210</td>\n",
       "      <td>1.724002</td>\n",
       "      <td>0.431032</td>\n",
       "      <td>0.429032</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704029f989240c733b6d0</th>\n",
       "      <td>0.973429</td>\n",
       "      <td>0.963991</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>2.920287</td>\n",
       "      <td>0.268469</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00050d84c6d26e26cd2b18c3eed83d3130c270e2361470ff272f9409103d067f</th>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>1.006598</td>\n",
       "      <td>2.980056</td>\n",
       "      <td>0.092158</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.150871</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    P_2_mean_3  P_2_min_3  \\\n",
       "customer_ID                                                                 \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.447801   0.414444   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.976846   0.974383   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.638958   0.634894   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.973429   0.963991   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.993352   0.968914   \n",
       "\n",
       "                                                    P_2_max_3  P_2_sum_3  \\\n",
       "customer_ID                                                                \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...   0.477116   1.343404   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...   0.978897   2.930539   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...   0.642295   1.916874   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...   0.980221   2.920287   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...   1.006598   2.980056   \n",
       "\n",
       "                                                    D_39_mean_3  D_39_min_3  \\\n",
       "customer_ID                                                                   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...     0.014288    0.000467   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...     0.002024    0.001221   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...     0.574667    0.415254   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...     0.268469    0.009431   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...     0.092158    0.005624   \n",
       "\n",
       "                                                    D_39_max_3  D_39_sum_3  \\\n",
       "customer_ID                                                                  \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.035885    0.042865   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.002629    0.006072   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.685210    1.724002   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.470704    0.805407   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.150871    0.276473   \n",
       "\n",
       "                                                    B_1_mean_3  B_1_min_3  \\\n",
       "customer_ID                                                                 \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.069795   0.009413   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.008831   0.006584   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.431032   0.429032   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.023506   0.019392   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.040335   0.026597   \n",
       "\n",
       "                                                    ...  \\\n",
       "customer_ID                                         ...   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...  ...   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...  ...   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...  ...   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...  ...   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...  ...   \n",
       "\n",
       "                                                    D_66_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_66_nan_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_0.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_2.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_3.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_4.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_5.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_6.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_nan_ever_respond_12  \n",
       "customer_ID                                                                   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1  \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0  \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0  \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0  \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0  \n",
       "\n",
       "[5 rows x 4152 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integrate feature engineered data\n",
    "feature_engineered_df = pd.merge(feature_engineered_df, final_feature_engineered_df, on='customer_ID', how='inner')\n",
    "feature_engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b549347c347c3945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T05:53:10.177943Z",
     "start_time": "2024-10-16T05:52:55.362331Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m feature_engineered_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/feature_engineered_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1919\u001b[0m     (\n\u001b[1;32m   1920\u001b[0m         index,\n\u001b[1;32m   1921\u001b[0m         columns,\n\u001b[1;32m   1922\u001b[0m         col_dict,\n\u001b[0;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mread(  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m         nrows\n\u001b[1;32m   1925\u001b[0m     )\n\u001b[1;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32mparsers.pyx:838\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:921\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:1083\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mparsers.pyx:1456\u001b[0m, in \u001b[0;36mpandas._libs.parsers._maybe_upcast\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/numpy/core/multiarray.py:1131\u001b[0m, in \u001b[0;36mputmask\u001b[0;34m(a, mask, values)\u001b[0m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124;03m    copyto(dst, src, casting='same_kind', where=True)\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (dst, src, where)\n\u001b[0;32m-> 1131\u001b[0m \u001b[38;5;129m@array_function_from_c_func_and_dispatcher\u001b[39m(_multiarray_umath\u001b[38;5;241m.\u001b[39mputmask)\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mputmask\u001b[39m(a, \u001b[38;5;241m/\u001b[39m, mask, values):\n\u001b[1;32m   1133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m \u001b[38;5;124;03m    putmask(a, mask, values)\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, mask, values)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feature_engineered_df = pd.read_csv('data/feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da790f45f933cf02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:05:37.778667Z",
     "start_time": "2024-10-16T21:05:37.758957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_mean_3</th>\n",
       "      <th>P_2_min_3</th>\n",
       "      <th>P_2_max_3</th>\n",
       "      <th>P_2_sum_3</th>\n",
       "      <th>D_39_mean_3</th>\n",
       "      <th>D_39_min_3</th>\n",
       "      <th>D_39_max_3</th>\n",
       "      <th>D_39_sum_3</th>\n",
       "      <th>B_1_mean_3</th>\n",
       "      <th>B_1_min_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1.0_ever_respond_12</th>\n",
       "      <th>D_66_nan_ever_respond_12</th>\n",
       "      <th>D_68_0.0_ever_respond_12</th>\n",
       "      <th>D_68_1.0_ever_respond_12</th>\n",
       "      <th>D_68_2.0_ever_respond_12</th>\n",
       "      <th>D_68_3.0_ever_respond_12</th>\n",
       "      <th>D_68_4.0_ever_respond_12</th>\n",
       "      <th>D_68_5.0_ever_respond_12</th>\n",
       "      <th>D_68_6.0_ever_respond_12</th>\n",
       "      <th>D_68_nan_ever_respond_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f5235f98b0f47c9d7d8d4</th>\n",
       "      <td>0.447801</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.477116</td>\n",
       "      <td>1.343404</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000445609ff2a39d2dd02484899affa5696210a95f6869f26390bd26eeb3b651</th>\n",
       "      <td>0.976846</td>\n",
       "      <td>0.974383</td>\n",
       "      <td>0.978897</td>\n",
       "      <td>2.930539</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004837f0c785928a29a6f83f70f4a1c54caec483a773ff4b5b317ac251abda0</th>\n",
       "      <td>0.638958</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.642295</td>\n",
       "      <td>1.916874</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.415254</td>\n",
       "      <td>0.685210</td>\n",
       "      <td>1.724002</td>\n",
       "      <td>0.431032</td>\n",
       "      <td>0.429032</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704029f989240c733b6d0</th>\n",
       "      <td>0.973429</td>\n",
       "      <td>0.963991</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>2.920287</td>\n",
       "      <td>0.268469</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00050d84c6d26e26cd2b18c3eed83d3130c270e2361470ff272f9409103d067f</th>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>1.006598</td>\n",
       "      <td>2.980056</td>\n",
       "      <td>0.092158</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.150871</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    P_2_mean_3  P_2_min_3  \\\n",
       "customer_ID                                                                 \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.447801   0.414444   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.976846   0.974383   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.638958   0.634894   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.973429   0.963991   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.993352   0.968914   \n",
       "\n",
       "                                                    P_2_max_3  P_2_sum_3  \\\n",
       "customer_ID                                                                \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...   0.477116   1.343404   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...   0.978897   2.930539   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...   0.642295   1.916874   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...   0.980221   2.920287   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...   1.006598   2.980056   \n",
       "\n",
       "                                                    D_39_mean_3  D_39_min_3  \\\n",
       "customer_ID                                                                   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...     0.014288    0.000467   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...     0.002024    0.001221   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...     0.574667    0.415254   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...     0.268469    0.009431   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...     0.092158    0.005624   \n",
       "\n",
       "                                                    D_39_max_3  D_39_sum_3  \\\n",
       "customer_ID                                                                  \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.035885    0.042865   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.002629    0.006072   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.685210    1.724002   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.470704    0.805407   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.150871    0.276473   \n",
       "\n",
       "                                                    B_1_mean_3  B_1_min_3  \\\n",
       "customer_ID                                                                 \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.069795   0.009413   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.008831   0.006584   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.431032   0.429032   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.023506   0.019392   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.040335   0.026597   \n",
       "\n",
       "                                                    ...  \\\n",
       "customer_ID                                         ...   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...  ...   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...  ...   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...  ...   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...  ...   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...  ...   \n",
       "\n",
       "                                                    D_66_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_66_nan_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_0.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_2.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_3.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_4.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_5.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_6.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_nan_ever_respond_12  \n",
       "customer_ID                                                                   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1  \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0  \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0  \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0  \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0  \n",
       "\n",
       "[5 rows x 4152 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9c745f813326df69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:06:42.209102Z",
     "start_time": "2024-10-16T21:06:29.087843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean_3</th>\n",
       "      <th>P_2_min_3</th>\n",
       "      <th>P_2_max_3</th>\n",
       "      <th>P_2_sum_3</th>\n",
       "      <th>D_39_mean_3</th>\n",
       "      <th>D_39_min_3</th>\n",
       "      <th>D_39_max_3</th>\n",
       "      <th>D_39_sum_3</th>\n",
       "      <th>B_1_mean_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_nan_ever_respond_12</th>\n",
       "      <th>D_68_0.0_ever_respond_12</th>\n",
       "      <th>D_68_1.0_ever_respond_12</th>\n",
       "      <th>D_68_2.0_ever_respond_12</th>\n",
       "      <th>D_68_3.0_ever_respond_12</th>\n",
       "      <th>D_68_4.0_ever_respond_12</th>\n",
       "      <th>D_68_5.0_ever_respond_12</th>\n",
       "      <th>D_68_6.0_ever_respond_12</th>\n",
       "      <th>D_68_nan_ever_respond_12</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>0.447801</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.477116</td>\n",
       "      <td>1.343404</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000445609ff2a39d2dd02484899affa5696210a95f6869...</td>\n",
       "      <td>0.976846</td>\n",
       "      <td>0.974383</td>\n",
       "      <td>0.978897</td>\n",
       "      <td>2.930539</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004837f0c785928a29a6f83f70f4a1c54caec483a773f...</td>\n",
       "      <td>0.638958</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.642295</td>\n",
       "      <td>1.916874</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.415254</td>\n",
       "      <td>0.685210</td>\n",
       "      <td>1.724002</td>\n",
       "      <td>0.431032</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704...</td>\n",
       "      <td>0.973429</td>\n",
       "      <td>0.963991</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>2.920287</td>\n",
       "      <td>0.268469</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00050d84c6d26e26cd2b18c3eed83d3130c270e2361470...</td>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>1.006598</td>\n",
       "      <td>2.980056</td>\n",
       "      <td>0.092158</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.150871</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean_3  P_2_min_3  \\\n",
       "0  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...    0.447801   0.414444   \n",
       "1  000445609ff2a39d2dd02484899affa5696210a95f6869...    0.976846   0.974383   \n",
       "2  0004837f0c785928a29a6f83f70f4a1c54caec483a773f...    0.638958   0.634894   \n",
       "3  0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704...    0.973429   0.963991   \n",
       "4  00050d84c6d26e26cd2b18c3eed83d3130c270e2361470...    0.993352   0.968914   \n",
       "\n",
       "   P_2_max_3  P_2_sum_3  D_39_mean_3  D_39_min_3  D_39_max_3  D_39_sum_3  \\\n",
       "0   0.477116   1.343404     0.014288    0.000467    0.035885    0.042865   \n",
       "1   0.978897   2.930539     0.002024    0.001221    0.002629    0.006072   \n",
       "2   0.642295   1.916874     0.574667    0.415254    0.685210    1.724002   \n",
       "3   0.980221   2.920287     0.268469    0.009431    0.470704    0.805407   \n",
       "4   1.006598   2.980056     0.092158    0.005624    0.150871    0.276473   \n",
       "\n",
       "   B_1_mean_3  ...  D_66_nan_ever_respond_12  D_68_0.0_ever_respond_12  \\\n",
       "0    0.069795  ...                         1                         0   \n",
       "1    0.008831  ...                         1                         0   \n",
       "2    0.431032  ...                         1                         0   \n",
       "3    0.023506  ...                         1                         0   \n",
       "4    0.040335  ...                         1                         0   \n",
       "\n",
       "   D_68_1.0_ever_respond_12  D_68_2.0_ever_respond_12  \\\n",
       "0                         0                         1   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   D_68_3.0_ever_respond_12  D_68_4.0_ever_respond_12  \\\n",
       "0                         1                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "\n",
       "   D_68_5.0_ever_respond_12  D_68_6.0_ever_respond_12  \\\n",
       "0                         0                         0   \n",
       "1                         0                         1   \n",
       "2                         1                         0   \n",
       "3                         1                         1   \n",
       "4                         0                         1   \n",
       "\n",
       "   D_68_nan_ever_respond_12  target  \n",
       "0                         1       0  \n",
       "1                         0       0  \n",
       "2                         0       0  \n",
       "3                         0       0  \n",
       "4                         0       0  \n",
       "\n",
       "[5 rows x 4154 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineered_df = pd.merge(feature_engineered_df, target_df, on='customer_ID', how='inner')\n",
    "feature_engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5371bef5f38fa9d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:13:43.821681Z",
     "start_time": "2024-10-16T21:08:32.590005Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_engineered_df.to_csv('data/feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638036cf2c73ef26",
   "metadata": {},
   "source": [
    "***USE THE BELOW CODE FOR QUESTION 7~***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfff947474849703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T20:47:58.671918Z",
     "start_time": "2024-10-17T20:47:03.599780Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fd6d2f86e5d73a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T20:48:24.575737Z",
     "start_time": "2024-10-17T20:48:18.294350Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m y \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Split the data into train and test sets\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.3\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      9\u001b[0m X_test1, X_test2, y_test1, y_test2 \u001b[38;5;241m=\u001b[39m train_test_split(X_test, y_test, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2805\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2801\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2803\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m-> 2805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2806\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m   2807\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2808\u001b[0m     )\n\u001b[1;32m   2809\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/model_selection/_split.py:2807\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2801\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[1;32m   2803\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[1;32m   2805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2806\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m-> 2807\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[1;32m   2808\u001b[0m     )\n\u001b[1;32m   2809\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/_indexing.py:263\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[0;34m(X, indices, axis)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpecifying the columns using strings is only supported for dataframes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m     )\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(X, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;66;03m# TODO: we should probably use _is_pandas_df_or_series(X) instead but this\u001b[39;00m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# would require updating some tests such as test_train_test_split_mock_pandas.\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_polars_df_or_series(X):\n\u001b[1;32m    265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _polars_indexing(X, indices, indices_dtype, axis\u001b[38;5;241m=\u001b[39maxis)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/sklearn/utils/_indexing.py:44\u001b[0m, in \u001b[0;36m_pandas_indexing\u001b[0;34m(X, key, key_dtype, axis)\u001b[0m\n\u001b[1;32m     39\u001b[0m     key \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(key)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(key)):\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# using take() instead of iloc[] ensures the return value is a \"proper\"\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# copy that will not raise SettingWithCopyWarning\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X\u001b[38;5;241m.\u001b[39mtake(key, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;66;03m# check whether we should index with loc or iloc\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39miloc \u001b[38;5;28;01mif\u001b[39;00m key_dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mloc\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/generic.py:4133\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[0;34m(self, indices, axis, **kwargs)\u001b[0m\n\u001b[1;32m   4128\u001b[0m     \u001b[38;5;66;03m# We can get here with a slice via DataFrame.__getitem__\u001b[39;00m\n\u001b[1;32m   4129\u001b[0m     indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m   4130\u001b[0m         indices\u001b[38;5;241m.\u001b[39mstart, indices\u001b[38;5;241m.\u001b[39mstop, indices\u001b[38;5;241m.\u001b[39mstep, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp\n\u001b[1;32m   4131\u001b[0m     )\n\u001b[0;32m-> 4133\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mtake(\n\u001b[1;32m   4134\u001b[0m     indices,\n\u001b[1;32m   4135\u001b[0m     axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_block_manager_axis(axis),\n\u001b[1;32m   4136\u001b[0m     verify\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   4137\u001b[0m )\n\u001b[1;32m   4138\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4139\u001b[0m     \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4140\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:894\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[1;32m    891\u001b[0m indexer \u001b[38;5;241m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[38;5;241m=\u001b[39mverify)\n\u001b[1;32m    893\u001b[0m new_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 894\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[1;32m    895\u001b[0m     new_axis\u001b[38;5;241m=\u001b[39mnew_labels,\n\u001b[1;32m    896\u001b[0m     indexer\u001b[38;5;241m=\u001b[39mindexer,\n\u001b[1;32m    897\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m    898\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    899\u001b[0m     copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    900\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:688\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    680\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_take_blocks_ax0(\n\u001b[1;32m    681\u001b[0m         indexer,\n\u001b[1;32m    682\u001b[0m         fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    683\u001b[0m         only_slice\u001b[38;5;241m=\u001b[39monly_slice,\n\u001b[1;32m    684\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39muse_na_proxy,\n\u001b[1;32m    685\u001b[0m     )\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 688\u001b[0m         blk\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m    689\u001b[0m             indexer,\n\u001b[1;32m    690\u001b[0m             axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    691\u001b[0m             fill_value\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    692\u001b[0m                 fill_value \u001b[38;5;28;01mif\u001b[39;00m fill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m blk\u001b[38;5;241m.\u001b[39mfill_value\n\u001b[1;32m    693\u001b[0m             ),\n\u001b[1;32m    694\u001b[0m         )\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks\n\u001b[1;32m    696\u001b[0m     ]\n\u001b[1;32m    698\u001b[0m new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m    699\u001b[0m new_axes[axis] \u001b[38;5;241m=\u001b[39m new_axis\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/internals/blocks.py:1307\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1304\u001b[0m     allow_fill \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;66;03m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m-> 1307\u001b[0m new_values \u001b[38;5;241m=\u001b[39m algos\u001b[38;5;241m.\u001b[39mtake_nd(\n\u001b[1;32m   1308\u001b[0m     values, indexer, axis\u001b[38;5;241m=\u001b[39maxis, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill, fill_value\u001b[38;5;241m=\u001b[39mfill_value\n\u001b[1;32m   1309\u001b[0m )\n\u001b[1;32m   1311\u001b[0m \u001b[38;5;66;03m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;66;03m#  these assertions\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m   1314\u001b[0m     \u001b[38;5;66;03m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m   1315\u001b[0m     \u001b[38;5;66;03m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mtake(indexer, fill_value\u001b[38;5;241m=\u001b[39mfill_value, allow_fill\u001b[38;5;241m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/array_algos/take.py:162\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    157\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(out_shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    159\u001b[0m func \u001b[38;5;241m=\u001b[39m _get_take_nd_function(\n\u001b[1;32m    160\u001b[0m     arr\u001b[38;5;241m.\u001b[39mndim, arr\u001b[38;5;241m.\u001b[39mdtype, out\u001b[38;5;241m.\u001b[39mdtype, axis\u001b[38;5;241m=\u001b[39maxis, mask_info\u001b[38;5;241m=\u001b[39mmask_info\n\u001b[1;32m    161\u001b[0m )\n\u001b[0;32m--> 162\u001b[0m func(arr, indexer, out, fill_value)\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flip_order:\n\u001b[1;32m    165\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mT\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Step 7; Train-test split\n",
    "# Use a random seed of 42 for the split.\n",
    "# Split the data into features and target\n",
    "X = df.drop(columns=['customer_ID', 'target'])\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test1, X_test2, y_test1, y_test2 = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a5d49d18985dbe1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:21:17.237885Z",
     "start_time": "2024-10-16T21:16:23.454681Z"
    }
   },
   "outputs": [],
   "source": [
    "# save train and test data as csv\n",
    "X_train.to_csv('data/X_train.csv', index=False)\n",
    "y_train.to_csv('data/y_train.csv', index=False)\n",
    "X_test1.to_csv('data/X_test1.csv', index=False)\n",
    "y_test1.to_csv('data/y_test1.csv', index=False)\n",
    "X_test2.to_csv('data/X_test2.csv', index=False)\n",
    "y_test2.to_csv('data/y_test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0f5c0061a92a10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:03:59.299797Z",
     "start_time": "2024-10-17T23:59:39.272837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:\n",
      "[0.00024673 0.17881931 0.0194177  ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Calculate feature importance using XGBoost\n",
    "\n",
    "# Load the training data\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Plot the feature importance\n",
    "# plot_importance(xgb_model)\n",
    "\n",
    "# Save the feature importance\n",
    "feature_importance = xgb_model.feature_importances_\n",
    "np.save('feature_importance.npy', feature_importance)\n",
    "\n",
    "# Display the feature importance\n",
    "print(\"Feature importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81d4d014c83802d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:04.170132Z",
     "start_time": "2024-10-18T00:04:04.151639Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cdd45b3552bdb021",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:25:43.033358Z",
     "start_time": "2024-10-16T21:25:43.017728Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_df.to_csv('data/feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8daf652f7f626637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:09.527028Z",
     "start_time": "2024-10-18T00:04:09.514850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.178819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.019418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R_1_mean_3</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B_1_min_3</td>\n",
       "      <td>0.017141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.011456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B_2_min_3</td>\n",
       "      <td>0.008486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>B_9_max_3</td>\n",
       "      <td>0.005448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B_2_sum_3</td>\n",
       "      <td>0.005181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature  Importance\n",
       "1   P_2_mean_3    0.178819\n",
       "2    P_2_min_3    0.019418\n",
       "17  R_1_mean_3    0.018642\n",
       "10   B_1_min_3    0.017141\n",
       "9   B_1_mean_3    0.011456\n",
       "14   B_2_min_3    0.008486\n",
       "99   B_9_max_3    0.005448\n",
       "16   B_2_sum_3    0.005181"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features = feature_importance_df[feature_importance_df['Importance'] > 0.005]\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "447e6db5f397fb02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:19.788895Z",
     "start_time": "2024-10-18T00:04:19.436591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.178819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.019418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R_1_mean_3</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B_1_min_3</td>\n",
       "      <td>0.017141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.011456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4065</th>\n",
       "      <td>D_117_4.0_response_rate_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3542</th>\n",
       "      <td>D_114_0.0_min_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>D_117_3.0_response_rate_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>D_88_mean_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>D_68_nan_ever_respond_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4153 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Feature  Importance\n",
       "1                     P_2_mean_3    0.178819\n",
       "2                      P_2_min_3    0.019418\n",
       "17                    R_1_mean_3    0.018642\n",
       "10                     B_1_min_3    0.017141\n",
       "9                     B_1_mean_3    0.011456\n",
       "...                          ...         ...\n",
       "4065  D_117_4.0_response_rate_12    0.000000\n",
       "3542            D_114_0.0_min_12    0.000000\n",
       "4064  D_117_3.0_response_rate_12    0.000000\n",
       "3201                D_88_mean_12    0.000000\n",
       "4152    D_68_nan_ever_respond_12    0.000000\n",
       "\n",
       "[4153 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply only importamt features\n",
    "# Run default XBG\n",
    "X_train_important = X_train[important_features['Feature']]\n",
    "\n",
    "xgb_model.fit(X_train_important, y_train)\n",
    "\n",
    "feature_importance_important = xgb_model.feature_importances_\n",
    "\n",
    "feature_importance_important_df = pd.DataFrame({\n",
    "    'Feature': X_train_important.columns,\n",
    "    'Importance': feature_importance_important\n",
    "})\n",
    "feature_importance_important_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_important_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cf116e78f9e8177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:24.950028Z",
     "start_time": "2024-10-18T00:04:24.940353Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_important_df = feature_importance_important_df[feature_importance_important_df['Importance'] > 0.005]\n",
    "feature_importance_important_df.to_csv('data/feature_importance_important.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6dd435893c5ee08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:30.247069Z",
     "start_time": "2024-10-18T00:04:30.240288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.178819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.019418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R_1_mean_3</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B_1_min_3</td>\n",
       "      <td>0.017141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.011456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B_2_min_3</td>\n",
       "      <td>0.008486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>B_9_max_3</td>\n",
       "      <td>0.005448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B_2_sum_3</td>\n",
       "      <td>0.005181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature  Importance\n",
       "1   P_2_mean_3    0.178819\n",
       "2    P_2_min_3    0.019418\n",
       "17  R_1_mean_3    0.018642\n",
       "10   B_1_min_3    0.017141\n",
       "9   B_1_mean_3    0.011456\n",
       "14   B_2_min_3    0.008486\n",
       "99   B_9_max_3    0.005448\n",
       "16   B_2_sum_3    0.005181"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_important_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f231ce461be088b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:11:16.678902Z",
     "start_time": "2024-10-18T00:04:50.388703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run XGB applying parameters 300 trees, 0.5 as learning rate, maximum depth of trees is 4, uses 50% of observation to build each tree, uses 50% of features to build each tree, and assigns a weight of 5 to default observations. \n",
    "# Save the model as 'xgb_model_important_features'\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model_important_features = xgb.XGBClassifier(n_estimators=300, learning_rate=0.5, max_depth=4, subsample=0.5, colsample_bytree=0.5, scale_pos_weight=5, random_state=71)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model_important_features.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the feature importance\n",
    "feature_importance_parameter_model = xgb_model_important_features.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1f993cf834ec5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:11:25.405482Z",
     "start_time": "2024-10-18T00:11:25.386963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.044978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>B_11_min_3</td>\n",
       "      <td>0.031572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>B_2_sum_6</td>\n",
       "      <td>0.031050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_2_sum_3</td>\n",
       "      <td>0.021610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>D_44_max_12</td>\n",
       "      <td>0.006988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>D_42_max_6</td>\n",
       "      <td>0.006929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B_1_max_3</td>\n",
       "      <td>0.005959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Importance\n",
       "2       P_2_min_3    0.044978\n",
       "126    B_11_min_3    0.031572\n",
       "944     B_2_sum_6    0.031050\n",
       "4       P_2_sum_3    0.021610\n",
       "2827  D_44_max_12    0.006988\n",
       "963    D_42_max_6    0.006929\n",
       "11      B_1_max_3    0.005959"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the feature importance\n",
    "feature_importance_parameter_model_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importance_parameter_model\n",
    "})\n",
    "feature_importance_parameter_model_df = feature_importance_parameter_model_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_parameter_model_df = feature_importance_parameter_model_df[feature_importance_parameter_model_df['Importance'] > 0.005]\n",
    "\n",
    "feature_importance_parameter_model_df.to_csv('data/feature_importance_parameter_model.csv', index=False)\n",
    "\n",
    "feature_importance_parameter_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2a5b99c8cdd53db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:47:16.056268Z",
     "start_time": "2024-10-18T00:47:16.050964Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_concat_df = pd.concat([feature_importance_parameter_model_df, feature_importance_important_df])\n",
    "feature_importance_concat_df = feature_importance_concat_df.drop_duplicates(subset='Feature')\n",
    "feature_importance_concat_df.to_csv('data/feature_importance_parameter_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "97936b1e9d3e1199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:47:24.037141Z",
     "start_time": "2024-10-18T00:47:24.031477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.044978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>B_11_min_3</td>\n",
       "      <td>0.031572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>B_2_sum_6</td>\n",
       "      <td>0.031050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_2_sum_3</td>\n",
       "      <td>0.021610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2827</th>\n",
       "      <td>D_44_max_12</td>\n",
       "      <td>0.006988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>D_42_max_6</td>\n",
       "      <td>0.006929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B_1_max_3</td>\n",
       "      <td>0.005959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.178819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R_1_mean_3</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B_1_min_3</td>\n",
       "      <td>0.017141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.011456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B_2_min_3</td>\n",
       "      <td>0.008486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>B_9_max_3</td>\n",
       "      <td>0.005448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B_2_sum_3</td>\n",
       "      <td>0.005181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Feature  Importance\n",
       "2       P_2_min_3    0.044978\n",
       "126    B_11_min_3    0.031572\n",
       "944     B_2_sum_6    0.031050\n",
       "4       P_2_sum_3    0.021610\n",
       "2827  D_44_max_12    0.006988\n",
       "963    D_42_max_6    0.006929\n",
       "11      B_1_max_3    0.005959\n",
       "1      P_2_mean_3    0.178819\n",
       "17     R_1_mean_3    0.018642\n",
       "10      B_1_min_3    0.017141\n",
       "9      B_1_mean_3    0.011456\n",
       "14      B_2_min_3    0.008486\n",
       "99      B_9_max_3    0.005448\n",
       "16      B_2_sum_3    0.005181"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ea14694b9c7f1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:48:19.870214Z",
     "start_time": "2024-10-18T00:47:28.844103Z"
    }
   },
   "outputs": [],
   "source": [
    "### step 9: When to resume training process\n",
    "# Load the training data, applying important features calculated by step 8\n",
    "# Load the training data, applying important features calculated by step 8\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "# feature_importance_parameter_model_df = pd.read_csv('output/feature_importance_parameter_model.csv')\n",
    "X_train = X_train[feature_importance_concat_df['Feature']]\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "\n",
    "X_test1 = pd.read_csv('data/X_test1.csv')\n",
    "X_test1 = X_test1[feature_importance_concat_df['Feature']]\n",
    "y_test1 = pd.read_csv('data/y_test1.csv')\n",
    "\n",
    "X_test2 = pd.read_csv('data/X_test2.csv')\n",
    "X_test2 = X_test2[feature_importance_concat_df['Feature']]\n",
    "y_test2 = pd.read_csv('data/y_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d63cf2936518f9ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:13:23.451302Z",
     "start_time": "2024-10-18T00:13:23.397450Z"
    }
   },
   "outputs": [],
   "source": [
    "Grid_Search_Results = pd.DataFrame(columns = [\"Number of Trees\", \"Learning Rate (LR)\", 'Subsample', '% Features', 'Weight of Default',\"AUC Train\", \"AUC Test 1\", \"AUC Test 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2c2270795e04d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:51:13.547161Z",
     "start_time": "2024-10-18T00:49:37.837482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete iteration: 1\n",
      "complete iteration: 2\n",
      "complete iteration: 3\n",
      "complete iteration: 4\n",
      "complete iteration: 5\n",
      "complete iteration: 6\n",
      "complete iteration: 7\n",
      "complete iteration: 8\n",
      "complete iteration: 9\n",
      "complete iteration: 10\n",
      "complete iteration: 11\n",
      "complete iteration: 12\n",
      "complete iteration: 13\n",
      "complete iteration: 14\n",
      "complete iteration: 15\n",
      "complete iteration: 16\n",
      "complete iteration: 17\n",
      "complete iteration: 18\n",
      "complete iteration: 19\n",
      "complete iteration: 20\n",
      "complete iteration: 21\n",
      "complete iteration: 22\n",
      "complete iteration: 23\n",
      "complete iteration: 24\n",
      "complete iteration: 25\n",
      "complete iteration: 26\n",
      "complete iteration: 27\n",
      "complete iteration: 28\n",
      "complete iteration: 29\n",
      "complete iteration: 30\n",
      "complete iteration: 31\n",
      "complete iteration: 32\n",
      "complete iteration: 33\n",
      "complete iteration: 34\n",
      "complete iteration: 35\n",
      "complete iteration: 36\n",
      "complete iteration: 37\n",
      "complete iteration: 38\n",
      "complete iteration: 39\n",
      "complete iteration: 40\n",
      "complete iteration: 41\n",
      "complete iteration: 42\n",
      "complete iteration: 43\n",
      "complete iteration: 44\n",
      "complete iteration: 45\n",
      "complete iteration: 46\n",
      "complete iteration: 47\n",
      "complete iteration: 48\n",
      "complete iteration: 49\n",
      "complete iteration: 50\n",
      "complete iteration: 51\n",
      "complete iteration: 52\n",
      "complete iteration: 53\n",
      "complete iteration: 54\n",
      "complete iteration: 55\n",
      "complete iteration: 56\n",
      "complete iteration: 57\n",
      "complete iteration: 58\n",
      "complete iteration: 59\n",
      "complete iteration: 60\n",
      "complete iteration: 61\n",
      "complete iteration: 62\n",
      "complete iteration: 63\n",
      "complete iteration: 64\n",
      "complete iteration: 65\n",
      "complete iteration: 66\n",
      "complete iteration: 67\n",
      "complete iteration: 68\n",
      "complete iteration: 69\n",
      "complete iteration: 70\n",
      "complete iteration: 71\n",
      "complete iteration: 72\n",
      "Grid search completed\n"
     ]
    }
   ],
   "source": [
    "Counter = 0\n",
    "for n_trees in [50, 100, 300]:\n",
    "    for lr in [0.01, 0.1]:\n",
    "        for subsample in [0.5, 0.8]:\n",
    "            for colsample in [0.5, 1.0]:\n",
    "                for weight in [1, 5, 10]:\n",
    "                    xgb_instance = xgb.XGBClassifier(n_estimators= n_trees, learning_rate = lr,subsample=subsample, colsample_bytree=colsample, scale_pos_weight=weight)                    \n",
    "                    model = xgb_instance.fit(X_train, y_train)\n",
    "                    \n",
    "                    Grid_Search_Results.loc[Counter,\"Number of Trees\"] = n_trees\n",
    "                    Grid_Search_Results.loc[Counter,\"Learning Rate (LR)\"] = lr\n",
    "                    Grid_Search_Results.loc[Counter,\"Subsample\"] = subsample\n",
    "                    Grid_Search_Results.loc[Counter,\"% Features\"] = colsample\n",
    "                    Grid_Search_Results.loc[Counter,\"Weight of Default\"] = weight\n",
    "                    \n",
    "                    Grid_Search_Results.loc[Counter,\"AUC Train\"] = roc_auc_score(y_train, model.predict_proba(X_train)[:,1])\n",
    "                    Grid_Search_Results.loc[Counter,\"AUC Test 1\"] = roc_auc_score(y_test1, model.predict_proba(X_test1)[:,1])\n",
    "                    Grid_Search_Results.loc[Counter,\"AUC Test 2\"] = roc_auc_score(y_test2, model.predict_proba(X_test2)[:,1])\n",
    "\n",
    "                    Counter += 1\n",
    "                    print('complete iteration:', Counter)\n",
    "print('Grid search completed')\n",
    "Grid_Search_Results.to_csv(\"output/Grid_Search_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cc53b147cb768f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:59:47.595570Z",
     "start_time": "2024-10-18T01:59:47.564265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Grid_Search_Results = pd.read_csv('output/Grid_Search_Results.csv')\n",
    "Grid_Search_Results"
   ],
   "id": "cc53b147cb768f5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Unnamed: 0  Number of Trees  Learning Rate (LR)  Subsample  % Features  \\\n",
       "0            0               50                0.01        0.5         0.5   \n",
       "1            1               50                0.01        0.5         0.5   \n",
       "2            2               50                0.01        0.5         0.5   \n",
       "3            3               50                0.01        0.5         1.0   \n",
       "4            4               50                0.01        0.5         1.0   \n",
       "..         ...              ...                 ...        ...         ...   \n",
       "67          67              300                0.10        0.8         0.5   \n",
       "68          68              300                0.10        0.8         0.5   \n",
       "69          69              300                0.10        0.8         1.0   \n",
       "70          70              300                0.10        0.8         1.0   \n",
       "71          71              300                0.10        0.8         1.0   \n",
       "\n",
       "    Weight of Default  AUC Train  AUC Test 1  AUC Test 2  \n",
       "0                   1   0.942934    0.941506    0.938124  \n",
       "1                   5   0.942033    0.940656    0.937163  \n",
       "2                  10   0.941684    0.940328    0.936314  \n",
       "3                   1   0.944099    0.942023    0.938624  \n",
       "4                   5   0.942963    0.941057    0.938003  \n",
       "..                ...        ...         ...         ...  \n",
       "67                  5   0.970592    0.942749    0.940652  \n",
       "68                 10   0.969102    0.942608    0.939753  \n",
       "69                  1   0.974293    0.942403    0.939500  \n",
       "70                  5   0.972858    0.942074    0.939852  \n",
       "71                 10   0.971203    0.941865    0.938958  \n",
       "\n",
       "[72 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Number of Trees</th>\n",
       "      <th>Learning Rate (LR)</th>\n",
       "      <th>Subsample</th>\n",
       "      <th>% Features</th>\n",
       "      <th>Weight of Default</th>\n",
       "      <th>AUC Train</th>\n",
       "      <th>AUC Test 1</th>\n",
       "      <th>AUC Test 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942934</td>\n",
       "      <td>0.941506</td>\n",
       "      <td>0.938124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942033</td>\n",
       "      <td>0.940656</td>\n",
       "      <td>0.937163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.941684</td>\n",
       "      <td>0.940328</td>\n",
       "      <td>0.936314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.942023</td>\n",
       "      <td>0.938624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942963</td>\n",
       "      <td>0.941057</td>\n",
       "      <td>0.938003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.970592</td>\n",
       "      <td>0.942749</td>\n",
       "      <td>0.940652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.969102</td>\n",
       "      <td>0.942608</td>\n",
       "      <td>0.939753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974293</td>\n",
       "      <td>0.942403</td>\n",
       "      <td>0.939500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.972858</td>\n",
       "      <td>0.942074</td>\n",
       "      <td>0.939852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971203</td>\n",
       "      <td>0.941865</td>\n",
       "      <td>0.938958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Trees Learning Rate (LR) Subsample % Features Weight of Default  \\\n",
       "0               50               0.01       0.5        0.5                 1   \n",
       "1               50               0.01       0.5        0.5                 5   \n",
       "2               50               0.01       0.5        0.5                10   \n",
       "3               50               0.01       0.5        1.0                 1   \n",
       "4               50               0.01       0.5        1.0                 5   \n",
       "..             ...                ...       ...        ...               ...   \n",
       "67             300                0.1       0.8        0.5                 5   \n",
       "68             300                0.1       0.8        0.5                10   \n",
       "69             300                0.1       0.8        1.0                 1   \n",
       "70             300                0.1       0.8        1.0                 5   \n",
       "71             300                0.1       0.8        1.0                10   \n",
       "\n",
       "   AUC Train AUC Test 1 AUC Test 2  \n",
       "0   0.942934   0.941506   0.938124  \n",
       "1   0.942033   0.940656   0.937163  \n",
       "2   0.941684   0.940328   0.936314  \n",
       "3   0.944099   0.942023   0.938624  \n",
       "4   0.942963   0.941057   0.938003  \n",
       "..       ...        ...        ...  \n",
       "67  0.970592   0.942749   0.940652  \n",
       "68  0.969102   0.942608   0.939753  \n",
       "69  0.974293   0.942403     0.9395  \n",
       "70  0.972858   0.942074   0.939852  \n",
       "71  0.971203   0.941865   0.938958  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],

   "execution_count": 73
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cb1b3f587401a6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:08:35.258080Z",
     "start_time": "2024-10-18T02:08:35.119760Z"
    }
   },
   "outputs": [],
   "source": [

    "## Calculate average and standard deviation of AUC across three samples (train and two tests)\n",
    "Grid_Search_Results['Average AUC'] = Grid_Search_Results[['AUC Train', 'AUC Test 1', 'AUC Test 2']].mean(axis=1)\n",
    "Grid_Search_Results['Standard Deviation AUC'] = Grid_Search_Results[['AUC Train', 'AUC Test 1', 'AUC Test 2']].std(axis=1)\n",
    "\n",
    "## Create a scatter plot of average AUC and standard deviation AUC\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(Grid_Search_Results['Average AUC'], Grid_Search_Results['Standard Deviation AUC'], color='yellow')\n",
    "plt.xlabel('Average AUC')\n",
    "plt.ylabel('Standard Deviation AUC')\n",
    "plt.title('Average AUC vs. Standard Deviation AUC')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "9cb1b3f587401a6d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 76
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:28:07.298438Z",
     "start_time": "2024-10-18T02:28:07.115439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# X-Axis is AUC of train sample and Y-Axis is AUC of Test 2 sample\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(Grid_Search_Results['AUC Train'], Grid_Search_Results['AUC Test 2'], color='yellow')\n",
    "\n",
    "# Find\n",
    "highest_index = Grid_Search_Results['AUC Test 2'].idxmax()\n",
    "plt.scatter(Grid_Search_Results.loc[highest_index, 'AUC Train'], Grid_Search_Results.loc[highest_index, 'AUC Test 2'], color='red', s=100, label='Highest AUC Test 2')\n",
    "plt.xlabel('AUC Train')\n",
    "plt.ylabel('AUC Test 2')\n",
    "plt.title('AUC Train vs. AUC Test 2')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "960019d376b4c26e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T02:33:16.728857Z",
     "start_time": "2024-10-18T02:33:16.629706Z"
    }
   },
   "cell_type": "code",
   "source": "Grid_Search_Results",
   "id": "4b5959bd2e118742",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Unnamed: 0  Number of Trees  Learning Rate (LR)  Subsample  % Features  \\\n",
       "0            0               50                0.01        0.5         0.5   \n",
       "1            1               50                0.01        0.5         0.5   \n",
       "2            2               50                0.01        0.5         0.5   \n",
       "3            3               50                0.01        0.5         1.0   \n",
       "4            4               50                0.01        0.5         1.0   \n",
       "..         ...              ...                 ...        ...         ...   \n",
       "67          67              300                0.10        0.8         0.5   \n",
       "68          68              300                0.10        0.8         0.5   \n",
       "69          69              300                0.10        0.8         1.0   \n",
       "70          70              300                0.10        0.8         1.0   \n",
       "71          71              300                0.10        0.8         1.0   \n",
       "\n",
       "    Weight of Default  AUC Train  AUC Test 1  AUC Test 2  Average AUC  \\\n",
       "0                   1   0.942934    0.941506    0.938124     0.940855   \n",
       "1                   5   0.942033    0.940656    0.937163     0.939951   \n",
       "2                  10   0.941684    0.940328    0.936314     0.939442   \n",
       "3                   1   0.944099    0.942023    0.938624     0.941582   \n",
       "4                   5   0.942963    0.941057    0.938003     0.940675   \n",
       "..                ...        ...         ...         ...          ...   \n",
       "67                  5   0.970592    0.942749    0.940652     0.951331   \n",
       "68                 10   0.969102    0.942608    0.939753     0.950488   \n",
       "69                  1   0.974293    0.942403    0.939500     0.952065   \n",
       "70                  5   0.972858    0.942074    0.939852     0.951595   \n",
       "71                 10   0.971203    0.941865    0.938958     0.950676   \n",
       "\n",
       "    Standard Deviation AUC  \n",
       "0                 0.002470  \n",
       "1                 0.002511  \n",
       "2                 0.002793  \n",
       "3                 0.002764  \n",
       "4                 0.002502  \n",
       "..                     ...  \n",
       "67                0.016713  \n",
       "68                0.016184  \n",
       "69                0.019304  \n",
       "70                0.018448  \n",
       "71                0.017837  \n",
       "\n",
       "[72 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Number of Trees</th>\n",
       "      <th>Learning Rate (LR)</th>\n",
       "      <th>Subsample</th>\n",
       "      <th>% Features</th>\n",
       "      <th>Weight of Default</th>\n",
       "      <th>AUC Train</th>\n",
       "      <th>AUC Test 1</th>\n",
       "      <th>AUC Test 2</th>\n",
       "      <th>Average AUC</th>\n",
       "      <th>Standard Deviation AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942934</td>\n",
       "      <td>0.941506</td>\n",
       "      <td>0.938124</td>\n",
       "      <td>0.940855</td>\n",
       "      <td>0.002470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942033</td>\n",
       "      <td>0.940656</td>\n",
       "      <td>0.937163</td>\n",
       "      <td>0.939951</td>\n",
       "      <td>0.002511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.941684</td>\n",
       "      <td>0.940328</td>\n",
       "      <td>0.936314</td>\n",
       "      <td>0.939442</td>\n",
       "      <td>0.002793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.942023</td>\n",
       "      <td>0.938624</td>\n",
       "      <td>0.941582</td>\n",
       "      <td>0.002764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942963</td>\n",
       "      <td>0.941057</td>\n",
       "      <td>0.938003</td>\n",
       "      <td>0.940675</td>\n",
       "      <td>0.002502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.970592</td>\n",
       "      <td>0.942749</td>\n",
       "      <td>0.940652</td>\n",
       "      <td>0.951331</td>\n",
       "      <td>0.016713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.969102</td>\n",
       "      <td>0.942608</td>\n",
       "      <td>0.939753</td>\n",
       "      <td>0.950488</td>\n",
       "      <td>0.016184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974293</td>\n",
       "      <td>0.942403</td>\n",
       "      <td>0.939500</td>\n",
       "      <td>0.952065</td>\n",
       "      <td>0.019304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.972858</td>\n",
       "      <td>0.942074</td>\n",
       "      <td>0.939852</td>\n",
       "      <td>0.951595</td>\n",
       "      <td>0.018448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971203</td>\n",
       "      <td>0.941865</td>\n",
       "      <td>0.938958</td>\n",
       "      <td>0.950676</td>\n",
       "      <td>0.017837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Find the best parameters\n",
    "best_parameters = Grid_Search_Results.loc[Grid_Search_Results['Average AUC'].idxmax()]\n",
    "best_model = xgb.XGBClassifier(\n",
    "    n_estimators=int(best_parameters['Number of Trees']),\n",
    "    learning_rate=best_parameters['Learning Rate (LR)'],\n",
    "    subsample=best_parameters['Subsample'],\n",
    "    colsample_bytree=best_parameters['% Features'],\n",
    "    scale_pos_weight=best_parameters['Weight of Default']\n",
    ")"
   ],
   "id": "6f2bdd99c0406ee1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:58:04.341485Z",
     "start_time": "2024-10-18T01:58:04.317128Z"
    }
   },
   "cell_type": "code",
   "source": "Grid_Search_Results",
   "id": "f5ad2f98aa20df2b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "    Unnamed: 0  Number of Trees  Learning Rate (LR)  Subsample  % Features  \\\n",
       "0            0               50                0.01        0.5         0.5   \n",
       "1            1               50                0.01        0.5         0.5   \n",
       "2            2               50                0.01        0.5         0.5   \n",
       "3            3               50                0.01        0.5         1.0   \n",
       "4            4               50                0.01        0.5         1.0   \n",
       "..         ...              ...                 ...        ...         ...   \n",
       "67          67              300                0.10        0.8         0.5   \n",
       "68          68              300                0.10        0.8         0.5   \n",
       "69          69              300                0.10        0.8         1.0   \n",
       "70          70              300                0.10        0.8         1.0   \n",
       "71          71              300                0.10        0.8         1.0   \n",
       "\n",
       "    Weight of Default  AUC Train  AUC Test 1  AUC Test 2  AUC Train Mean  \\\n",
       "0                   1   0.942934    0.941506    0.938124        0.951815   \n",
       "1                   5   0.942033    0.940656    0.937163        0.951815   \n",
       "2                  10   0.941684    0.940328    0.936314        0.951815   \n",
       "3                   1   0.944099    0.942023    0.938624        0.951815   \n",
       "4                   5   0.942963    0.941057    0.938003        0.951815   \n",
       "..                ...        ...         ...         ...             ...   \n",
       "67                  5   0.970592    0.942749    0.940652        0.951815   \n",
       "68                 10   0.969102    0.942608    0.939753        0.951815   \n",
       "69                  1   0.974293    0.942403    0.939500        0.951815   \n",
       "70                  5   0.972858    0.942074    0.939852        0.951815   \n",
       "71                 10   0.971203    0.941865    0.938958        0.951815   \n",
       "\n",
       "    AUC Test 1 Mean  AUC Test 2 Mean  AUC Train Std  AUC Test 1 Std  \\\n",
       "0          0.942775         0.939539       0.009556        0.001301   \n",
       "1          0.942775         0.939539       0.009556        0.001301   \n",
       "2          0.942775         0.939539       0.009556        0.001301   \n",
       "3          0.942775         0.939539       0.009556        0.001301   \n",
       "4          0.942775         0.939539       0.009556        0.001301   \n",
       "..              ...              ...            ...             ...   \n",
       "67         0.942775         0.939539       0.009556        0.001301   \n",
       "68         0.942775         0.939539       0.009556        0.001301   \n",
       "69         0.942775         0.939539       0.009556        0.001301   \n",
       "70         0.942775         0.939539       0.009556        0.001301   \n",
       "71         0.942775         0.939539       0.009556        0.001301   \n",
       "\n",
       "    AUC Test 2 Std  \n",
       "0         0.001356  \n",
       "1         0.001356  \n",
       "2         0.001356  \n",
       "3         0.001356  \n",
       "4         0.001356  \n",
       "..             ...  \n",
       "67        0.001356  \n",
       "68        0.001356  \n",
       "69        0.001356  \n",
       "70        0.001356  \n",
       "71        0.001356  \n",
       "\n",
       "[72 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Number of Trees</th>\n",
       "      <th>Learning Rate (LR)</th>\n",
       "      <th>Subsample</th>\n",
       "      <th>% Features</th>\n",
       "      <th>Weight of Default</th>\n",
       "      <th>AUC Train</th>\n",
       "      <th>AUC Test 1</th>\n",
       "      <th>AUC Test 2</th>\n",
       "      <th>AUC Train Mean</th>\n",
       "      <th>AUC Test 1 Mean</th>\n",
       "      <th>AUC Test 2 Mean</th>\n",
       "      <th>AUC Train Std</th>\n",
       "      <th>AUC Test 1 Std</th>\n",
       "      <th>AUC Test 2 Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942934</td>\n",
       "      <td>0.941506</td>\n",
       "      <td>0.938124</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942033</td>\n",
       "      <td>0.940656</td>\n",
       "      <td>0.937163</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.941684</td>\n",
       "      <td>0.940328</td>\n",
       "      <td>0.936314</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944099</td>\n",
       "      <td>0.942023</td>\n",
       "      <td>0.938624</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.942963</td>\n",
       "      <td>0.941057</td>\n",
       "      <td>0.938003</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.970592</td>\n",
       "      <td>0.942749</td>\n",
       "      <td>0.940652</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.969102</td>\n",
       "      <td>0.942608</td>\n",
       "      <td>0.939753</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.974293</td>\n",
       "      <td>0.942403</td>\n",
       "      <td>0.939500</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>70</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.972858</td>\n",
       "      <td>0.942074</td>\n",
       "      <td>0.939852</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>71</td>\n",
       "      <td>300</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.971203</td>\n",
       "      <td>0.941865</td>\n",
       "      <td>0.938958</td>\n",
       "      <td>0.951815</td>\n",
       "      <td>0.942775</td>\n",
       "      <td>0.939539</td>\n",
       "      <td>0.009556</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "570fb932b429e973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:52:08.895917Z",
     "start_time": "2024-10-18T00:52:08.890383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Number of Trees': 300, 'Learning Rate (LR)': 0.1, 'Subsample': 0.8, '% Features': 1.0, 'Weight of Default': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_parameters)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c205be352bed0f16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:53:31.833109Z",
     "start_time": "2024-10-18T00:53:30.729544Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the best model\n",
    "best_xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=int(best_parameters['Number of Trees']),\n",
    "    learning_rate=best_parameters['Learning Rate (LR)'],\n",
    "    subsample=best_parameters['Subsample'],\n",
    "    colsample_bytree=best_parameters['% Features'],\n",
    "    scale_pos_weight=best_parameters['Weight of Default']\n",
    ")\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the best model\n",
    "best_xgb_model.save_model('best_xgb_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d227cbcf9f9893c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:32:31.912038Z",
     "start_time": "2024-10-16T21:32:31.864899Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model('output/best_xgb_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74ac1ada95b4632b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:35.545739Z",
     "start_time": "2024-10-18T00:56:35.457028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete iteration: 2\n",
      "complete iteration: 3\n",
      "complete iteration: 4\n",
      "complete iteration: 5\n",
      "complete iteration: 6\n",
      "complete iteration: 7\n",
      "complete iteration: 8\n",
      "complete iteration: 9\n",
      "complete iteration: 10\n",
      "complete iteration: 11\n",
      "complete iteration: 12\n",
      "complete iteration: 13\n",
      "complete iteration: 14\n",
      "complete iteration: 15\n",
      "----Calculation Complete----\n"
     ]
    }
   ],
   "source": [
    "# step 10: Neural Network\n",
    "# Data Preprocessing\n",
    "outliers = pd.DataFrame(columns = ['Feature', 'p1', 'p99'])\n",
    "\n",
    "counter = 1\n",
    "for col in X_train.columns:\n",
    "    p1 = X_train[col].quantile(0.01)\n",
    "    p99 = X_train[col].quantile(0.99)\n",
    "    outliers.loc[counter] = [col, p1, p99]\n",
    "    counter += 1\n",
    "    print('complete iteration:', counter)\n",
    "print('----Calculation Complete----')\n",
    "outliers.to_csv('output/outliers.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d15d4619cf50d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:46.636841Z",
     "start_time": "2024-10-18T00:56:46.471518Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace outliers with p1 and p99\n",
    "X_train = X_train.clip(lower = X_train.quantile(0.01), upper = X_train.quantile(0.99), axis = 1)\n",
    "X_test1 = X_test1.clip(lower = X_train.quantile(0.01), upper = X_train.quantile(0.99), axis = 1)\n",
    "X_test2 = X_test2.clip(lower = X_train.quantile(0.01), upper = X_train.quantile(0.99), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3385cb34c3db98b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:50.620116Z",
     "start_time": "2024-10-18T00:56:50.570114Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test1_scaled = pd.DataFrame(scaler.transform(X_test1), columns = X_train.columns)\n",
    "X_test2_scaled = pd.DataFrame(scaler.transform(X_test2), columns = X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8158695979322d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:53.061982Z",
     "start_time": "2024-10-18T00:56:53.056374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in X_train: 55909\n",
      "Number of missing values in X_test1: 11997\n",
      "Number of missing values in X_test2: 11979\n"
     ]
    }
   ],
   "source": [
    "# fill missing values with 0\n",
    "print('Number of missing values in X_train:', X_train_scaled.isnull().sum().sum())\n",
    "print('Number of missing values in X_test1:', X_test1_scaled.isnull().sum().sum())\n",
    "print('Number of missing values in X_test2:', X_test2_scaled.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "697db8a0bdd5182d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:56.688611Z",
     "start_time": "2024-10-18T00:56:56.667659Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled.fillna(0, inplace=True)\n",
    "X_test1_scaled.fillna(0, inplace=True)\n",
    "X_test2_scaled.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76c5f0cc497c624e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:58.792054Z",
     "start_time": "2024-10-18T00:56:58.784821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in X_train: 0\n",
      "Number of missing values in X_test1: 0\n",
      "Number of missing values in X_test2: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the number of missing values again\n",
    "print('Number of missing values in X_train:', X_train_scaled.isnull().sum().sum())\n",
    "print('Number of missing values in X_test1:', X_test1_scaled.isnull().sum().sum())\n",
    "print('Number of missing values in X_test2:', X_test2_scaled.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b8abc9b30b75071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:00.998393Z",
     "start_time": "2024-10-18T00:57:00.983170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_min_3</th>\n",
       "      <th>B_11_min_3</th>\n",
       "      <th>B_2_sum_6</th>\n",
       "      <th>P_2_sum_3</th>\n",
       "      <th>D_44_max_12</th>\n",
       "      <th>D_42_max_6</th>\n",
       "      <th>B_1_max_3</th>\n",
       "      <th>P_2_mean_3</th>\n",
       "      <th>R_1_mean_3</th>\n",
       "      <th>B_1_min_3</th>\n",
       "      <th>B_1_mean_3</th>\n",
       "      <th>B_2_min_3</th>\n",
       "      <th>B_9_max_3</th>\n",
       "      <th>B_2_sum_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.650809</td>\n",
       "      <td>-0.154200</td>\n",
       "      <td>-1.406933</td>\n",
       "      <td>-0.051839</td>\n",
       "      <td>-0.651831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.225414</td>\n",
       "      <td>-0.100086</td>\n",
       "      <td>-0.410863</td>\n",
       "      <td>-0.070301</td>\n",
       "      <td>-0.150938</td>\n",
       "      <td>-1.172024</td>\n",
       "      <td>0.923663</td>\n",
       "      <td>-1.397350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.655672</td>\n",
       "      <td>1.198938</td>\n",
       "      <td>-0.463044</td>\n",
       "      <td>-0.678755</td>\n",
       "      <td>2.274824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.199052</td>\n",
       "      <td>-0.746734</td>\n",
       "      <td>-0.406592</td>\n",
       "      <td>1.321831</td>\n",
       "      <td>1.238736</td>\n",
       "      <td>-1.214813</td>\n",
       "      <td>-0.767820</td>\n",
       "      <td>-1.346659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.643313</td>\n",
       "      <td>0.374681</td>\n",
       "      <td>-1.468284</td>\n",
       "      <td>-1.620546</td>\n",
       "      <td>4.212030</td>\n",
       "      <td>0.382075</td>\n",
       "      <td>0.290951</td>\n",
       "      <td>-1.718166</td>\n",
       "      <td>1.492090</td>\n",
       "      <td>0.491907</td>\n",
       "      <td>0.393126</td>\n",
       "      <td>-1.216151</td>\n",
       "      <td>1.558677</td>\n",
       "      <td>-1.416897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.124724</td>\n",
       "      <td>-0.502704</td>\n",
       "      <td>0.613785</td>\n",
       "      <td>0.103288</td>\n",
       "      <td>-0.656168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.625817</td>\n",
       "      <td>0.059923</td>\n",
       "      <td>-0.422977</td>\n",
       "      <td>-0.552944</td>\n",
       "      <td>-0.595677</td>\n",
       "      <td>0.685589</td>\n",
       "      <td>-0.768932</td>\n",
       "      <td>0.584513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.178081</td>\n",
       "      <td>-0.509591</td>\n",
       "      <td>0.778785</td>\n",
       "      <td>-0.216368</td>\n",
       "      <td>-0.652651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.635297</td>\n",
       "      <td>-0.269794</td>\n",
       "      <td>-0.428528</td>\n",
       "      <td>-0.563172</td>\n",
       "      <td>-0.606298</td>\n",
       "      <td>0.676677</td>\n",
       "      <td>-0.767048</td>\n",
       "      <td>0.904216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64243</th>\n",
       "      <td>0.880030</td>\n",
       "      <td>-0.498854</td>\n",
       "      <td>0.616683</td>\n",
       "      <td>1.018272</td>\n",
       "      <td>-0.654837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.629035</td>\n",
       "      <td>1.003705</td>\n",
       "      <td>-0.421076</td>\n",
       "      <td>-0.561018</td>\n",
       "      <td>-0.602401</td>\n",
       "      <td>0.681646</td>\n",
       "      <td>-0.772839</td>\n",
       "      <td>0.585047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64244</th>\n",
       "      <td>0.540434</td>\n",
       "      <td>-0.181660</td>\n",
       "      <td>-1.442948</td>\n",
       "      <td>0.527134</td>\n",
       "      <td>0.319988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.228447</td>\n",
       "      <td>0.497109</td>\n",
       "      <td>-0.426669</td>\n",
       "      <td>-0.065095</td>\n",
       "      <td>-0.153812</td>\n",
       "      <td>-1.184948</td>\n",
       "      <td>1.243813</td>\n",
       "      <td>-1.412472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64245</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.499780</td>\n",
       "      <td>0.679887</td>\n",
       "      <td>-2.365119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.531187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.424694</td>\n",
       "      <td>-0.485862</td>\n",
       "      <td>-0.520850</td>\n",
       "      <td>-1.265988</td>\n",
       "      <td>-0.772327</td>\n",
       "      <td>0.213664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64246</th>\n",
       "      <td>-0.165413</td>\n",
       "      <td>-0.510634</td>\n",
       "      <td>1.125710</td>\n",
       "      <td>-0.145014</td>\n",
       "      <td>-0.651150</td>\n",
       "      <td>-0.789057</td>\n",
       "      <td>-0.628512</td>\n",
       "      <td>-0.196194</td>\n",
       "      <td>-0.418504</td>\n",
       "      <td>-0.539091</td>\n",
       "      <td>-0.592630</td>\n",
       "      <td>1.136758</td>\n",
       "      <td>-0.536272</td>\n",
       "      <td>1.077220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64247</th>\n",
       "      <td>-0.440354</td>\n",
       "      <td>-0.401682</td>\n",
       "      <td>1.116897</td>\n",
       "      <td>-0.395775</td>\n",
       "      <td>-0.163572</td>\n",
       "      <td>1.280082</td>\n",
       "      <td>-0.402105</td>\n",
       "      <td>-0.454847</td>\n",
       "      <td>-0.419193</td>\n",
       "      <td>-0.396674</td>\n",
       "      <td>-0.383008</td>\n",
       "      <td>1.132823</td>\n",
       "      <td>-0.780460</td>\n",
       "      <td>1.065296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64248 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       P_2_min_3  B_11_min_3  B_2_sum_6  P_2_sum_3  D_44_max_12  D_42_max_6  \\\n",
       "0      -0.650809   -0.154200  -1.406933  -0.051839    -0.651831    0.000000   \n",
       "1      -0.655672    1.198938  -0.463044  -0.678755     2.274824    0.000000   \n",
       "2      -1.643313    0.374681  -1.468284  -1.620546     4.212030    0.382075   \n",
       "3       0.124724   -0.502704   0.613785   0.103288    -0.656168    0.000000   \n",
       "4      -0.178081   -0.509591   0.778785  -0.216368    -0.652651    0.000000   \n",
       "...          ...         ...        ...        ...          ...         ...   \n",
       "64243   0.880030   -0.498854   0.616683   1.018272    -0.654837    0.000000   \n",
       "64244   0.540434   -0.181660  -1.442948   0.527134     0.319988    0.000000   \n",
       "64245   0.000000   -0.499780   0.679887  -2.365119     0.000000    0.000000   \n",
       "64246  -0.165413   -0.510634   1.125710  -0.145014    -0.651150   -0.789057   \n",
       "64247  -0.440354   -0.401682   1.116897  -0.395775    -0.163572    1.280082   \n",
       "\n",
       "       B_1_max_3  P_2_mean_3  R_1_mean_3  B_1_min_3  B_1_mean_3  B_2_min_3  \\\n",
       "0      -0.225414   -0.100086   -0.410863  -0.070301   -0.150938  -1.172024   \n",
       "1       1.199052   -0.746734   -0.406592   1.321831    1.238736  -1.214813   \n",
       "2       0.290951   -1.718166    1.492090   0.491907    0.393126  -1.216151   \n",
       "3      -0.625817    0.059923   -0.422977  -0.552944   -0.595677   0.685589   \n",
       "4      -0.635297   -0.269794   -0.428528  -0.563172   -0.606298   0.676677   \n",
       "...          ...         ...         ...        ...         ...        ...   \n",
       "64243  -0.629035    1.003705   -0.421076  -0.561018   -0.602401   0.681646   \n",
       "64244  -0.228447    0.497109   -0.426669  -0.065095   -0.153812  -1.184948   \n",
       "64245  -0.531187    0.000000   -0.424694  -0.485862   -0.520850  -1.265988   \n",
       "64246  -0.628512   -0.196194   -0.418504  -0.539091   -0.592630   1.136758   \n",
       "64247  -0.402105   -0.454847   -0.419193  -0.396674   -0.383008   1.132823   \n",
       "\n",
       "       B_9_max_3  B_2_sum_3  \n",
       "0       0.923663  -1.397350  \n",
       "1      -0.767820  -1.346659  \n",
       "2       1.558677  -1.416897  \n",
       "3      -0.768932   0.584513  \n",
       "4      -0.767048   0.904216  \n",
       "...          ...        ...  \n",
       "64243  -0.772839   0.585047  \n",
       "64244   1.243813  -1.412472  \n",
       "64245  -0.772327   0.213664  \n",
       "64246  -0.536272   1.077220  \n",
       "64247  -0.780460   1.065296  \n",
       "\n",
       "[64248 rows x 14 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d98f9ed1d018d46d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:10.501017Z",
     "start_time": "2024-10-18T00:57:09.258205Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled.to_csv('data/X_train_scaled.csv', index=False)\n",
    "X_test1_scaled.to_csv('data/X_test1_scaled.csv', index=False)\n",
    "X_test2_scaled.to_csv('data/X_test2_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af46397cb15de063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:19.677779Z",
     "start_time": "2024-10-18T00:57:19.458418Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data for nn\n",
    "X_train_scaled = pd.read_csv('data/X_train_scaled.csv')\n",
    "X_test1_scaled = pd.read_csv('data/X_test1_scaled.csv')\n",
    "X_test2_scaled = pd.read_csv('data/X_test2_scaled.csv')\n",
    "\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "y_test1 = pd.read_csv('data/y_test1.csv')\n",
    "y_test2 = pd.read_csv('data/y_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cec5ec5df12581c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:01:31.927291Z",
     "start_time": "2024-10-18T00:57:21.646113Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429us/step - loss: 0.6801\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.4743\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.3956\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.3524\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - loss: 0.3276\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - loss: 0.3116\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - loss: 0.3033\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.2999\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - loss: 0.2924\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.2877\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 0.2865\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - loss: 0.2829\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - loss: 0.2787\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.2762\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 0.2791\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - loss: 0.2782\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 0.2775\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.2778\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - loss: 0.2757\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 0.2778\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7078  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6799 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.6517\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6245 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6034 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5837 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5656 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5467 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5280 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5076 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4882 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4676 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.4500\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4320 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4154 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4034 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3900 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3786 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3700 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3600 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - loss: 0.6078\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4788\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.4526\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4502\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.4489\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.4474\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 0.4485\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.4503\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.4486\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4461\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.4477\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4423\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.4475\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.4475\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.4441\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.4429\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.4477\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.4467\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4447\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.4469\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7674  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7476 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7221 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7029 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6892 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6735 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6597 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6428 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6325 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6169 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6041 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6021 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5897 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5799 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5721 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5628 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5570 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5495 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5400 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5334 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366us/step - loss: 0.5600\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - loss: 0.3004\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.2898\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 0.2839\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 0.2847\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.2803\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2786\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2780\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2744\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2839\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2758\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.2742\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.2751\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.2761\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 0.2758\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - loss: 0.2754\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.2784\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 0.2775\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.2750\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - loss: 0.2760\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8163  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7813 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.7462\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.7172\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6879 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6646 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.6391\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6195 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.6032\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.5846\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.5670\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5569 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5434  \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5314 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5210 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5093 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5007 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4921 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4845 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4781 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - loss: 0.5577\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.3848\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 0.3754\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3656\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 0.3607\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 0.3601\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 0.3569\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.3557\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.3543\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.3592\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.3546\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.3529\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.3553\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 0.3544\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 0.3515\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.3589\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 0.3485\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 0.3489\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 0.3539\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 0.3539\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7030  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6789 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6585 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6423 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6276 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6158 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6024 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5975 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5888 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5801 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5701 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5647 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5599 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5559 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5472 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5436 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5371 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5333 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5252 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5251 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476us/step - loss: 0.4901\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 0.2869\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 0.2724\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.2749\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.2714\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 0.2752\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.2719\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - loss: 0.2734\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.2692\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.2731\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.2721\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.2691\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.2742\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.2728\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 0.2742\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.2720\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.2718\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 0.2712\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.2709\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 0.2709\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6903  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6770 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6606 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6462 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6303 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6150 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6004 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5846 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5693 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5535 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5366 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5158 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4948 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4708 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4525 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4324 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4165 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4012 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3887 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3786 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - loss: 0.6878\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.4372\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 0.4020\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.3864\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.3779\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 0.3764\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 0.3767\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.3767\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.3725\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.3719\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.3700\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 0.3735\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.3716\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3708\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.3700\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.3731\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.3737\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 0.3731\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.3723\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 0.3722\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0414  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9653 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9006 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8762 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8175 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7862 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7559 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7229 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6905 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6639 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6389 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6222 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6041 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5815 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5738 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5607 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5529 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5468 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5389 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5284 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - loss: 0.4806\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.2903\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 0.2804\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - loss: 0.2794\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - loss: 0.2807\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - loss: 0.2783\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2751\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - loss: 0.2776\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.2761\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - loss: 0.2764\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.2773\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.2721\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 0.2751\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 0.2695\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.2718\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.2705\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.2726\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.2690\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 0.2730\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.2754\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8841  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8161 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7554 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7032 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6577 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6194 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5839 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5536 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5254 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5006 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4791 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4607 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4446 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4303 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4170 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4052 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3973 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3880 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3800 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3726 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431us/step - loss: 0.5922\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.3711\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.3496\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 0.3405\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 0.3365\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.3365\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.3326\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.3347\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 0.3361\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.3335\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 0.3316\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - loss: 0.3275\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.3278\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.3331\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3235\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.3248\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 0.3267\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 0.3213\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 0.3328\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.3260\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8438  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8054 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7671 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7332 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6990 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6750 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6517 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6322 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6142 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5973 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5824 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5672 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5553 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5457 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5365 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5263 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5185 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5091 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5021 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4944 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - loss: 0.4363\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - loss: 0.2815\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.2818\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 0.2773\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 0.2738\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.2757\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.2746\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.2714\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.2712\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.2699\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.2727\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.2743\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.2760\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 0.2745\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - loss: 0.2729\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 0.2718\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 0.2753\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.2745\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.2743\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.2725\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6952  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6886 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6821 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6764 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6697 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6624 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6521 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6377 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6164 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5935 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5715 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5480 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5257 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5063 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4874 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4733 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4573 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4430 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4324 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4231 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - loss: 0.9752\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.5830\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 0.5566\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 0.5275\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 0.5150\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.5099\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.5067\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.5009\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.4996\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 0.5027\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.4980\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 0.4990\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 0.4991\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - loss: 0.4996\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4989\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4961\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - loss: 0.4950\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.4922\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.4955\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.4951\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8164\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7951 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7813 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7554 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7432 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7209 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7132 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6997 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6926 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6805 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6714 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6681 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6577 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6519 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6491 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6384 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6356 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6323 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6270 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6204 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435us/step - loss: 0.4668\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2940\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.2889\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2800\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.2787\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.2786\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2772\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 0.2778\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2772\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2738\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.2725\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.2749\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.2737\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 0.2751\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2756\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.2765\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 0.2717\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.2746\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - loss: 0.2733\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - loss: 0.2741\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6928\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6567 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6240 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5952 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5699 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5484 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5281 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5104 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4930\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4756\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4598\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4450\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4324 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4175 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4051 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3954 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3852 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3764 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3667 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3586 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 622us/step - loss: 0.6524\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - loss: 0.4799\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.4409\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.4211\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.4092\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 0.4056\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3980\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4040\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3943\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.3966\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.3985\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 0.3956\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.3996\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.3905\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.3979\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 0.3965\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.3975\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.3922\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.3939\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.3933\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7448  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7253 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7062 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6880 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6762 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6633 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6526 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6402 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6300 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6224 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6137 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6064 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6015 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5948 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5867 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5844 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5750 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5722 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5678 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5658 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - loss: 0.4429\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2798\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2800\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.2761\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 0.2729\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 0.2728\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 0.2736\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2756\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.2733\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.2715\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.2721\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 0.2690\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.2720\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.2729\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.2731\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.2694\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.2730\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2694\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.2720\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2706\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7178  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6960 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6789 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6633 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6447 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6276 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6086 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5885 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5670 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5440 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5219 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4992 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4776 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4576 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4376 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4190 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3996 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3834 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3697 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3582 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - loss: 0.6479\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 0.5262\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 0.5009\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 0.4762\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 0.4677\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.4529\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 0.4447\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 0.4442\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 0.4426\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 0.4414\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.4378\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 0.4409\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 0.4445\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.4398\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.4418\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 0.4447\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 0.4394\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 0.4350\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.4446\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 0.4411\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7292  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7177 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7032 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6962 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6906 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6862 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6824 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6772 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6749 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6704 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6661 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6634 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6605 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6575 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6541 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6500 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6471 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6442 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6400 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6368 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - loss: 0.4869\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 0.2944\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 0.2804\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 0.2812\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 0.2802\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.2796\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2758\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 0.2779\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.2778\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.2750\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2747\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2756\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.2726\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.2768\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.2737\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.2710\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.2728\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - loss: 0.2722\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.2739\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.2749\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6614  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6186 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5792 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5428 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5088 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4770 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4488 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4245 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4010 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3831 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3683 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3561 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3462 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3363 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3295 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3242 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3179 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3146 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3156 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3079 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 505us/step - loss: 0.5926\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.4105\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.3864\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 0.3717\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3654\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 0.3627\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 0.3563\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 0.3559\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.3562\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.3570\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3520\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3538\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.3583\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.3543\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.3515\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.3567\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.3553\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.3518\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 0.3533\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - loss: 0.3492\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7489  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7221 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6969 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6735 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6570 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6429 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6297 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6225 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6115 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6026 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5936 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5849 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5785 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5688 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5603 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5564 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5478 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5412 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5382 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5319 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step\n",
      "Grid search completed\n"
     ]
    }
   ],
   "source": [
    "# build neural network\n",
    "nn_grid_search_result = pd.DataFrame(columns = [\"#HL\", \"#Nodes\", \"ActivationFunction\", \"Dropout\", \"BatchSize\", \"AUC_Train\", \"AUC_Test1\", \"AUC_Test2\"])\n",
    "\n",
    "Counter = 0\n",
    "for hl in [2,4]:\n",
    "    for nodes in [4,6]:\n",
    "        for activate_function in [\"relu\", \"tanh\"]:\n",
    "            for dropout in [0, 0.5]:\n",
    "                for batch_size in [100, 10000]:\n",
    "                    model = Sequential()\n",
    "                    model.add(Dense(nodes, input_dim=X_train_scaled.shape[1], activation=activate_function))\n",
    "                    model.add(Dropout(dropout))\n",
    "                    for i in range(hl - 1):\n",
    "                        model.add(Dense(nodes, activation=activate_function))\n",
    "                        model.add(Dropout(dropout))\n",
    "                    model.add(Dense(1, activation='sigmoid'))\n",
    "                    model.compile(optimizer=Adam(), loss=BinaryCrossentropy())\n",
    "                    model.fit(X_train_scaled, y_train, batch_size=batch_size, epochs=20)\n",
    "                    \n",
    "                    nn_grid_search_result.loc[Counter, \"#HL\"] = hl\n",
    "                    nn_grid_search_result.loc[Counter, \"#Nodes\"] = nodes\n",
    "                    nn_grid_search_result.loc[Counter, \"ActivationFunction\"] = activate_function\n",
    "                    nn_grid_search_result.loc[Counter, \"Dropout\"] = dropout\n",
    "                    nn_grid_search_result.loc[Counter, \"BatchSize\"] = batch_size\n",
    "                    nn_grid_search_result.loc[Counter, \"AUC_Train\"] = roc_auc_score(y_train, model.predict(X_train_scaled))\n",
    "                    nn_grid_search_result.loc[Counter, \"AUC_Test1\"] = roc_auc_score(y_test1, model.predict(X_test1_scaled))\n",
    "                    nn_grid_search_result.loc[Counter, \"AUC_Test2\"] = roc_auc_score(y_test2, model.predict(X_test2_scaled))\n",
    "                    \n",
    "                    Counter += 1\n",
    "\n",
    "print('Grid search completed')\n",
    "nn_grid_search_result.to_csv('output/nn_grid_search_result.csv')\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4d29b363d2337fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:03:43.805810Z",
     "start_time": "2024-10-18T01:03:43.766677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#HL</th>\n",
       "      <th>#Nodes</th>\n",
       "      <th>ActivationFunction</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>BatchSize</th>\n",
       "      <th>AUC_Train</th>\n",
       "      <th>AUC_Test1</th>\n",
       "      <th>AUC_Test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.937706</td>\n",
       "      <td>0.940149</td>\n",
       "      <td>0.936429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.927040</td>\n",
       "      <td>0.930282</td>\n",
       "      <td>0.925276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936715</td>\n",
       "      <td>0.939418</td>\n",
       "      <td>0.935537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.895927</td>\n",
       "      <td>0.901307</td>\n",
       "      <td>0.895857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936607</td>\n",
       "      <td>0.939496</td>\n",
       "      <td>0.936229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.823929</td>\n",
       "      <td>0.832054</td>\n",
       "      <td>0.819274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936339</td>\n",
       "      <td>0.938840</td>\n",
       "      <td>0.935383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.913145</td>\n",
       "      <td>0.917832</td>\n",
       "      <td>0.912122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.938592</td>\n",
       "      <td>0.940596</td>\n",
       "      <td>0.937435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.931316</td>\n",
       "      <td>0.934847</td>\n",
       "      <td>0.930024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936274</td>\n",
       "      <td>0.938666</td>\n",
       "      <td>0.935157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.882195</td>\n",
       "      <td>0.885170</td>\n",
       "      <td>0.878113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.938300</td>\n",
       "      <td>0.940406</td>\n",
       "      <td>0.937342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.917121</td>\n",
       "      <td>0.920719</td>\n",
       "      <td>0.914666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936164</td>\n",
       "      <td>0.938762</td>\n",
       "      <td>0.935328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.919970</td>\n",
       "      <td>0.921241</td>\n",
       "      <td>0.918030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.937773</td>\n",
       "      <td>0.940074</td>\n",
       "      <td>0.936396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.890957</td>\n",
       "      <td>0.893709</td>\n",
       "      <td>0.890111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936164</td>\n",
       "      <td>0.938984</td>\n",
       "      <td>0.935104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.845415</td>\n",
       "      <td>0.839998</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.937928</td>\n",
       "      <td>0.940324</td>\n",
       "      <td>0.936587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.925128</td>\n",
       "      <td>0.929282</td>\n",
       "      <td>0.924158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.935846</td>\n",
       "      <td>0.938413</td>\n",
       "      <td>0.935081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.902848</td>\n",
       "      <td>0.905326</td>\n",
       "      <td>0.901235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.938529</td>\n",
       "      <td>0.940395</td>\n",
       "      <td>0.936909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.927956</td>\n",
       "      <td>0.930908</td>\n",
       "      <td>0.926392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936045</td>\n",
       "      <td>0.938583</td>\n",
       "      <td>0.934832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.854660</td>\n",
       "      <td>0.865046</td>\n",
       "      <td>0.848798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.938408</td>\n",
       "      <td>0.940861</td>\n",
       "      <td>0.937142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.932010</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>0.929548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936299</td>\n",
       "      <td>0.938954</td>\n",
       "      <td>0.935355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.910234</td>\n",
       "      <td>0.913566</td>\n",
       "      <td>0.906873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    #HL  #Nodes ActivationFunction  Dropout  BatchSize  AUC_Train  AUC_Test1  \\\n",
       "0     2       4               relu      0.0        100   0.937706   0.940149   \n",
       "1     2       4               relu      0.0      10000   0.927040   0.930282   \n",
       "2     2       4               relu      0.5        100   0.936715   0.939418   \n",
       "3     2       4               relu      0.5      10000   0.895927   0.901307   \n",
       "4     2       4               tanh      0.0        100   0.936607   0.939496   \n",
       "5     2       4               tanh      0.0      10000   0.823929   0.832054   \n",
       "6     2       4               tanh      0.5        100   0.936339   0.938840   \n",
       "7     2       4               tanh      0.5      10000   0.913145   0.917832   \n",
       "8     2       6               relu      0.0        100   0.938592   0.940596   \n",
       "9     2       6               relu      0.0      10000   0.931316   0.934847   \n",
       "10    2       6               relu      0.5        100   0.936274   0.938666   \n",
       "11    2       6               relu      0.5      10000   0.882195   0.885170   \n",
       "12    2       6               tanh      0.0        100   0.938300   0.940406   \n",
       "13    2       6               tanh      0.0      10000   0.917121   0.920719   \n",
       "14    2       6               tanh      0.5        100   0.936164   0.938762   \n",
       "15    2       6               tanh      0.5      10000   0.919970   0.921241   \n",
       "16    4       4               relu      0.0        100   0.937773   0.940074   \n",
       "17    4       4               relu      0.0      10000   0.890957   0.893709   \n",
       "18    4       4               relu      0.5        100   0.936164   0.938984   \n",
       "19    4       4               relu      0.5      10000   0.845415   0.839998   \n",
       "20    4       4               tanh      0.0        100   0.937928   0.940324   \n",
       "21    4       4               tanh      0.0      10000   0.925128   0.929282   \n",
       "22    4       4               tanh      0.5        100   0.935846   0.938413   \n",
       "23    4       4               tanh      0.5      10000   0.902848   0.905326   \n",
       "24    4       6               relu      0.0        100   0.938529   0.940395   \n",
       "25    4       6               relu      0.0      10000   0.927956   0.930908   \n",
       "26    4       6               relu      0.5        100   0.936045   0.938583   \n",
       "27    4       6               relu      0.5      10000   0.854660   0.865046   \n",
       "28    4       6               tanh      0.0        100   0.938408   0.940861   \n",
       "29    4       6               tanh      0.0      10000   0.932010   0.933934   \n",
       "30    4       6               tanh      0.5        100   0.936299   0.938954   \n",
       "31    4       6               tanh      0.5      10000   0.910234   0.913566   \n",
       "\n",
       "    AUC_Test2  \n",
       "0    0.936429  \n",
       "1    0.925276  \n",
       "2    0.935537  \n",
       "3    0.895857  \n",
       "4    0.936229  \n",
       "5    0.819274  \n",
       "6    0.935383  \n",
       "7    0.912122  \n",
       "8    0.937435  \n",
       "9    0.930024  \n",
       "10   0.935157  \n",
       "11   0.878113  \n",
       "12   0.937342  \n",
       "13   0.914666  \n",
       "14   0.935328  \n",
       "15   0.918030  \n",
       "16   0.936396  \n",
       "17   0.890111  \n",
       "18   0.935104  \n",
       "19   0.841000  \n",
       "20   0.936587  \n",
       "21   0.924158  \n",
       "22   0.935081  \n",
       "23   0.901235  \n",
       "24   0.936909  \n",
       "25   0.926392  \n",
       "26   0.934832  \n",
       "27   0.848798  \n",
       "28   0.937142  \n",
       "29   0.929548  \n",
       "30   0.935355  \n",
       "31   0.906873  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search_result = pd.read_csv('output/nn_grid_search_result.csv', index_col=0)\n",
    "nn_grid_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece1659b726ff7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
