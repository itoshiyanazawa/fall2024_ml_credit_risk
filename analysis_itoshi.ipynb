{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:29:27.046489Z",
     "start_time": "2024-10-18T00:29:27.035714Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.core.common import random_state\n",
    "from pandas.core.interchange.from_dataframe import categorical_column_to_series\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from tensorflow.python.ops.gen_dataset_ops import model_dataset\n",
    "from xgboost import plot_importance\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62d616227abc4dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T00:37:10.645002Z",
     "start_time": "2024-10-16T00:37:10.639918Z"
    }
   },
   "outputs": [],
   "source": [
    "chunk_size = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "435202c9b6abac00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:26:30.449636Z",
     "start_time": "2024-09-26T20:26:30.447099Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize variables for analysis\n",
    "total_rows = 0\n",
    "column_sums = None\n",
    "column_squared_sums = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "975540a43160cb5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:26:31.469312Z",
     "start_time": "2024-09-26T20:26:31.465683Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: Read the data in chunks\n",
    "def read_csv_in_chunks(file_path, chunk_size):\n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        yield chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b401fcbd7ea719b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T18:34:42.985826Z",
     "start_time": "2024-09-26T18:34:42.480513Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Sample 20% of observation\n",
    "labels = pd.read_csv('data/train_labels.csv')\n",
    "sample_labels = labels.sample(frac=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade08e5e4c931082",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T18:45:12.751126Z",
     "start_time": "2024-09-26T18:40:24.363556Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "sampled_data = []\n",
    "for chunk in read_csv_in_chunks('data/train_data.csv', chunk_size):\n",
    "    merged_chunk = pd.merge(chunk, sample_labels, on='customer_ID', how='inner')\n",
    "    sampled_data.append(merged_chunk)\n",
    "    \n",
    "# Combine all chunks into a single dataframe\n",
    "development_sample = pd.concat(sampled_data, ignore_index=True)\n",
    "\n",
    "# Save the development sample\n",
    "development_sample.to_csv('data/development_sample.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c917101ada60f7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T20:01:56.955999Z",
     "start_time": "2024-09-26T20:01:35.465964Z"
    }
   },
   "outputs": [],
   "source": [
    "# load development_sample\n",
    "data = []\n",
    "for chunk in read_csv_in_chunks('data/development_sample.csv', chunk_size):\n",
    "    data.append(chunk)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1907398581b9aa5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-26T18:57:41.316645Z",
     "start_time": "2024-09-26T18:57:39.949939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_137</th>\n",
       "      <th>D_138</th>\n",
       "      <th>D_139</th>\n",
       "      <th>D_140</th>\n",
       "      <th>D_141</th>\n",
       "      <th>D_142</th>\n",
       "      <th>D_143</th>\n",
       "      <th>D_144</th>\n",
       "      <th>D_145</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>0.374606</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>0.044293</td>\n",
       "      <td>1.008622</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.459235</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008263</td>\n",
       "      <td>0.006609</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007171</td>\n",
       "      <td>0.005120</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.414269</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.059667</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.004050</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>0.413310</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009515</td>\n",
       "      <td>0.008757</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-06-10</td>\n",
       "      <td>0.328983</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.115654</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.416112</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.007841</td>\n",
       "      <td>0.007421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>0.496989</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.419864</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.098308</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.006957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008746</td>\n",
       "      <td>0.007101</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 191 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID         S_2       P_2  \\\n",
       "0  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-03-11  0.374606   \n",
       "1  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-04-22  0.414269   \n",
       "2  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-05-12  0.413310   \n",
       "3  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-06-10  0.328983   \n",
       "4  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-07-19  0.496989   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
       "0  0.033519  0.044293  1.008622  0.001470  0.459235  0.002339  0.006168  ...   \n",
       "1  0.002516  0.059667  0.123964  0.004374  0.434148  0.001405  0.052130  ...   \n",
       "2  0.003285  0.053418  0.304955  0.002316  0.415906  0.009388  0.048780  ...   \n",
       "3  0.038574  0.049463  0.115654  0.004654  0.416112  0.003223  0.081001  ...   \n",
       "4  0.005552  0.041452  0.133631  0.007363  0.419864  0.003393  0.098308  ...   \n",
       "\n",
       "   D_137  D_138     D_139     D_140     D_141  D_142     D_143     D_144  \\\n",
       "0    NaN    NaN  0.008263  0.006609  0.007370    NaN  0.007171  0.005120   \n",
       "1    NaN    NaN  0.001986  0.004050  0.000796    NaN  0.001802  0.002364   \n",
       "2    NaN    NaN  0.009515  0.008757  0.009219    NaN  0.003134  0.001686   \n",
       "3    NaN    NaN  0.002524  0.007841  0.007421    NaN  0.000728  0.003591   \n",
       "4    NaN    NaN  0.003823  0.009599  0.006957    NaN  0.008746  0.007101   \n",
       "\n",
       "      D_145  target  \n",
       "0  0.007513       0  \n",
       "1  0.003987       0  \n",
       "2  0.001265       0  \n",
       "3  0.007998       0  \n",
       "4  0.006658       0  \n",
       "\n",
       "[5 rows x 191 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(data, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d672127d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        Category  #Observations  Default rate\n",
      "0                                 All applicants          91783      0.246498\n",
      "1   Applications with 13 months of historic data          77348      0.229405\n",
      "2   Applications with 12 months of historic data           2115      0.378723\n",
      "3   Applications with 11 months of historic data           1159      0.440897\n",
      "4   Applications with 10 months of historic data           1329      0.465764\n",
      "5    Applications with 9 months of historic data           1278      0.435837\n",
      "6    Applications with 8 months of historic data           1169      0.450813\n",
      "7    Applications with 7 months of historic data           1046      0.414914\n",
      "8    Applications with 6 months of historic data           1109      0.412985\n",
      "9    Applications with 5 months of historic data            933      0.394427\n",
      "10   Applications with 4 months of historic data            938      0.430704\n",
      "11   Applications with 3 months of historic data           1158      0.357513\n",
      "12   Applications with 2 months of historic data           1217      0.312243\n",
      "13   Applications with 1 months of historic data            984      0.331301\n"
     ]
    }
   ],
   "source": [
    "def calculate_default_rate(data):\n",
    "    # Initialize a DataFrame to store the results\n",
    "    default_rates = pd.DataFrame(columns=[\"Category\", \"#Observations\", \"Default rate\"])\n",
    "    \n",
    "    # Get the total number of unique customer IDs\n",
    "    total_customers = len(data[\"customer_ID\"].unique())\n",
    "    \n",
    "    # Calculate default rate for all applicants\n",
    "    default_rate_all = data[\"target\"].mean()\n",
    "    default_rates.loc[0] = [\"All applicants\", total_customers, default_rate_all]\n",
    "    \n",
    "    # Calculate default rate for each category of historic data length\n",
    "    for months in range(13, 0, -1):  # Iterate from 13 months to 1 month\n",
    "        category_customers = data.groupby(\"customer_ID\").size() == months  # Check if each customer has data for the specific number of months\n",
    "        category_observations = category_customers.sum()  # Get the number of customers in this category\n",
    "        category_data = data[data[\"customer_ID\"].isin(category_customers[category_customers].index)]  # Filter data for the specific category\n",
    "        default_rate_category = category_data[\"target\"].mean()  # Calculate default rate for this category\n",
    "        default_rates.loc[len(default_rates)] = [f\"Applications with {months} months of historic data\", category_observations, default_rate_category]\n",
    "    \n",
    "    return default_rates\n",
    "\n",
    "# Call the function with your development_sample dataset\n",
    "default_rates_data = calculate_default_rate(development_sample)\n",
    "\n",
    "# Display the results\n",
    "print(default_rates_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15b8f22df0c015d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:01:51.333896Z",
     "start_time": "2024-10-16T21:01:51.324472Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a756f487fcb57c0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T00:55:02.153395Z",
     "start_time": "2024-09-27T00:54:32.732911Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 100000\n",
      "Processed chunk of size 7082\n",
      "One-hot encoding completed.\n",
      "Shape of encoded DataFrame: (1107082, 235)\n",
      "                                         customer_ID         S_2       P_2  \\\n",
      "0  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-03-11  0.374606   \n",
      "1  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-04-22  0.414269   \n",
      "2  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-05-12  0.413310   \n",
      "3  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-06-10  0.328983   \n",
      "4  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...  2017-07-19  0.496989   \n",
      "\n",
      "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
      "0  0.033519  0.044293  1.008622  0.001470  0.459235  0.002339  0.006168  ...   \n",
      "1  0.002516  0.059667  0.123964  0.004374  0.434148  0.001405  0.052130  ...   \n",
      "2  0.003285  0.053418  0.304955  0.002316  0.415906  0.009388  0.048780  ...   \n",
      "3  0.038574  0.049463  0.115654  0.004654  0.416112  0.003223  0.081001  ...   \n",
      "4  0.005552  0.041452  0.133631  0.007363  0.419864  0.003393  0.098308  ...   \n",
      "\n",
      "   D_66_1.0  D_66_nan  D_68_0.0  D_68_1.0  D_68_2.0  D_68_3.0  D_68_4.0  \\\n",
      "0         0         1         0         0         0         0         0   \n",
      "1         0         1         0         0         0         0         0   \n",
      "2         0         1         0         0         1         0         0   \n",
      "3         0         1         0         0         1         0         0   \n",
      "4         0         1         0         0         1         0         0   \n",
      "\n",
      "   D_68_5.0  D_68_6.0  D_68_nan  \n",
      "0         0         0         1  \n",
      "1         0         0         1  \n",
      "2         0         0         0  \n",
      "3         0         0         0  \n",
      "4         0         0         0  \n",
      "\n",
      "[5 rows x 235 columns]\n",
      "customer_ID     object\n",
      "S_2             object\n",
      "P_2            float64\n",
      "D_39           float64\n",
      "B_1            float64\n",
      "                ...   \n",
      "D_68_3.0         int64\n",
      "D_68_4.0         int64\n",
      "D_68_5.0         int64\n",
      "D_68_6.0         int64\n",
      "D_68_nan         int64\n",
      "Length: 235, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Step 5: One-hot encoding for categorical variables\n",
    "# List of known categorical columns\n",
    "# List of categorical columns\n",
    "\n",
    "# Function to read and process data in chunks\n",
    "def process_chunks(file_path, chunk_size=100000):\n",
    "    encoded_chunks = []\n",
    "    \n",
    "    for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "        # Convert all specified columns to strings\n",
    "        for col in categorical_columns:\n",
    "            chunk[col] = chunk[col].astype(str)\n",
    "        \n",
    "        # Perform one-hot encoding\n",
    "        encoded_chunk = pd.get_dummies(chunk, columns=categorical_columns)\n",
    "        \n",
    "        # Ensure the encoded columns are of type int (0 or 1)\n",
    "        for col in encoded_chunk.columns:\n",
    "            if col.startswith(tuple(categorical_columns)):\n",
    "                encoded_chunk[col] = encoded_chunk[col].astype(int)\n",
    "        \n",
    "        encoded_chunks.append(encoded_chunk)\n",
    "        \n",
    "        print(f\"Processed chunk of size {len(chunk)}\")\n",
    "    \n",
    "    return pd.concat(encoded_chunks, ignore_index=True)\n",
    "\n",
    "# Process the file\n",
    "df_encoded = process_chunks('data/development_sample.csv')\n",
    "\n",
    "print(\"One-hot encoding completed.\")\n",
    "print(f\"Shape of encoded DataFrame: {df_encoded.shape}\")\n",
    "\n",
    "# Display the first few rows of the encoded DataFrame\n",
    "print(df_encoded.head())\n",
    "\n",
    "# Check the data types of the encoded columns\n",
    "print(df_encoded.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "469a5414f95c282d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-27T01:06:12.001677Z",
     "start_time": "2024-09-27T00:55:43.570546Z"
    }
   },
   "outputs": [],
   "source": [
    "df_encoded.to_csv('data/train_encoded_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932d32f61abc07a",
   "metadata": {},
   "source": [
    "***USE THE BELOW CODE FOR QUESTION 6~***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f44bf4fb5408634",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:52:20.892343Z",
     "start_time": "2024-10-16T20:51:54.320339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Feature Engineering\n",
    "df = pd.read_csv('data/train_encoded_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dbcdb1aec6587c92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:53:17.935355Z",
     "start_time": "2024-10-16T20:53:17.682827Z"
    }
   },
   "outputs": [],
   "source": [
    "target_df = df[['customer_ID', 'target']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "536ff412600491ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:53:36.334535Z",
     "start_time": "2024-10-16T20:53:36.329295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_df['target'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e2ad17f4f50b6e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:54:04.426397Z",
     "start_time": "2024-10-16T20:54:02.525589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>S_2</th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1.0</th>\n",
       "      <th>D_66_nan</th>\n",
       "      <th>D_68_0.0</th>\n",
       "      <th>D_68_1.0</th>\n",
       "      <th>D_68_2.0</th>\n",
       "      <th>D_68_3.0</th>\n",
       "      <th>D_68_4.0</th>\n",
       "      <th>D_68_5.0</th>\n",
       "      <th>D_68_6.0</th>\n",
       "      <th>D_68_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>0.374606</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>0.044293</td>\n",
       "      <td>1.008622</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.459235</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-04-22</td>\n",
       "      <td>0.414269</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.059667</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>0.413310</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-06-10</td>\n",
       "      <td>0.328983</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.115654</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.416112</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>0.496989</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.419864</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.098308</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID        S_2       P_2  \\\n",
       "0  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-03-11  0.374606   \n",
       "1  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-04-22  0.414269   \n",
       "2  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-05-12  0.413310   \n",
       "3  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-06-10  0.328983   \n",
       "4  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52... 2017-07-19  0.496989   \n",
       "\n",
       "       D_39       B_1       B_2       R_1       S_3      D_41       B_3  ...  \\\n",
       "0  0.033519  0.044293  1.008622  0.001470  0.459235  0.002339  0.006168  ...   \n",
       "1  0.002516  0.059667  0.123964  0.004374  0.434148  0.001405  0.052130  ...   \n",
       "2  0.003285  0.053418  0.304955  0.002316  0.415906  0.009388  0.048780  ...   \n",
       "3  0.038574  0.049463  0.115654  0.004654  0.416112  0.003223  0.081001  ...   \n",
       "4  0.005552  0.041452  0.133631  0.007363  0.419864  0.003393  0.098308  ...   \n",
       "\n",
       "   D_66_1.0  D_66_nan  D_68_0.0  D_68_1.0  D_68_2.0  D_68_3.0  D_68_4.0  \\\n",
       "0         0         1         0         0         0         0         0   \n",
       "1         0         1         0         0         0         0         0   \n",
       "2         0         1         0         0         1         0         0   \n",
       "3         0         1         0         0         1         0         0   \n",
       "4         0         1         0         0         1         0         0   \n",
       "\n",
       "   D_68_5.0  D_68_6.0  D_68_nan  \n",
       "0         0         0         1  \n",
       "1         0         0         1  \n",
       "2         0         0         0  \n",
       "3         0         0         0  \n",
       "4         0         0         0  \n",
       "\n",
       "[5 rows x 234 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['S_2'] = pd.to_datetime(df['S_2'])\n",
    "df = df.drop(columns=['target'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14fd115f80b05bd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:54:07.969320Z",
     "start_time": "2024-10-16T20:54:06.780068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Numerical Columns:\n",
    "numerical_columns = df.select_dtypes(include=[np.number]).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebdf49e0a42531ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T20:54:10.634636Z",
     "start_time": "2024-10-16T20:54:09.277219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2</th>\n",
       "      <th>D_39</th>\n",
       "      <th>B_1</th>\n",
       "      <th>B_2</th>\n",
       "      <th>R_1</th>\n",
       "      <th>S_3</th>\n",
       "      <th>D_41</th>\n",
       "      <th>B_3</th>\n",
       "      <th>D_42</th>\n",
       "      <th>D_43</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1.0</th>\n",
       "      <th>D_66_nan</th>\n",
       "      <th>D_68_0.0</th>\n",
       "      <th>D_68_1.0</th>\n",
       "      <th>D_68_2.0</th>\n",
       "      <th>D_68_3.0</th>\n",
       "      <th>D_68_4.0</th>\n",
       "      <th>D_68_5.0</th>\n",
       "      <th>D_68_6.0</th>\n",
       "      <th>D_68_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.374606</td>\n",
       "      <td>0.033519</td>\n",
       "      <td>0.044293</td>\n",
       "      <td>1.008622</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.459235</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.152932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.414269</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.059667</td>\n",
       "      <td>0.123964</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>0.434148</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.052130</td>\n",
       "      <td>0.154147</td>\n",
       "      <td>0.053474</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.413310</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>0.053418</td>\n",
       "      <td>0.304955</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.415906</td>\n",
       "      <td>0.009388</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.150513</td>\n",
       "      <td>0.035667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.328983</td>\n",
       "      <td>0.038574</td>\n",
       "      <td>0.049463</td>\n",
       "      <td>0.115654</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.416112</td>\n",
       "      <td>0.003223</td>\n",
       "      <td>0.081001</td>\n",
       "      <td>0.148605</td>\n",
       "      <td>0.166655</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.496989</td>\n",
       "      <td>0.005552</td>\n",
       "      <td>0.041452</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>0.007363</td>\n",
       "      <td>0.419864</td>\n",
       "      <td>0.003393</td>\n",
       "      <td>0.098308</td>\n",
       "      <td>0.147616</td>\n",
       "      <td>0.117810</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        P_2      D_39       B_1       B_2       R_1       S_3      D_41  \\\n",
       "0  0.374606  0.033519  0.044293  1.008622  0.001470  0.459235  0.002339   \n",
       "1  0.414269  0.002516  0.059667  0.123964  0.004374  0.434148  0.001405   \n",
       "2  0.413310  0.003285  0.053418  0.304955  0.002316  0.415906  0.009388   \n",
       "3  0.328983  0.038574  0.049463  0.115654  0.004654  0.416112  0.003223   \n",
       "4  0.496989  0.005552  0.041452  0.133631  0.007363  0.419864  0.003393   \n",
       "\n",
       "        B_3      D_42      D_43  ...  D_66_1.0  D_66_nan  D_68_0.0  D_68_1.0  \\\n",
       "0  0.006168  0.152932       NaN  ...         0         1         0         0   \n",
       "1  0.052130  0.154147  0.053474  ...         0         1         0         0   \n",
       "2  0.048780  0.150513  0.035667  ...         0         1         0         0   \n",
       "3  0.081001  0.148605  0.166655  ...         0         1         0         0   \n",
       "4  0.098308  0.147616  0.117810  ...         0         1         0         0   \n",
       "\n",
       "   D_68_2.0  D_68_3.0  D_68_4.0  D_68_5.0  D_68_6.0  D_68_nan  \n",
       "0         0         0         0         0         0         1  \n",
       "1         0         0         0         0         0         1  \n",
       "2         1         0         0         0         0         0  \n",
       "3         1         0         0         0         0         0  \n",
       "4         1         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[numerical_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd5165ccd9c4a6b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:02:20.408427Z",
     "start_time": "2024-10-16T21:02:13.215057Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4lz5rdmd4gn8qjywng68z9d00000gn/T/ipykernel_35128/3144716453.py:21: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_engineered_df = pd.merge(average_spend_3_months, average_spend_6_months, on='customer_ID', how='inner')\n",
      "/var/folders/jm/4lz5rdmd4gn8qjywng68z9d00000gn/T/ipykernel_35128/3144716453.py:22: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_engineered_df = pd.merge(feature_engineered_df, average_spend_9_months, on='customer_ID', how='inner')\n",
      "/var/folders/jm/4lz5rdmd4gn8qjywng68z9d00000gn/T/ipykernel_35128/3144716453.py:23: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_engineered_df = pd.merge(feature_engineered_df, average_spend_12_months, on='customer_ID', how='inner')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_mean_3</th>\n",
       "      <th>P_2_min_3</th>\n",
       "      <th>P_2_max_3</th>\n",
       "      <th>P_2_sum_3</th>\n",
       "      <th>D_39_mean_3</th>\n",
       "      <th>D_39_min_3</th>\n",
       "      <th>D_39_max_3</th>\n",
       "      <th>D_39_sum_3</th>\n",
       "      <th>B_1_mean_3</th>\n",
       "      <th>B_1_min_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_68_5.0_max_12</th>\n",
       "      <th>D_68_5.0_sum_12</th>\n",
       "      <th>D_68_6.0_mean_12</th>\n",
       "      <th>D_68_6.0_min_12</th>\n",
       "      <th>D_68_6.0_max_12</th>\n",
       "      <th>D_68_6.0_sum_12</th>\n",
       "      <th>D_68_nan_mean_12</th>\n",
       "      <th>D_68_nan_min_12</th>\n",
       "      <th>D_68_nan_max_12</th>\n",
       "      <th>D_68_nan_sum_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f5235f98b0f47c9d7d8d4</th>\n",
       "      <td>0.447801</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.477116</td>\n",
       "      <td>1.343404</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000445609ff2a39d2dd02484899affa5696210a95f6869f26390bd26eeb3b651</th>\n",
       "      <td>0.976846</td>\n",
       "      <td>0.974383</td>\n",
       "      <td>0.978897</td>\n",
       "      <td>2.930539</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004837f0c785928a29a6f83f70f4a1c54caec483a773ff4b5b317ac251abda0</th>\n",
       "      <td>0.638958</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.642295</td>\n",
       "      <td>1.916874</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.415254</td>\n",
       "      <td>0.685210</td>\n",
       "      <td>1.724002</td>\n",
       "      <td>0.431032</td>\n",
       "      <td>0.429032</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704029f989240c733b6d0</th>\n",
       "      <td>0.973429</td>\n",
       "      <td>0.963991</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>2.920287</td>\n",
       "      <td>0.268469</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00050d84c6d26e26cd2b18c3eed83d3130c270e2361470ff272f9409103d067f</th>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>1.006598</td>\n",
       "      <td>2.980056</td>\n",
       "      <td>0.092158</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.150871</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3712 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    P_2_mean_3  P_2_min_3  \\\n",
       "customer_ID                                                                 \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.447801   0.414444   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.976846   0.974383   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.638958   0.634894   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.973429   0.963991   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.993352   0.968914   \n",
       "\n",
       "                                                    P_2_max_3  P_2_sum_3  \\\n",
       "customer_ID                                                                \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...   0.477116   1.343404   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...   0.978897   2.930539   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...   0.642295   1.916874   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...   0.980221   2.920287   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...   1.006598   2.980056   \n",
       "\n",
       "                                                    D_39_mean_3  D_39_min_3  \\\n",
       "customer_ID                                                                   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...     0.014288    0.000467   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...     0.002024    0.001221   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...     0.574667    0.415254   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...     0.268469    0.009431   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...     0.092158    0.005624   \n",
       "\n",
       "                                                    D_39_max_3  D_39_sum_3  \\\n",
       "customer_ID                                                                  \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.035885    0.042865   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.002629    0.006072   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.685210    1.724002   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.470704    0.805407   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.150871    0.276473   \n",
       "\n",
       "                                                    B_1_mean_3  B_1_min_3  \\\n",
       "customer_ID                                                                 \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.069795   0.009413   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.008831   0.006584   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.431032   0.429032   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.023506   0.019392   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.040335   0.026597   \n",
       "\n",
       "                                                    ...  D_68_5.0_max_12  \\\n",
       "customer_ID                                         ...                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...  ...                0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...  ...                0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...  ...                1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...  ...                1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...  ...                0   \n",
       "\n",
       "                                                    D_68_5.0_sum_12  \\\n",
       "customer_ID                                                           \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...               12   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                7   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                0   \n",
       "\n",
       "                                                    D_68_6.0_mean_12  \\\n",
       "customer_ID                                                            \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...          0.000000   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...          1.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...          0.000000   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...          0.416667   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...          1.000000   \n",
       "\n",
       "                                                    D_68_6.0_min_12  \\\n",
       "customer_ID                                                           \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                1   \n",
       "\n",
       "                                                    D_68_6.0_max_12  \\\n",
       "customer_ID                                                           \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                1   \n",
       "\n",
       "                                                    D_68_6.0_sum_12  \\\n",
       "customer_ID                                                           \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...               12   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                5   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...               12   \n",
       "\n",
       "                                                    D_68_nan_mean_12  \\\n",
       "customer_ID                                                            \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...          0.083333   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...          0.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...          0.000000   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...          0.000000   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...          0.000000   \n",
       "\n",
       "                                                    D_68_nan_min_12  \\\n",
       "customer_ID                                                           \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                0   \n",
       "\n",
       "                                                    D_68_nan_max_12  \\\n",
       "customer_ID                                                           \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                0   \n",
       "\n",
       "                                                    D_68_nan_sum_12  \n",
       "customer_ID                                                          \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                1  \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                0  \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                0  \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                0  \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                0  \n",
       "\n",
       "[5 rows x 3712 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregation For all the numerical columns\n",
    "\n",
    "def calculate_numerical_statistics(df, time_period):\n",
    "    last_date = df['S_2'].max()\n",
    "    time_period_ago = last_date - pd.DateOffset(months=time_period)\n",
    "\n",
    "    data_last_time_period = df[(df['S_2'] > time_period_ago) & (df['S_2'] <= last_date)]\n",
    "\n",
    "    average_spend_last_time_period = data_last_time_period.groupby('customer_ID')[numerical_columns].agg(['mean', 'min', 'max', 'sum'])\n",
    "    average_spend_last_time_period.columns = [f'{col}_{agg}_{time_period}' for col, agg in average_spend_last_time_period.columns]\n",
    "\n",
    "    return average_spend_last_time_period\n",
    "\n",
    "\n",
    "# Calculate statistics for different time periods\n",
    "average_spend_3_months = calculate_numerical_statistics(df, 3)\n",
    "average_spend_6_months = calculate_numerical_statistics(df, 6)\n",
    "average_spend_9_months = calculate_numerical_statistics(df, 9)\n",
    "average_spend_12_months = calculate_numerical_statistics(df, 12)\n",
    "\n",
    "feature_engineered_df = pd.merge(average_spend_3_months, average_spend_6_months, on='customer_ID', how='inner')\n",
    "feature_engineered_df = pd.merge(feature_engineered_df, average_spend_9_months, on='customer_ID', how='inner')\n",
    "feature_engineered_df = pd.merge(feature_engineered_df, average_spend_12_months, on='customer_ID', how='inner')\n",
    "\n",
    "feature_engineered_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "675130b07df2c37a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:01:22.447137Z",
     "start_time": "2024-10-16T20:56:20.272485Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_engineered_df.to_csv('data/feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60b9d40a8b17755c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:02:24.150129Z",
     "start_time": "2024-10-16T21:02:24.146232Z"
    }
   },
   "outputs": [],
   "source": [
    "# Categorical Columns:\n",
    "one_hot_encoded_col = []\n",
    "for ftr in df.columns:\n",
    "    for column in categorical_columns:\n",
    "        if ftr.startswith(column):\n",
    "            one_hot_encoded_col.append(ftr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0daef8b550b1786",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:02:36.109782Z",
     "start_time": "2024-10-16T21:02:27.212500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B_30_0.0_response_rate_3</th>\n",
       "      <th>B_30_1.0_response_rate_3</th>\n",
       "      <th>B_30_2.0_response_rate_3</th>\n",
       "      <th>B_30_nan_response_rate_3</th>\n",
       "      <th>B_38_1.0_response_rate_3</th>\n",
       "      <th>B_38_2.0_response_rate_3</th>\n",
       "      <th>B_38_3.0_response_rate_3</th>\n",
       "      <th>B_38_4.0_response_rate_3</th>\n",
       "      <th>B_38_5.0_response_rate_3</th>\n",
       "      <th>B_38_6.0_response_rate_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1.0_ever_respond_12</th>\n",
       "      <th>D_66_nan_ever_respond_12</th>\n",
       "      <th>D_68_0.0_ever_respond_12</th>\n",
       "      <th>D_68_1.0_ever_respond_12</th>\n",
       "      <th>D_68_2.0_ever_respond_12</th>\n",
       "      <th>D_68_3.0_ever_respond_12</th>\n",
       "      <th>D_68_4.0_ever_respond_12</th>\n",
       "      <th>D_68_5.0_ever_respond_12</th>\n",
       "      <th>D_68_6.0_ever_respond_12</th>\n",
       "      <th>D_68_nan_ever_respond_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f5235f98b0f47c9d7d8d4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000445609ff2a39d2dd02484899affa5696210a95f6869f26390bd26eeb3b651</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004837f0c785928a29a6f83f70f4a1c54caec483a773ff4b5b317ac251abda0</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704029f989240c733b6d0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00050d84c6d26e26cd2b18c3eed83d3130c270e2361470ff272f9409103d067f</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 440 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    B_30_0.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                  0.666667   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                  1.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                  0.666667   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                  1.000000   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                  1.000000   \n",
       "\n",
       "                                                    B_30_1.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                  0.333333   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                  0.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                  0.333333   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                  0.000000   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                  0.000000   \n",
       "\n",
       "                                                    B_30_2.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    B_30_nan_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    B_38_1.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       1.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    B_38_2.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       1.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       1.0   \n",
       "\n",
       "                                                    B_38_3.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                  0.333333   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                  0.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                  0.000000   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                  0.000000   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                  0.000000   \n",
       "\n",
       "                                                    B_38_4.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    B_38_5.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                  0.666667   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                  0.000000   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                  0.000000   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                  0.000000   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                  0.000000   \n",
       "\n",
       "                                                    B_38_6.0_response_rate_3  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                       0.0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                       0.0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                       0.0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                       0.0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                       0.0   \n",
       "\n",
       "                                                    ...  \\\n",
       "customer_ID                                         ...   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...  ...   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...  ...   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...  ...   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...  ...   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...  ...   \n",
       "\n",
       "                                                    D_66_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_66_nan_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_0.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_2.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_3.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_4.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_5.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_6.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_nan_ever_respond_12  \n",
       "customer_ID                                                                   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1  \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0  \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0  \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0  \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0  \n",
       "\n",
       "[5 rows x 440 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature engineering for categorical values \n",
    "def calculate_categorical_statistics(df, time_period, one_hot_encoded_cols):\n",
    "    # Get the last date in the dataset\n",
    "    last_date = df['S_2'].max()\n",
    "    \n",
    "    # Calculate the date for the start of the time period\n",
    "    time_period_start = last_date - pd.DateOffset(months=time_period)\n",
    "    \n",
    "    # Filter the data for the specified time period\n",
    "    data_last_time_period = df[(df['S_2'] > time_period_start) & (df['S_2'] <= last_date)]\n",
    "    \n",
    "    # Calculate the positive response rates for each customer\n",
    "    positive_response_rates = data_last_time_period.groupby('customer_ID')[one_hot_encoded_cols].mean()\n",
    "    positive_response_rates.columns = [f'{col}_response_rate_{time_period}' for col in positive_response_rates.columns]\n",
    "    \n",
    "    # Calculate whether each customer ever responded positively\n",
    "    ever_responded = data_last_time_period.groupby('customer_ID')[one_hot_encoded_cols].any().astype(int)\n",
    "    ever_responded.columns = [f'{col}_ever_respond_{time_period}' for col in ever_responded.columns]\n",
    "    \n",
    "    # Merge the two DataFrames on 'customer_ID'\n",
    "    merged_df = pd.merge(positive_response_rates, ever_responded, on='customer_ID', how='inner')\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "cat_stats_3_months = calculate_categorical_statistics(df, 3, one_hot_encoded_col)\n",
    "cat_stats_6_months = calculate_categorical_statistics(df, 6, one_hot_encoded_col)\n",
    "cat_stats_9_months = calculate_categorical_statistics(df, 9, one_hot_encoded_col)\n",
    "cat_stats_12_months = calculate_categorical_statistics(df, 12, one_hot_encoded_col)\n",
    "\n",
    "final_categorical_df = pd.merge(cat_stats_3_months, cat_stats_6_months, on='customer_ID', how='inner')\n",
    "final_categorical_df = pd.merge(final_categorical_df, cat_stats_9_months, on='customer_ID', how='inner')\n",
    "final_feature_engineered_df = pd.merge(final_categorical_df, cat_stats_12_months, on='customer_ID', how='inner')\n",
    "\n",
    "final_feature_engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "539b6e96f5df1421",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:04:13.542705Z",
     "start_time": "2024-10-16T21:03:57.999613Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jm/4lz5rdmd4gn8qjywng68z9d00000gn/T/ipykernel_35128/1743165620.py:2: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  feature_engineered_df = pd.merge(feature_engineered_df, final_feature_engineered_df, on='customer_ID', how='inner')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_mean_3</th>\n",
       "      <th>P_2_min_3</th>\n",
       "      <th>P_2_max_3</th>\n",
       "      <th>P_2_sum_3</th>\n",
       "      <th>D_39_mean_3</th>\n",
       "      <th>D_39_min_3</th>\n",
       "      <th>D_39_max_3</th>\n",
       "      <th>D_39_sum_3</th>\n",
       "      <th>B_1_mean_3</th>\n",
       "      <th>B_1_min_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_66_1.0_ever_respond_12</th>\n",
       "      <th>D_66_nan_ever_respond_12</th>\n",
       "      <th>D_68_0.0_ever_respond_12</th>\n",
       "      <th>D_68_1.0_ever_respond_12</th>\n",
       "      <th>D_68_2.0_ever_respond_12</th>\n",
       "      <th>D_68_3.0_ever_respond_12</th>\n",
       "      <th>D_68_4.0_ever_respond_12</th>\n",
       "      <th>D_68_5.0_ever_respond_12</th>\n",
       "      <th>D_68_6.0_ever_respond_12</th>\n",
       "      <th>D_68_nan_ever_respond_12</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f5235f98b0f47c9d7d8d4</th>\n",
       "      <td>0.447801</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.477116</td>\n",
       "      <td>1.343404</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>0.009413</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000445609ff2a39d2dd02484899affa5696210a95f6869f26390bd26eeb3b651</th>\n",
       "      <td>0.976846</td>\n",
       "      <td>0.974383</td>\n",
       "      <td>0.978897</td>\n",
       "      <td>2.930539</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>0.006584</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004837f0c785928a29a6f83f70f4a1c54caec483a773ff4b5b317ac251abda0</th>\n",
       "      <td>0.638958</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.642295</td>\n",
       "      <td>1.916874</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.415254</td>\n",
       "      <td>0.685210</td>\n",
       "      <td>1.724002</td>\n",
       "      <td>0.431032</td>\n",
       "      <td>0.429032</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704029f989240c733b6d0</th>\n",
       "      <td>0.973429</td>\n",
       "      <td>0.963991</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>2.920287</td>\n",
       "      <td>0.268469</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.019392</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00050d84c6d26e26cd2b18c3eed83d3130c270e2361470ff272f9409103d067f</th>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>1.006598</td>\n",
       "      <td>2.980056</td>\n",
       "      <td>0.092158</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.150871</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>0.026597</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4152 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    P_2_mean_3  P_2_min_3  \\\n",
       "customer_ID                                                                 \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.447801   0.414444   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.976846   0.974383   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.638958   0.634894   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.973429   0.963991   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.993352   0.968914   \n",
       "\n",
       "                                                    P_2_max_3  P_2_sum_3  \\\n",
       "customer_ID                                                                \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...   0.477116   1.343404   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...   0.978897   2.930539   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...   0.642295   1.916874   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...   0.980221   2.920287   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...   1.006598   2.980056   \n",
       "\n",
       "                                                    D_39_mean_3  D_39_min_3  \\\n",
       "customer_ID                                                                   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...     0.014288    0.000467   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...     0.002024    0.001221   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...     0.574667    0.415254   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...     0.268469    0.009431   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...     0.092158    0.005624   \n",
       "\n",
       "                                                    D_39_max_3  D_39_sum_3  \\\n",
       "customer_ID                                                                  \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.035885    0.042865   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.002629    0.006072   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.685210    1.724002   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.470704    0.805407   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.150871    0.276473   \n",
       "\n",
       "                                                    B_1_mean_3  B_1_min_3  \\\n",
       "customer_ID                                                                 \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...    0.069795   0.009413   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...    0.008831   0.006584   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...    0.431032   0.429032   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...    0.023506   0.019392   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...    0.040335   0.026597   \n",
       "\n",
       "                                                    ...  \\\n",
       "customer_ID                                         ...   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...  ...   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...  ...   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...  ...   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...  ...   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...  ...   \n",
       "\n",
       "                                                    D_66_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_66_nan_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_0.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_1.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_2.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_3.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_4.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_5.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         1   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0   \n",
       "\n",
       "                                                    D_68_6.0_ever_respond_12  \\\n",
       "customer_ID                                                                    \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         0   \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         1   \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0   \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         1   \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         1   \n",
       "\n",
       "                                                    D_68_nan_ever_respond_12  \n",
       "customer_ID                                                                   \n",
       "000098081fde4fd64bc4d503a5d6f86a0aedc425c96f523...                         1  \n",
       "000445609ff2a39d2dd02484899affa5696210a95f6869f...                         0  \n",
       "0004837f0c785928a29a6f83f70f4a1c54caec483a773ff...                         0  \n",
       "0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab7040...                         0  \n",
       "00050d84c6d26e26cd2b18c3eed83d3130c270e2361470f...                         0  \n",
       "\n",
       "[5 rows x 4152 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Integrate feature engineered data\n",
    "feature_engineered_df = pd.merge(feature_engineered_df, final_feature_engineered_df, on='customer_ID', how='inner')\n",
    "feature_engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b549347c347c3945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T05:53:10.177943Z",
     "start_time": "2024-10-16T05:52:55.362331Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_engineered_df = pd.read_csv('data/feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da790f45f933cf02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:05:37.778667Z",
     "start_time": "2024-10-16T21:05:37.758957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean_3</th>\n",
       "      <th>P_2_min_3</th>\n",
       "      <th>P_2_max_3</th>\n",
       "      <th>P_2_sum_3</th>\n",
       "      <th>D_39_mean_3</th>\n",
       "      <th>D_39_min_3</th>\n",
       "      <th>D_39_max_3</th>\n",
       "      <th>D_39_sum_3</th>\n",
       "      <th>B_1_mean_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_68_5.0_max_12</th>\n",
       "      <th>D_68_5.0_sum_12</th>\n",
       "      <th>D_68_6.0_mean_12</th>\n",
       "      <th>D_68_6.0_min_12</th>\n",
       "      <th>D_68_6.0_max_12</th>\n",
       "      <th>D_68_6.0_sum_12</th>\n",
       "      <th>D_68_nan_mean_12</th>\n",
       "      <th>D_68_nan_min_12</th>\n",
       "      <th>D_68_nan_max_12</th>\n",
       "      <th>D_68_nan_sum_12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>0.447801</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.477116</td>\n",
       "      <td>1.343404</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000445609ff2a39d2dd02484899affa5696210a95f6869...</td>\n",
       "      <td>0.976846</td>\n",
       "      <td>0.974383</td>\n",
       "      <td>0.978897</td>\n",
       "      <td>2.930539</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004837f0c785928a29a6f83f70f4a1c54caec483a773f...</td>\n",
       "      <td>0.638958</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.642295</td>\n",
       "      <td>1.916874</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.415254</td>\n",
       "      <td>0.685210</td>\n",
       "      <td>1.724002</td>\n",
       "      <td>0.431032</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704...</td>\n",
       "      <td>0.973429</td>\n",
       "      <td>0.963991</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>2.920287</td>\n",
       "      <td>0.268469</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00050d84c6d26e26cd2b18c3eed83d3130c270e2361470...</td>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>1.006598</td>\n",
       "      <td>2.980056</td>\n",
       "      <td>0.092158</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.150871</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3713 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean_3  P_2_min_3  \\\n",
       "0  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...    0.447801   0.414444   \n",
       "1  000445609ff2a39d2dd02484899affa5696210a95f6869...    0.976846   0.974383   \n",
       "2  0004837f0c785928a29a6f83f70f4a1c54caec483a773f...    0.638958   0.634894   \n",
       "3  0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704...    0.973429   0.963991   \n",
       "4  00050d84c6d26e26cd2b18c3eed83d3130c270e2361470...    0.993352   0.968914   \n",
       "\n",
       "   P_2_max_3  P_2_sum_3  D_39_mean_3  D_39_min_3  D_39_max_3  D_39_sum_3  \\\n",
       "0   0.477116   1.343404     0.014288    0.000467    0.035885    0.042865   \n",
       "1   0.978897   2.930539     0.002024    0.001221    0.002629    0.006072   \n",
       "2   0.642295   1.916874     0.574667    0.415254    0.685210    1.724002   \n",
       "3   0.980221   2.920287     0.268469    0.009431    0.470704    0.805407   \n",
       "4   1.006598   2.980056     0.092158    0.005624    0.150871    0.276473   \n",
       "\n",
       "   B_1_mean_3  ...  D_68_5.0_max_12  D_68_5.0_sum_12  D_68_6.0_mean_12  \\\n",
       "0    0.069795  ...                0                0          0.000000   \n",
       "1    0.008831  ...                0                0          1.000000   \n",
       "2    0.431032  ...                1               12          0.000000   \n",
       "3    0.023506  ...                1                7          0.416667   \n",
       "4    0.040335  ...                0                0          1.000000   \n",
       "\n",
       "   D_68_6.0_min_12  D_68_6.0_max_12  D_68_6.0_sum_12  D_68_nan_mean_12  \\\n",
       "0                0                0                0          0.083333   \n",
       "1                1                1               12          0.000000   \n",
       "2                0                0                0          0.000000   \n",
       "3                0                1                5          0.000000   \n",
       "4                1                1               12          0.000000   \n",
       "\n",
       "   D_68_nan_min_12  D_68_nan_max_12  D_68_nan_sum_12  \n",
       "0                0                1                1  \n",
       "1                0                0                0  \n",
       "2                0                0                0  \n",
       "3                0                0                0  \n",
       "4                0                0                0  \n",
       "\n",
       "[5 rows x 3713 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c745f813326df69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:06:42.209102Z",
     "start_time": "2024-10-16T21:06:29.087843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_ID</th>\n",
       "      <th>P_2_mean_3</th>\n",
       "      <th>P_2_min_3</th>\n",
       "      <th>P_2_max_3</th>\n",
       "      <th>P_2_sum_3</th>\n",
       "      <th>D_39_mean_3</th>\n",
       "      <th>D_39_min_3</th>\n",
       "      <th>D_39_max_3</th>\n",
       "      <th>D_39_sum_3</th>\n",
       "      <th>B_1_mean_3</th>\n",
       "      <th>...</th>\n",
       "      <th>D_68_5.0_sum_12</th>\n",
       "      <th>D_68_6.0_mean_12</th>\n",
       "      <th>D_68_6.0_min_12</th>\n",
       "      <th>D_68_6.0_max_12</th>\n",
       "      <th>D_68_6.0_sum_12</th>\n",
       "      <th>D_68_nan_mean_12</th>\n",
       "      <th>D_68_nan_min_12</th>\n",
       "      <th>D_68_nan_max_12</th>\n",
       "      <th>D_68_nan_sum_12</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...</td>\n",
       "      <td>0.447801</td>\n",
       "      <td>0.414444</td>\n",
       "      <td>0.477116</td>\n",
       "      <td>1.343404</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>0.069795</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000445609ff2a39d2dd02484899affa5696210a95f6869...</td>\n",
       "      <td>0.976846</td>\n",
       "      <td>0.974383</td>\n",
       "      <td>0.978897</td>\n",
       "      <td>2.930539</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.006072</td>\n",
       "      <td>0.008831</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0004837f0c785928a29a6f83f70f4a1c54caec483a773f...</td>\n",
       "      <td>0.638958</td>\n",
       "      <td>0.634894</td>\n",
       "      <td>0.642295</td>\n",
       "      <td>1.916874</td>\n",
       "      <td>0.574667</td>\n",
       "      <td>0.415254</td>\n",
       "      <td>0.685210</td>\n",
       "      <td>1.724002</td>\n",
       "      <td>0.431032</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704...</td>\n",
       "      <td>0.973429</td>\n",
       "      <td>0.963991</td>\n",
       "      <td>0.980221</td>\n",
       "      <td>2.920287</td>\n",
       "      <td>0.268469</td>\n",
       "      <td>0.009431</td>\n",
       "      <td>0.470704</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00050d84c6d26e26cd2b18c3eed83d3130c270e2361470...</td>\n",
       "      <td>0.993352</td>\n",
       "      <td>0.968914</td>\n",
       "      <td>1.006598</td>\n",
       "      <td>2.980056</td>\n",
       "      <td>0.092158</td>\n",
       "      <td>0.005624</td>\n",
       "      <td>0.150871</td>\n",
       "      <td>0.276473</td>\n",
       "      <td>0.040335</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         customer_ID  P_2_mean_3  P_2_min_3  \\\n",
       "0  000098081fde4fd64bc4d503a5d6f86a0aedc425c96f52...    0.447801   0.414444   \n",
       "1  000445609ff2a39d2dd02484899affa5696210a95f6869...    0.976846   0.974383   \n",
       "2  0004837f0c785928a29a6f83f70f4a1c54caec483a773f...    0.638958   0.634894   \n",
       "3  0004ec03ca1ab2adb9aa260c61ba5dce8185e19d3ab704...    0.973429   0.963991   \n",
       "4  00050d84c6d26e26cd2b18c3eed83d3130c270e2361470...    0.993352   0.968914   \n",
       "\n",
       "   P_2_max_3  P_2_sum_3  D_39_mean_3  D_39_min_3  D_39_max_3  D_39_sum_3  \\\n",
       "0   0.477116   1.343404     0.014288    0.000467    0.035885    0.042865   \n",
       "1   0.978897   2.930539     0.002024    0.001221    0.002629    0.006072   \n",
       "2   0.642295   1.916874     0.574667    0.415254    0.685210    1.724002   \n",
       "3   0.980221   2.920287     0.268469    0.009431    0.470704    0.805407   \n",
       "4   1.006598   2.980056     0.092158    0.005624    0.150871    0.276473   \n",
       "\n",
       "   B_1_mean_3  ...  D_68_5.0_sum_12  D_68_6.0_mean_12  D_68_6.0_min_12  \\\n",
       "0    0.069795  ...                0          0.000000                0   \n",
       "1    0.008831  ...                0          1.000000                1   \n",
       "2    0.431032  ...               12          0.000000                0   \n",
       "3    0.023506  ...                7          0.416667                0   \n",
       "4    0.040335  ...                0          1.000000                1   \n",
       "\n",
       "   D_68_6.0_max_12  D_68_6.0_sum_12  D_68_nan_mean_12  D_68_nan_min_12  \\\n",
       "0                0                0          0.083333                0   \n",
       "1                1               12          0.000000                0   \n",
       "2                0                0          0.000000                0   \n",
       "3                1                5          0.000000                0   \n",
       "4                1               12          0.000000                0   \n",
       "\n",
       "   D_68_nan_max_12  D_68_nan_sum_12  target  \n",
       "0                1                1       0  \n",
       "1                0                0       0  \n",
       "2                0                0       0  \n",
       "3                0                0       0  \n",
       "4                0                0       0  \n",
       "\n",
       "[5 rows x 3714 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_engineered_df = pd.merge(feature_engineered_df, target_df, on='customer_ID', how='inner')\n",
    "feature_engineered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5371bef5f38fa9d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:13:43.821681Z",
     "start_time": "2024-10-16T21:08:32.590005Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_engineered_df.to_csv('data/feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638036cf2c73ef26",
   "metadata": {},
   "source": [
    "***USE THE BELOW CODE FOR QUESTION 7~***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfff947474849703",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T20:47:58.671918Z",
     "start_time": "2024-10-17T20:47:03.599780Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/feature_engineered_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fd6d2f86e5d73a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-17T20:48:24.575737Z",
     "start_time": "2024-10-17T20:48:18.294350Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 7; Train-test split\n",
    "# Use a random seed of 42 for the split.\n",
    "# Split the data into features and target\n",
    "X = df.drop(columns=['customer_ID', 'target'])\n",
    "y = df['target']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test1, X_test2, y_test1, y_test2 = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d49d18985dbe1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:21:17.237885Z",
     "start_time": "2024-10-16T21:16:23.454681Z"
    }
   },
   "outputs": [],
   "source": [
    "# save train and test data as csv\n",
    "X_train.to_csv('data/X_train.csv', index=False)\n",
    "y_train.to_csv('data/y_train.csv', index=False)\n",
    "X_test1.to_csv('data/X_test1.csv', index=False)\n",
    "y_test1.to_csv('data/y_test1.csv', index=False)\n",
    "X_test2.to_csv('data/X_test2.csv', index=False)\n",
    "y_test2.to_csv('data/y_test2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b0f5c0061a92a10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:03:59.299797Z",
     "start_time": "2024-10-17T23:59:39.272837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importance:\n",
      "[0.00024673 0.1788193  0.0194177  ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Calculate feature importance using XGBoost\n",
    "\n",
    "# Load the training data\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Fit the model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# # Plot the feature importance\n",
    "# plot_importance(xgb_model)\n",
    "\n",
    "# Save the feature importance\n",
    "feature_importance = xgb_model.feature_importances_\n",
    "np.save('feature_importance.npy', feature_importance)\n",
    "\n",
    "# Display the feature importance\n",
    "print(\"Feature importance:\")\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81d4d014c83802d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:04.170132Z",
     "start_time": "2024-10-18T00:04:04.151639Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importance\n",
    "})\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdd45b3552bdb021",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:25:43.033358Z",
     "start_time": "2024-10-16T21:25:43.017728Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_df.to_csv('data/feature_importance.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8daf652f7f626637",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:09.527028Z",
     "start_time": "2024-10-18T00:04:09.514850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.178819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.019418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R_1_mean_3</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B_1_min_3</td>\n",
       "      <td>0.017141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.011456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B_2_min_3</td>\n",
       "      <td>0.008486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>B_9_max_3</td>\n",
       "      <td>0.005448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B_2_sum_3</td>\n",
       "      <td>0.005181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature  Importance\n",
       "1   P_2_mean_3    0.178819\n",
       "2    P_2_min_3    0.019418\n",
       "17  R_1_mean_3    0.018642\n",
       "10   B_1_min_3    0.017141\n",
       "9   B_1_mean_3    0.011456\n",
       "14   B_2_min_3    0.008486\n",
       "99   B_9_max_3    0.005448\n",
       "16   B_2_sum_3    0.005181"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features = feature_importance_df[feature_importance_df['Importance'] > 0.005]\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "447e6db5f397fb02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:19.788895Z",
     "start_time": "2024-10-18T00:04:19.436591Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.178819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.019418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R_1_mean_3</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B_1_min_3</td>\n",
       "      <td>0.017141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.011456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>D_68_4.0_max_3</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2629</th>\n",
       "      <td>D_116_1.0_mean_9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1856</th>\n",
       "      <td>D_68_nan_sum_6</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>D_116_1.0_max_9</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3712</th>\n",
       "      <td>D_68_nan_sum_12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3713 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Importance\n",
       "1           P_2_mean_3    0.178819\n",
       "2            P_2_min_3    0.019418\n",
       "17          R_1_mean_3    0.018642\n",
       "10           B_1_min_3    0.017141\n",
       "9           B_1_mean_3    0.011456\n",
       "...                ...         ...\n",
       "915     D_68_4.0_max_3    0.000000\n",
       "2629  D_116_1.0_mean_9    0.000000\n",
       "1856    D_68_nan_sum_6    0.000000\n",
       "2631   D_116_1.0_max_9    0.000000\n",
       "3712   D_68_nan_sum_12    0.000000\n",
       "\n",
       "[3713 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply only importamt features\n",
    "# Run default XBG\n",
    "X_train_important = X_train[important_features['Feature']]\n",
    "\n",
    "xgb_model.fit(X_train_important, y_train)\n",
    "\n",
    "feature_importance_important = xgb_model.feature_importances_\n",
    "\n",
    "feature_importance_important_df = pd.DataFrame({\n",
    "    'Feature': X_train_important.columns,\n",
    "    'Importance': feature_importance_important\n",
    "})\n",
    "feature_importance_important_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_important_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf116e78f9e8177",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:24.950028Z",
     "start_time": "2024-10-18T00:04:24.940353Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_importance_important_df = feature_importance_important_df[feature_importance_important_df['Importance'] > 0.005]\n",
    "feature_importance_important_df.to_csv('data/feature_importance_important.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6dd435893c5ee08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:04:30.247069Z",
     "start_time": "2024-10-18T00:04:30.240288Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.178819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.019418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R_1_mean_3</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B_1_min_3</td>\n",
       "      <td>0.017141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.011456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B_2_min_3</td>\n",
       "      <td>0.008486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>B_9_max_3</td>\n",
       "      <td>0.005448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B_2_sum_3</td>\n",
       "      <td>0.005181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature  Importance\n",
       "1   P_2_mean_3    0.178819\n",
       "2    P_2_min_3    0.019418\n",
       "17  R_1_mean_3    0.018642\n",
       "10   B_1_min_3    0.017141\n",
       "9   B_1_mean_3    0.011456\n",
       "14   B_2_min_3    0.008486\n",
       "99   B_9_max_3    0.005448\n",
       "16   B_2_sum_3    0.005181"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_important_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f231ce461be088b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:11:16.678902Z",
     "start_time": "2024-10-18T00:04:50.388703Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run XGB applying parameters 300 trees, 0.5 as learning rate, maximum depth of trees is 4, uses 50% of observation to build each tree, uses 50% of features to build each tree, and assigns a weight of 5 to default observations. \n",
    "# Save the model as 'xgb_model_important_features'\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model_important_features = xgb.XGBClassifier(n_estimators=300, learning_rate=0.5, max_depth=4, subsample=0.5, colsample_bytree=0.5, scale_pos_weight=5, random_state=71)\n",
    "\n",
    "# Fit the model\n",
    "xgb_model_important_features.fit(X_train, y_train)\n",
    "\n",
    "# Calculate the feature importance\n",
    "feature_importance_parameter_model = xgb_model_important_features.feature_importances_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a1f993cf834ec5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:11:25.405482Z",
     "start_time": "2024-10-18T00:11:25.386963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.050226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.017277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B_2_sum_3</td>\n",
       "      <td>0.016865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P_2_sum_3</td>\n",
       "      <td>0.013772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>B_7_max_3</td>\n",
       "      <td>0.011873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.010779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>D_44_mean_3</td>\n",
       "      <td>0.007088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B_2_min_3</td>\n",
       "      <td>0.006548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Importance\n",
       "2     P_2_min_3    0.050226\n",
       "1    P_2_mean_3    0.017277\n",
       "16    B_2_sum_3    0.016865\n",
       "4     P_2_sum_3    0.013772\n",
       "83    B_7_max_3    0.011873\n",
       "9    B_1_mean_3    0.010779\n",
       "41  D_44_mean_3    0.007088\n",
       "14    B_2_min_3    0.006548"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the feature importance\n",
    "feature_importance_parameter_model_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': feature_importance_parameter_model\n",
    "})\n",
    "feature_importance_parameter_model_df = feature_importance_parameter_model_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "feature_importance_parameter_model_df = feature_importance_parameter_model_df[feature_importance_parameter_model_df['Importance'] > 0.005]\n",
    "\n",
    "feature_importance_parameter_model_df.to_csv('data/feature_importance_parameter_model.csv', index=False)\n",
    "\n",
    "feature_importance_parameter_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2a5b99c8cdd53db7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:47:16.056268Z",
     "start_time": "2024-10-18T00:47:16.050964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load feature importance from the first model\n",
    "feature_importance_important_df = pd.read_csv('data/feature_importance_important.csv')\n",
    "feature_importance_important_df['Model'] = 'Model 1'\n",
    "\n",
    "# Load feature importance from the second model\n",
    "feature_importance_parameter_model_df = pd.read_csv('data/feature_importance_parameter_model.csv')\n",
    "feature_importance_parameter_model_df['Model'] = 'Model 2'\n",
    "feature_importance_concat_df = pd.concat([feature_importance_parameter_model_df, feature_importance_important_df])\n",
    "feature_importance_concat_df.to_csv('data/feature_importance_parameter_model.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97936b1e9d3e1199",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:47:24.037141Z",
     "start_time": "2024-10-18T00:47:24.031477Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "      <th>Model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.050226</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.017277</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B_2_sum_3</td>\n",
       "      <td>0.016865</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P_2_sum_3</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_7_max_3</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>D_44_mean_3</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B_2_min_3</td>\n",
       "      <td>0.006548</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R_1_mean_3</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B_1_min_3</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B_9_max_3</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>Model 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P_2_mean_3</td>\n",
       "      <td>0.178819</td>\n",
       "      <td>Model 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P_2_min_3</td>\n",
       "      <td>0.019418</td>\n",
       "      <td>Model 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R_1_mean_3</td>\n",
       "      <td>0.018642</td>\n",
       "      <td>Model 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B_1_min_3</td>\n",
       "      <td>0.017141</td>\n",
       "      <td>Model 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B_1_mean_3</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>Model 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B_2_min_3</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>Model 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B_9_max_3</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>Model 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B_2_sum_3</td>\n",
       "      <td>0.005181</td>\n",
       "      <td>Model 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature  Importance    Model\n",
       "0     P_2_min_3    0.050226  Model 2\n",
       "1    P_2_mean_3    0.017277  Model 2\n",
       "2     B_2_sum_3    0.016865  Model 2\n",
       "3     P_2_sum_3    0.013772  Model 2\n",
       "4     B_7_max_3    0.011873  Model 2\n",
       "5    B_1_mean_3    0.010779  Model 2\n",
       "6   D_44_mean_3    0.007088  Model 2\n",
       "7     B_2_min_3    0.006548  Model 2\n",
       "8    R_1_mean_3    0.018642  Model 2\n",
       "9     B_1_min_3    0.017141  Model 2\n",
       "10    B_9_max_3    0.005448  Model 2\n",
       "0    P_2_mean_3    0.178819  Model 1\n",
       "1     P_2_min_3    0.019418  Model 1\n",
       "2    R_1_mean_3    0.018642  Model 1\n",
       "3     B_1_min_3    0.017141  Model 1\n",
       "4    B_1_mean_3    0.011456  Model 1\n",
       "5     B_2_min_3    0.008486  Model 1\n",
       "6     B_9_max_3    0.005448  Model 1\n",
       "7     B_2_sum_3    0.005181  Model 1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_concat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c140c32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Sort the combined DataFrame by importance values in descending order\n",
    "feature_importance_concat_df.sort_values(by='Importance', ascending=False, inplace=True)\n",
    "\n",
    "# Filter the top features\n",
    "top_features = feature_importance_concat_df.head(60)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Plot horizontal bars\n",
    "bars = plt.barh(range(len(top_features)), top_features['Importance'], color='skyblue')\n",
    "\n",
    "# Add labels for model name and percentage\n",
    "for i, bar in enumerate(bars):\n",
    "    feature = top_features.iloc[i]['Feature']\n",
    "    importance = top_features.iloc[i]['Importance']\n",
    "    model = top_features.iloc[i]['Model']\n",
    "    if importance > 0.005:\n",
    "        if model == 'Model 1':\n",
    "            bar.set_color('red')\n",
    "        else:\n",
    "            bar.set_color('blue')\n",
    "    plt.text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2, f'{model}: {feature} ({importance:.2%})', va='center', ha='left', fontsize=10, color='black', weight='bold')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Feature Importance Percentage')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Top Feature Importance Comparison between Model 1 and Model 2')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the highest importance at the top\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ea14694b9c7f1ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:48:19.870214Z",
     "start_time": "2024-10-18T00:47:28.844103Z"
    }
   },
   "outputs": [],
   "source": [
    "### step 9: When to resume training process\n",
    "# Load the training data, applying important features calculated by step 8\n",
    "# Load the training data, applying important features calculated by step 8\n",
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "# feature_importance_parameter_model_df = pd.read_csv('output/feature_importance_parameter_model.csv')\n",
    "X_train = X_train[feature_importance_concat_df['Feature']]\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "\n",
    "X_test1 = pd.read_csv('data/X_test1.csv')\n",
    "X_test1 = X_test1[feature_importance_concat_df['Feature']]\n",
    "y_test1 = pd.read_csv('data/y_test1.csv')\n",
    "\n",
    "X_test2 = pd.read_csv('data/X_test2.csv')\n",
    "X_test2 = X_test2[feature_importance_concat_df['Feature']]\n",
    "y_test2 = pd.read_csv('data/y_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d63cf2936518f9ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:13:23.451302Z",
     "start_time": "2024-10-18T00:13:23.397450Z"
    }
   },
   "outputs": [],
   "source": [
    "Grid_Search_Results = pd.DataFrame(columns = [\"Number of Trees\", \"Learning Rate (LR)\", 'Subsample', '% Features', 'Weight of Default',\"AUC Train\", \"AUC Test 1\", \"AUC Test 2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a2c2270795e04d26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:51:13.547161Z",
     "start_time": "2024-10-18T00:49:37.837482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete iteration: 1\n",
      "complete iteration: 2\n",
      "complete iteration: 3\n",
      "complete iteration: 4\n",
      "complete iteration: 5\n",
      "complete iteration: 6\n",
      "complete iteration: 7\n",
      "complete iteration: 8\n",
      "complete iteration: 9\n",
      "complete iteration: 10\n",
      "complete iteration: 11\n",
      "complete iteration: 12\n",
      "complete iteration: 13\n",
      "complete iteration: 14\n",
      "complete iteration: 15\n",
      "complete iteration: 16\n",
      "complete iteration: 17\n",
      "complete iteration: 18\n",
      "complete iteration: 19\n",
      "complete iteration: 20\n",
      "complete iteration: 21\n",
      "complete iteration: 22\n",
      "complete iteration: 23\n",
      "complete iteration: 24\n",
      "complete iteration: 25\n",
      "complete iteration: 26\n",
      "complete iteration: 27\n",
      "complete iteration: 28\n",
      "complete iteration: 29\n",
      "complete iteration: 30\n",
      "complete iteration: 31\n",
      "complete iteration: 32\n",
      "complete iteration: 33\n",
      "complete iteration: 34\n",
      "complete iteration: 35\n",
      "complete iteration: 36\n",
      "complete iteration: 37\n",
      "complete iteration: 38\n",
      "complete iteration: 39\n",
      "complete iteration: 40\n",
      "complete iteration: 41\n",
      "complete iteration: 42\n",
      "complete iteration: 43\n",
      "complete iteration: 44\n",
      "complete iteration: 45\n",
      "complete iteration: 46\n",
      "complete iteration: 47\n",
      "complete iteration: 48\n",
      "complete iteration: 49\n",
      "complete iteration: 50\n",
      "complete iteration: 51\n",
      "complete iteration: 52\n",
      "complete iteration: 53\n",
      "complete iteration: 54\n",
      "complete iteration: 55\n",
      "complete iteration: 56\n",
      "complete iteration: 57\n",
      "complete iteration: 58\n",
      "complete iteration: 59\n",
      "complete iteration: 60\n",
      "complete iteration: 61\n",
      "complete iteration: 62\n",
      "complete iteration: 63\n",
      "complete iteration: 64\n",
      "complete iteration: 65\n",
      "complete iteration: 66\n",
      "complete iteration: 67\n",
      "complete iteration: 68\n",
      "complete iteration: 69\n",
      "complete iteration: 70\n",
      "complete iteration: 71\n",
      "complete iteration: 72\n",
      "Grid search completed\n"
     ]
    }
   ],
   "source": [
    "Counter = 0\n",
    "for n_trees in [50, 100, 300]:\n",
    "    for lr in [0.01, 0.1]:\n",
    "        for subsample in [0.5, 0.8]:\n",
    "            for colsample in [0.5, 1.0]:\n",
    "                for weight in [1, 5, 10]:\n",
    "                    xgb_instance = xgb.XGBClassifier(n_estimators= n_trees, learning_rate = lr,subsample=subsample, colsample_bytree=colsample, scale_pos_weight=weight)                    \n",
    "                    model = xgb_instance.fit(X_train, y_train)\n",
    "                    \n",
    "                    Grid_Search_Results.loc[Counter,\"Number of Trees\"] = n_trees\n",
    "                    Grid_Search_Results.loc[Counter,\"Learning Rate (LR)\"] = lr\n",
    "                    Grid_Search_Results.loc[Counter,\"Subsample\"] = subsample\n",
    "                    Grid_Search_Results.loc[Counter,\"% Features\"] = colsample\n",
    "                    Grid_Search_Results.loc[Counter,\"Weight of Default\"] = weight\n",
    "                    \n",
    "                    Grid_Search_Results.loc[Counter,\"AUC Train\"] = roc_auc_score(y_train, model.predict_proba(X_train)[:,1])\n",
    "                    Grid_Search_Results.loc[Counter,\"AUC Test 1\"] = roc_auc_score(y_test1, model.predict_proba(X_test1)[:,1])\n",
    "                    Grid_Search_Results.loc[Counter,\"AUC Test 2\"] = roc_auc_score(y_test2, model.predict_proba(X_test2)[:,1])\n",
    "\n",
    "                    Counter += 1\n",
    "                    print('complete iteration:', Counter)\n",
    "print('Grid search completed')\n",
    "Grid_Search_Results.to_csv(\"output/Grid_Search_Results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc53b147cb768f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:52:38.080610Z",
     "start_time": "2024-10-18T00:52:38.072423Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Trees</th>\n",
       "      <th>Learning Rate (LR)</th>\n",
       "      <th>Subsample</th>\n",
       "      <th>% Features</th>\n",
       "      <th>Weight of Default</th>\n",
       "      <th>AUC Train</th>\n",
       "      <th>AUC Test 1</th>\n",
       "      <th>AUC Test 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.941526</td>\n",
       "      <td>0.941043</td>\n",
       "      <td>0.937271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.941145</td>\n",
       "      <td>0.940185</td>\n",
       "      <td>0.936393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.94094</td>\n",
       "      <td>0.94013</td>\n",
       "      <td>0.936397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942165</td>\n",
       "      <td>0.940485</td>\n",
       "      <td>0.937402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.941428</td>\n",
       "      <td>0.939849</td>\n",
       "      <td>0.93666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.967662</td>\n",
       "      <td>0.940046</td>\n",
       "      <td>0.938027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10</td>\n",
       "      <td>0.965693</td>\n",
       "      <td>0.939541</td>\n",
       "      <td>0.937475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.972227</td>\n",
       "      <td>0.940087</td>\n",
       "      <td>0.936562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.971671</td>\n",
       "      <td>0.939683</td>\n",
       "      <td>0.93733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.969709</td>\n",
       "      <td>0.939487</td>\n",
       "      <td>0.936501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>72 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Trees Learning Rate (LR) Subsample % Features Weight of Default  \\\n",
       "0               50               0.01       0.5        0.5                 1   \n",
       "1               50               0.01       0.5        0.5                 5   \n",
       "2               50               0.01       0.5        0.5                10   \n",
       "3               50               0.01       0.5        1.0                 1   \n",
       "4               50               0.01       0.5        1.0                 5   \n",
       "..             ...                ...       ...        ...               ...   \n",
       "67             300                0.1       0.8        0.5                 5   \n",
       "68             300                0.1       0.8        0.5                10   \n",
       "69             300                0.1       0.8        1.0                 1   \n",
       "70             300                0.1       0.8        1.0                 5   \n",
       "71             300                0.1       0.8        1.0                10   \n",
       "\n",
       "   AUC Train AUC Test 1 AUC Test 2  \n",
       "0   0.941526   0.941043   0.937271  \n",
       "1   0.941145   0.940185   0.936393  \n",
       "2    0.94094    0.94013   0.936397  \n",
       "3   0.942165   0.940485   0.937402  \n",
       "4   0.941428   0.939849    0.93666  \n",
       "..       ...        ...        ...  \n",
       "67  0.967662   0.940046   0.938027  \n",
       "68  0.965693   0.939541   0.937475  \n",
       "69  0.972227   0.940087   0.936562  \n",
       "70  0.971671   0.939683    0.93733  \n",
       "71  0.969709   0.939487   0.936501  \n",
       "\n",
       "[72 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid_Search_Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cb1b3f587401a6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:52:05.882235Z",
     "start_time": "2024-10-18T00:52:05.874442Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "reduction operation 'argmax' not allowed for this dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m best_model \u001b[38;5;241m=\u001b[39m Grid_Search_Results[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC Train\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC Test 1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAUC Test 2\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39midxmax()\n\u001b[1;32m      2\u001b[0m best_parameters \u001b[38;5;241m=\u001b[39m Grid_Search_Results\u001b[38;5;241m.\u001b[39miloc[best_model, :\u001b[38;5;241m5\u001b[39m]\u001b[38;5;241m.\u001b[39mto_dict()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/series.py:2531\u001b[0m, in \u001b[0;36mSeries.idxmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2466\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2467\u001b[0m \u001b[38;5;124;03mReturn the row label of the maximum value.\u001b[39;00m\n\u001b[1;32m   2468\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2527\u001b[0m \u001b[38;5;124;03mnan\u001b[39;00m\n\u001b[1;32m   2528\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2529\u001b[0m \u001b[38;5;66;03m# error: Argument 1 to \"argmax\" of \"IndexOpsMixin\" has incompatible type\u001b[39;00m\n\u001b[1;32m   2530\u001b[0m \u001b[38;5;66;03m# \"Union[int, Literal['index', 'columns']]\"; expected \"Optional[int]\"\u001b[39;00m\n\u001b[0;32m-> 2531\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margmax(axis, skipna, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mnan\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/base.py:678\u001b[0m, in \u001b[0;36mIndexOpsMixin.argmax\u001b[0;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m delegate\u001b[38;5;241m.\u001b[39margmax()\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[int, ndarray]\", expected\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;66;03m# \"int\")\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m nanops\u001b[38;5;241m.\u001b[39mnanargmax(  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[1;32m    679\u001b[0m         delegate, skipna\u001b[38;5;241m=\u001b[39mskipna\n\u001b[1;32m    680\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/nanops.py:91\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck(obj) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m obj_iter):\n\u001b[1;32m     90\u001b[0m     f_name \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnan\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreduction operation \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m not allowed for this dtype\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mTypeError\u001b[0m: reduction operation 'argmax' not allowed for this dtype"
     ]
    }
   ],
   "source": [
    "best_model = Grid_Search_Results[['AUC Train', 'AUC Test 1', 'AUC Test 2']].mean(axis=1).idxmax()\n",
    "best_parameters = Grid_Search_Results.iloc[best_model, :5].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "570fb932b429e973",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:52:08.895917Z",
     "start_time": "2024-10-18T00:52:08.890383Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Number of Trees': 300, 'Learning Rate (LR)': 0.1, 'Subsample': 0.8, '% Features': 1.0, 'Weight of Default': 1}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(best_parameters)\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c205be352bed0f16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:53:31.833109Z",
     "start_time": "2024-10-18T00:53:30.729544Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the best model\n",
    "best_xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=int(best_parameters['Number of Trees']),\n",
    "    learning_rate=best_parameters['Learning Rate (LR)'],\n",
    "    subsample=best_parameters['Subsample'],\n",
    "    colsample_bytree=best_parameters['% Features'],\n",
    "    scale_pos_weight=best_parameters['Weight of Default']\n",
    ")\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the best model\n",
    "best_xgb_model.save_model('best_xgb_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d227cbcf9f9893c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T21:32:31.912038Z",
     "start_time": "2024-10-16T21:32:31.864899Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = xgb.XGBClassifier()\n",
    "loaded_model.load_model('output/best_xgb_model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "74ac1ada95b4632b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:35.545739Z",
     "start_time": "2024-10-18T00:56:35.457028Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete iteration: 2\n",
      "complete iteration: 3\n",
      "complete iteration: 4\n",
      "complete iteration: 5\n",
      "complete iteration: 6\n",
      "complete iteration: 7\n",
      "complete iteration: 8\n",
      "complete iteration: 9\n",
      "complete iteration: 10\n",
      "complete iteration: 11\n",
      "complete iteration: 12\n",
      "complete iteration: 13\n",
      "complete iteration: 14\n",
      "complete iteration: 15\n",
      "----Calculation Complete----\n"
     ]
    }
   ],
   "source": [
    "# step 10: Neural Network\n",
    "# Data Preprocessing\n",
    "outliers = pd.DataFrame(columns = ['Feature', 'p1', 'p99'])\n",
    "\n",
    "counter = 1\n",
    "for col in X_train.columns:\n",
    "    p1 = X_train[col].quantile(0.01)\n",
    "    p99 = X_train[col].quantile(0.99)\n",
    "    outliers.loc[counter] = [col, p1, p99]\n",
    "    counter += 1\n",
    "    print('complete iteration:', counter)\n",
    "print('----Calculation Complete----')\n",
    "outliers.to_csv('output/outliers.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d15d4619cf50d87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:46.636841Z",
     "start_time": "2024-10-18T00:56:46.471518Z"
    }
   },
   "outputs": [],
   "source": [
    "# replace outliers with p1 and p99\n",
    "X_train = X_train.clip(lower = X_train.quantile(0.01), upper = X_train.quantile(0.99), axis = 1)\n",
    "X_test1 = X_test1.clip(lower = X_train.quantile(0.01), upper = X_train.quantile(0.99), axis = 1)\n",
    "X_test2 = X_test2.clip(lower = X_train.quantile(0.01), upper = X_train.quantile(0.99), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3385cb34c3db98b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:50.620116Z",
     "start_time": "2024-10-18T00:56:50.570114Z"
    }
   },
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "X_test1_scaled = pd.DataFrame(scaler.transform(X_test1), columns = X_train.columns)\n",
    "X_test2_scaled = pd.DataFrame(scaler.transform(X_test2), columns = X_train.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a8158695979322d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:53.061982Z",
     "start_time": "2024-10-18T00:56:53.056374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in X_train: 55909\n",
      "Number of missing values in X_test1: 11997\n",
      "Number of missing values in X_test2: 11979\n"
     ]
    }
   ],
   "source": [
    "# fill missing values with 0\n",
    "print('Number of missing values in X_train:', X_train_scaled.isnull().sum().sum())\n",
    "print('Number of missing values in X_test1:', X_test1_scaled.isnull().sum().sum())\n",
    "print('Number of missing values in X_test2:', X_test2_scaled.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "697db8a0bdd5182d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:56.688611Z",
     "start_time": "2024-10-18T00:56:56.667659Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled.fillna(0, inplace=True)\n",
    "X_test1_scaled.fillna(0, inplace=True)\n",
    "X_test2_scaled.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "76c5f0cc497c624e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:56:58.792054Z",
     "start_time": "2024-10-18T00:56:58.784821Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values in X_train: 0\n",
      "Number of missing values in X_test1: 0\n",
      "Number of missing values in X_test2: 0\n"
     ]
    }
   ],
   "source": [
    "# Check the number of missing values again\n",
    "print('Number of missing values in X_train:', X_train_scaled.isnull().sum().sum())\n",
    "print('Number of missing values in X_test1:', X_test1_scaled.isnull().sum().sum())\n",
    "print('Number of missing values in X_test2:', X_test2_scaled.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b8abc9b30b75071",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:00.998393Z",
     "start_time": "2024-10-18T00:57:00.983170Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P_2_min_3</th>\n",
       "      <th>B_11_min_3</th>\n",
       "      <th>B_2_sum_6</th>\n",
       "      <th>P_2_sum_3</th>\n",
       "      <th>D_44_max_12</th>\n",
       "      <th>D_42_max_6</th>\n",
       "      <th>B_1_max_3</th>\n",
       "      <th>P_2_mean_3</th>\n",
       "      <th>R_1_mean_3</th>\n",
       "      <th>B_1_min_3</th>\n",
       "      <th>B_1_mean_3</th>\n",
       "      <th>B_2_min_3</th>\n",
       "      <th>B_9_max_3</th>\n",
       "      <th>B_2_sum_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.650809</td>\n",
       "      <td>-0.154200</td>\n",
       "      <td>-1.406933</td>\n",
       "      <td>-0.051839</td>\n",
       "      <td>-0.651831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.225414</td>\n",
       "      <td>-0.100086</td>\n",
       "      <td>-0.410863</td>\n",
       "      <td>-0.070301</td>\n",
       "      <td>-0.150938</td>\n",
       "      <td>-1.172024</td>\n",
       "      <td>0.923663</td>\n",
       "      <td>-1.397350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.655672</td>\n",
       "      <td>1.198938</td>\n",
       "      <td>-0.463044</td>\n",
       "      <td>-0.678755</td>\n",
       "      <td>2.274824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.199052</td>\n",
       "      <td>-0.746734</td>\n",
       "      <td>-0.406592</td>\n",
       "      <td>1.321831</td>\n",
       "      <td>1.238736</td>\n",
       "      <td>-1.214813</td>\n",
       "      <td>-0.767820</td>\n",
       "      <td>-1.346659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.643313</td>\n",
       "      <td>0.374681</td>\n",
       "      <td>-1.468284</td>\n",
       "      <td>-1.620546</td>\n",
       "      <td>4.212030</td>\n",
       "      <td>0.382075</td>\n",
       "      <td>0.290951</td>\n",
       "      <td>-1.718166</td>\n",
       "      <td>1.492090</td>\n",
       "      <td>0.491907</td>\n",
       "      <td>0.393126</td>\n",
       "      <td>-1.216151</td>\n",
       "      <td>1.558677</td>\n",
       "      <td>-1.416897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.124724</td>\n",
       "      <td>-0.502704</td>\n",
       "      <td>0.613785</td>\n",
       "      <td>0.103288</td>\n",
       "      <td>-0.656168</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.625817</td>\n",
       "      <td>0.059923</td>\n",
       "      <td>-0.422977</td>\n",
       "      <td>-0.552944</td>\n",
       "      <td>-0.595677</td>\n",
       "      <td>0.685589</td>\n",
       "      <td>-0.768932</td>\n",
       "      <td>0.584513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.178081</td>\n",
       "      <td>-0.509591</td>\n",
       "      <td>0.778785</td>\n",
       "      <td>-0.216368</td>\n",
       "      <td>-0.652651</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.635297</td>\n",
       "      <td>-0.269794</td>\n",
       "      <td>-0.428528</td>\n",
       "      <td>-0.563172</td>\n",
       "      <td>-0.606298</td>\n",
       "      <td>0.676677</td>\n",
       "      <td>-0.767048</td>\n",
       "      <td>0.904216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64243</th>\n",
       "      <td>0.880030</td>\n",
       "      <td>-0.498854</td>\n",
       "      <td>0.616683</td>\n",
       "      <td>1.018272</td>\n",
       "      <td>-0.654837</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.629035</td>\n",
       "      <td>1.003705</td>\n",
       "      <td>-0.421076</td>\n",
       "      <td>-0.561018</td>\n",
       "      <td>-0.602401</td>\n",
       "      <td>0.681646</td>\n",
       "      <td>-0.772839</td>\n",
       "      <td>0.585047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64244</th>\n",
       "      <td>0.540434</td>\n",
       "      <td>-0.181660</td>\n",
       "      <td>-1.442948</td>\n",
       "      <td>0.527134</td>\n",
       "      <td>0.319988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.228447</td>\n",
       "      <td>0.497109</td>\n",
       "      <td>-0.426669</td>\n",
       "      <td>-0.065095</td>\n",
       "      <td>-0.153812</td>\n",
       "      <td>-1.184948</td>\n",
       "      <td>1.243813</td>\n",
       "      <td>-1.412472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64245</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.499780</td>\n",
       "      <td>0.679887</td>\n",
       "      <td>-2.365119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.531187</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.424694</td>\n",
       "      <td>-0.485862</td>\n",
       "      <td>-0.520850</td>\n",
       "      <td>-1.265988</td>\n",
       "      <td>-0.772327</td>\n",
       "      <td>0.213664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64246</th>\n",
       "      <td>-0.165413</td>\n",
       "      <td>-0.510634</td>\n",
       "      <td>1.125710</td>\n",
       "      <td>-0.145014</td>\n",
       "      <td>-0.651150</td>\n",
       "      <td>-0.789057</td>\n",
       "      <td>-0.628512</td>\n",
       "      <td>-0.196194</td>\n",
       "      <td>-0.418504</td>\n",
       "      <td>-0.539091</td>\n",
       "      <td>-0.592630</td>\n",
       "      <td>1.136758</td>\n",
       "      <td>-0.536272</td>\n",
       "      <td>1.077220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64247</th>\n",
       "      <td>-0.440354</td>\n",
       "      <td>-0.401682</td>\n",
       "      <td>1.116897</td>\n",
       "      <td>-0.395775</td>\n",
       "      <td>-0.163572</td>\n",
       "      <td>1.280082</td>\n",
       "      <td>-0.402105</td>\n",
       "      <td>-0.454847</td>\n",
       "      <td>-0.419193</td>\n",
       "      <td>-0.396674</td>\n",
       "      <td>-0.383008</td>\n",
       "      <td>1.132823</td>\n",
       "      <td>-0.780460</td>\n",
       "      <td>1.065296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64248 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       P_2_min_3  B_11_min_3  B_2_sum_6  P_2_sum_3  D_44_max_12  D_42_max_6  \\\n",
       "0      -0.650809   -0.154200  -1.406933  -0.051839    -0.651831    0.000000   \n",
       "1      -0.655672    1.198938  -0.463044  -0.678755     2.274824    0.000000   \n",
       "2      -1.643313    0.374681  -1.468284  -1.620546     4.212030    0.382075   \n",
       "3       0.124724   -0.502704   0.613785   0.103288    -0.656168    0.000000   \n",
       "4      -0.178081   -0.509591   0.778785  -0.216368    -0.652651    0.000000   \n",
       "...          ...         ...        ...        ...          ...         ...   \n",
       "64243   0.880030   -0.498854   0.616683   1.018272    -0.654837    0.000000   \n",
       "64244   0.540434   -0.181660  -1.442948   0.527134     0.319988    0.000000   \n",
       "64245   0.000000   -0.499780   0.679887  -2.365119     0.000000    0.000000   \n",
       "64246  -0.165413   -0.510634   1.125710  -0.145014    -0.651150   -0.789057   \n",
       "64247  -0.440354   -0.401682   1.116897  -0.395775    -0.163572    1.280082   \n",
       "\n",
       "       B_1_max_3  P_2_mean_3  R_1_mean_3  B_1_min_3  B_1_mean_3  B_2_min_3  \\\n",
       "0      -0.225414   -0.100086   -0.410863  -0.070301   -0.150938  -1.172024   \n",
       "1       1.199052   -0.746734   -0.406592   1.321831    1.238736  -1.214813   \n",
       "2       0.290951   -1.718166    1.492090   0.491907    0.393126  -1.216151   \n",
       "3      -0.625817    0.059923   -0.422977  -0.552944   -0.595677   0.685589   \n",
       "4      -0.635297   -0.269794   -0.428528  -0.563172   -0.606298   0.676677   \n",
       "...          ...         ...         ...        ...         ...        ...   \n",
       "64243  -0.629035    1.003705   -0.421076  -0.561018   -0.602401   0.681646   \n",
       "64244  -0.228447    0.497109   -0.426669  -0.065095   -0.153812  -1.184948   \n",
       "64245  -0.531187    0.000000   -0.424694  -0.485862   -0.520850  -1.265988   \n",
       "64246  -0.628512   -0.196194   -0.418504  -0.539091   -0.592630   1.136758   \n",
       "64247  -0.402105   -0.454847   -0.419193  -0.396674   -0.383008   1.132823   \n",
       "\n",
       "       B_9_max_3  B_2_sum_3  \n",
       "0       0.923663  -1.397350  \n",
       "1      -0.767820  -1.346659  \n",
       "2       1.558677  -1.416897  \n",
       "3      -0.768932   0.584513  \n",
       "4      -0.767048   0.904216  \n",
       "...          ...        ...  \n",
       "64243  -0.772839   0.585047  \n",
       "64244   1.243813  -1.412472  \n",
       "64245  -0.772327   0.213664  \n",
       "64246  -0.536272   1.077220  \n",
       "64247  -0.780460   1.065296  \n",
       "\n",
       "[64248 rows x 14 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d98f9ed1d018d46d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:10.501017Z",
     "start_time": "2024-10-18T00:57:09.258205Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scaled.to_csv('data/X_train_scaled.csv', index=False)\n",
    "X_test1_scaled.to_csv('data/X_test1_scaled.csv', index=False)\n",
    "X_test2_scaled.to_csv('data/X_test2_scaled.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af46397cb15de063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T00:57:19.677779Z",
     "start_time": "2024-10-18T00:57:19.458418Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data for nn\n",
    "X_train_scaled = pd.read_csv('data/X_train_scaled.csv')\n",
    "X_test1_scaled = pd.read_csv('data/X_test1_scaled.csv')\n",
    "X_test2_scaled = pd.read_csv('data/X_test2_scaled.csv')\n",
    "\n",
    "y_train = pd.read_csv('data/y_train.csv')\n",
    "y_test1 = pd.read_csv('data/y_test1.csv')\n",
    "y_test2 = pd.read_csv('data/y_test2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cec5ec5df12581c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:01:31.927291Z",
     "start_time": "2024-10-18T00:57:21.646113Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 429us/step - loss: 0.6801\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.4743\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.3956\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.3524\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - loss: 0.3276\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - loss: 0.3116\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - loss: 0.3033\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.2999\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - loss: 0.2924\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.2877\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 370us/step - loss: 0.2865\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - loss: 0.2829\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - loss: 0.2787\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.2762\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 368us/step - loss: 0.2791\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376us/step - loss: 0.2782\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 0.2775\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.2778\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - loss: 0.2757\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 364us/step - loss: 0.2778\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 295us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7078  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6799 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - loss: 0.6517\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6245 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6034 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5837 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5656 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5467 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5280 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5076 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4882 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4676 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step - loss: 0.4500\n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4320 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4154 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4034 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3900 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3786 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3700 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3600 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 397us/step - loss: 0.6078\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4788\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.4526\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4502\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.4489\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.4474\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 0.4485\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378us/step - loss: 0.4503\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.4486\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4461\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.4477\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4423\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step - loss: 0.4475\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379us/step - loss: 0.4475\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.4441\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.4429\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.4477\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.4467\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.4447\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.4469\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 285us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7674  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7476 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7221 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7029 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6892 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6735 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6597 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6428 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6325 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6169 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6041 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6021 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5897 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5799 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5721 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5628 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5570 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5495 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5400 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5334 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 279us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 366us/step - loss: 0.5600\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 359us/step - loss: 0.3004\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.2898\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 0.2839\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 0.2847\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - loss: 0.2803\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2786\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2780\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2744\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2839\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2758\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.2742\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.2751\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.2761\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 541us/step - loss: 0.2758\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 764us/step - loss: 0.2754\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - loss: 0.2784\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 609us/step - loss: 0.2775\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.2750\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 356us/step - loss: 0.2760\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.8163  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.7813 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - loss: 0.7462\n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 978us/step - loss: 0.7172\n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6879 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6646 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - loss: 0.6391\n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6195 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 986us/step - loss: 0.6032\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 0.5846\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 0.5670\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5569 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5434  \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5314 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5210 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5093 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5007 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4921 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4845 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4781 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 290us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 282us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 419us/step - loss: 0.5577\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.3848\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 0.3754\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.3656\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393us/step - loss: 0.3607\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 0.3601\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 0.3569\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.3557\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 553us/step - loss: 0.3543\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.3592\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 444us/step - loss: 0.3546\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.3529\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.3553\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 0.3544\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 0.3515\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.3589\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 533us/step - loss: 0.3485\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 0.3489\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 0.3539\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 396us/step - loss: 0.3539\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 289us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.7030  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6789 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6585 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6423 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6276 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6158 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6024 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5975 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5888 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5801 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5701 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5647 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5599 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5559 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5472 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5436 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5371 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5333 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5252 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5251 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 294us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 346us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 476us/step - loss: 0.4901\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 0.2869\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 0.2724\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.2749\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.2714\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 0.2752\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.2719\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 369us/step - loss: 0.2734\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.2692\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385us/step - loss: 0.2731\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.2721\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.2691\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 518us/step - loss: 0.2742\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.2728\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 418us/step - loss: 0.2742\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.2720\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.2718\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 422us/step - loss: 0.2712\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.2709\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 460us/step - loss: 0.2709\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6903  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6770 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6606 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6462 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6303 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6150 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6004 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5846 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5693 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5535 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5366 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5158 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4948 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4708 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4525 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4324 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4165 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4012 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3887 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3786 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 284us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 289us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 434us/step - loss: 0.6878\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.4372\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - loss: 0.4020\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.3864\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 503us/step - loss: 0.3779\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 0.3764\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 454us/step - loss: 0.3767\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.3767\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.3725\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.3719\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386us/step - loss: 0.3700\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 389us/step - loss: 0.3735\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.3716\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 429us/step - loss: 0.3708\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.3700\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.3731\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.3737\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 0.3731\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.3723\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 394us/step - loss: 0.3722\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 291us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 278us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 1.0414  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9653 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9006 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8762 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8175 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7862 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7559 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7229 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6905 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6639 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6389 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6222 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6041 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5815 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5738 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5607 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5529 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5468 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5389 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5284 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 287us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step - loss: 0.4806\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 415us/step - loss: 0.2903\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 375us/step - loss: 0.2804\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 361us/step - loss: 0.2794\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 362us/step - loss: 0.2807\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 358us/step - loss: 0.2783\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2751\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 372us/step - loss: 0.2776\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.2761\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367us/step - loss: 0.2764\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384us/step - loss: 0.2773\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382us/step - loss: 0.2721\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366us/step - loss: 0.2751\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 371us/step - loss: 0.2695\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388us/step - loss: 0.2718\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380us/step - loss: 0.2705\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383us/step - loss: 0.2726\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 374us/step - loss: 0.2690\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 438us/step - loss: 0.2730\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - loss: 0.2754\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 343us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 283us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8841  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8161 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7554 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7032 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6577 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6194 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5839 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5536 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5254 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5006 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4791 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4607 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4446 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4303 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4170 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4052 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3973 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3880 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3800 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.3726 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 286us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 431us/step - loss: 0.5922\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.3711\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.3496\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486us/step - loss: 0.3405\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 452us/step - loss: 0.3365\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.3365\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.3326\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.3347\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 0.3361\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 423us/step - loss: 0.3335\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 439us/step - loss: 0.3316\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - loss: 0.3275\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 432us/step - loss: 0.3278\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.3331\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.3235\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.3248\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 463us/step - loss: 0.3267\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 0.3213\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 449us/step - loss: 0.3328\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.3260\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 293us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 281us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8438  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8054 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7671 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7332 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6990 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6750 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6517 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6322 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6142 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5973 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5824 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5672 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5553 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5457 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5365 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5263 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5185 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5091 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5021 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4944 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 321us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 560us/step - loss: 0.4363\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - loss: 0.2815\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - loss: 0.2818\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 0.2773\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500us/step - loss: 0.2738\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step - loss: 0.2757\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 634us/step - loss: 0.2746\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.2714\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.2712\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 425us/step - loss: 0.2699\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.2727\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428us/step - loss: 0.2743\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 446us/step - loss: 0.2760\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599us/step - loss: 0.2745\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - loss: 0.2729\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 0.2718\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - loss: 0.2753\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 747us/step - loss: 0.2745\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - loss: 0.2743\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.2725\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 519us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 508us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 519us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.6952  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6886 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6821 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6764 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6697 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6624 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6521 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6377 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6164 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5935 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5715 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5480 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5257 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5063 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4874 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4733 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4573 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4430 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4324 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.4231 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 491us/step - loss: 0.9752\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 472us/step - loss: 0.5830\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480us/step - loss: 0.5566\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 0.5275\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 566us/step - loss: 0.5150\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483us/step - loss: 0.5099\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - loss: 0.5067\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.5009\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.4996\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 0.5027\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.4980\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 517us/step - loss: 0.4990\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 0.4991\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 790us/step - loss: 0.4996\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.4989\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4961\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 835us/step - loss: 0.4950\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 610us/step - loss: 0.4922\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.4955\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.4951\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 410us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 302us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.8164\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7951 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7813 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7554 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7432 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7209 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7132 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6997 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6926 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6805 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6714 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6681 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6577 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6519 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6491 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6384 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6356 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6323 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6270 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6204 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 435us/step - loss: 0.4668\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399us/step - loss: 0.2940\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step - loss: 0.2889\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2800\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.2787\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.2786\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 402us/step - loss: 0.2772\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 0.2778\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2772\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2738\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 397us/step - loss: 0.2725\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 466us/step - loss: 0.2749\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - loss: 0.2737\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 459us/step - loss: 0.2751\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2756\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 424us/step - loss: 0.2765\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 0.2717\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 734us/step - loss: 0.2746\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 893us/step - loss: 0.2733\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 911us/step - loss: 0.2741\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 495us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 305us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.6928\n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6567 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6240 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5952 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5699 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5484 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5281 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5104 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4930\n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.4756\n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.4598\n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4450\n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.4324 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.4175 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.4051 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3954 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.3852 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3764 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.3667 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.3586 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 373us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 400us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 622us/step - loss: 0.6524\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - loss: 0.4799\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 554us/step - loss: 0.4409\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 549us/step - loss: 0.4211\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 511us/step - loss: 0.4092\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 605us/step - loss: 0.4056\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3980\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.4040\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3943\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 563us/step - loss: 0.3966\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 560us/step - loss: 0.3985\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 471us/step - loss: 0.3956\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 469us/step - loss: 0.3996\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 468us/step - loss: 0.3905\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 521us/step - loss: 0.3979\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 504us/step - loss: 0.3965\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.3975\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 513us/step - loss: 0.3922\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.3939\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.3933\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 306us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7448  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7253 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.7062 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6880 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6762 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6633 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6526 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6402 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6300 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6224 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6137 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6064 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6015 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5948 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5867 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5844 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5750 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5722 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5678 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5658 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 299us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 288us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 424us/step - loss: 0.4429\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2798\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2800\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.2761\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412us/step - loss: 0.2729\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 0.2728\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405us/step - loss: 0.2736\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2756\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.2733\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 411us/step - loss: 0.2715\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.2721\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 414us/step - loss: 0.2690\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.2720\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 409us/step - loss: 0.2729\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 410us/step - loss: 0.2731\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.2694\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.2730\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2694\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 407us/step - loss: 0.2720\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408us/step - loss: 0.2706\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 297us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.7178  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6960 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6789 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6633 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6447 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6276 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6086 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5885 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5670 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5440 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5219 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4992 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4776 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4576 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4376 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4190 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3996 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3834 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3697 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3582 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 303us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504us/step - loss: 0.6479\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 0.5262\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498us/step - loss: 0.5009\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487us/step - loss: 0.4762\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 0.4677\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.4529\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 0.4447\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 0.4442\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 0.4426\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496us/step - loss: 0.4414\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 509us/step - loss: 0.4378\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 0.4409\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 491us/step - loss: 0.4445\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.4398\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - loss: 0.4418\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 0.4447\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495us/step - loss: 0.4394\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497us/step - loss: 0.4350\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 505us/step - loss: 0.4446\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494us/step - loss: 0.4411\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 296us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7292  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7177 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7032 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6962 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6906 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6862 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6824 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6772 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6749 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6704 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6661 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6634 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.6605 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6575 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6541 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6500 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6471 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6442 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6400 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6368 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 641us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 552us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 343us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 464us/step - loss: 0.4869\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 524us/step - loss: 0.2944\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488us/step - loss: 0.2804\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 458us/step - loss: 0.2812\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 456us/step - loss: 0.2802\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442us/step - loss: 0.2796\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2758\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 416us/step - loss: 0.2779\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419us/step - loss: 0.2778\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 437us/step - loss: 0.2750\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403us/step - loss: 0.2747\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 401us/step - loss: 0.2756\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 426us/step - loss: 0.2726\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 430us/step - loss: 0.2768\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 421us/step - loss: 0.2737\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 406us/step - loss: 0.2710\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.2728\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 417us/step - loss: 0.2722\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 413us/step - loss: 0.2739\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 420us/step - loss: 0.2749\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 305us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 294us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 293us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.6614  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6186 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5792 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5428 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5088 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4770 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4488 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4245 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4010 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3831 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3683 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3561 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3462 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3363 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3295 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.3242 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3179 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3146 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3156 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.3079 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 300us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 291us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 505us/step - loss: 0.5926\n",
      "Epoch 2/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.4105\n",
      "Epoch 3/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.3864\n",
      "Epoch 4/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475us/step - loss: 0.3717\n",
      "Epoch 5/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3654\n",
      "Epoch 6/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474us/step - loss: 0.3627\n",
      "Epoch 7/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492us/step - loss: 0.3563\n",
      "Epoch 8/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499us/step - loss: 0.3559\n",
      "Epoch 9/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.3562\n",
      "Epoch 10/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.3570\n",
      "Epoch 11/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3520\n",
      "Epoch 12/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479us/step - loss: 0.3538\n",
      "Epoch 13/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478us/step - loss: 0.3583\n",
      "Epoch 14/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489us/step - loss: 0.3543\n",
      "Epoch 15/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484us/step - loss: 0.3515\n",
      "Epoch 16/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.3567\n",
      "Epoch 17/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477us/step - loss: 0.3553\n",
      "Epoch 18/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476us/step - loss: 0.3518\n",
      "Epoch 19/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493us/step - loss: 0.3533\n",
      "Epoch 20/20\n",
      "\u001b[1m643/643\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 41ms/step - loss: 0.3492\n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 361us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 295us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286us/step\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/itoshi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.7489  \n",
      "Epoch 2/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.7221 \n",
      "Epoch 3/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6969 \n",
      "Epoch 4/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6735 \n",
      "Epoch 5/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6570 \n",
      "Epoch 6/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.6429 \n",
      "Epoch 7/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6297 \n",
      "Epoch 8/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6225 \n",
      "Epoch 9/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6115 \n",
      "Epoch 10/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.6026 \n",
      "Epoch 11/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5936 \n",
      "Epoch 12/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5849 \n",
      "Epoch 13/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5785 \n",
      "Epoch 14/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5688 \n",
      "Epoch 15/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5603 \n",
      "Epoch 16/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5564 \n",
      "Epoch 17/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5478 \n",
      "Epoch 18/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5412 \n",
      "Epoch 19/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5382 \n",
      "Epoch 20/20\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.5319 \n",
      "\u001b[1m2008/2008\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 299us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 292us/step\n",
      "\u001b[1m431/431\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290us/step\n",
      "Grid search completed\n"
     ]
    }
   ],
   "source": [
    "# build neural network\n",
    "nn_grid_search_result = pd.DataFrame(columns = [\"#HL\", \"#Nodes\", \"ActivationFunction\", \"Dropout\", \"BatchSize\", \"AUC_Train\", \"AUC_Test1\", \"AUC_Test2\"])\n",
    "\n",
    "Counter = 0\n",
    "for hl in [2,4]:\n",
    "    for nodes in [4,6]:\n",
    "        for activate_function in [\"relu\", \"tanh\"]:\n",
    "            for dropout in [0, 0.5]:\n",
    "                for batch_size in [100, 10000]:\n",
    "                    model = Sequential()\n",
    "                    model.add(Dense(nodes, input_dim=X_train_scaled.shape[1], activation=activate_function))\n",
    "                    model.add(Dropout(dropout))\n",
    "                    for i in range(hl - 1):\n",
    "                        model.add(Dense(nodes, activation=activate_function))\n",
    "                        model.add(Dropout(dropout))\n",
    "                    model.add(Dense(1, activation='sigmoid'))\n",
    "                    model.compile(optimizer=Adam(), loss=BinaryCrossentropy())\n",
    "                    model.fit(X_train_scaled, y_train, batch_size=batch_size, epochs=20)\n",
    "                    \n",
    "                    nn_grid_search_result.loc[Counter, \"#HL\"] = hl\n",
    "                    nn_grid_search_result.loc[Counter, \"#Nodes\"] = nodes\n",
    "                    nn_grid_search_result.loc[Counter, \"ActivationFunction\"] = activate_function\n",
    "                    nn_grid_search_result.loc[Counter, \"Dropout\"] = dropout\n",
    "                    nn_grid_search_result.loc[Counter, \"BatchSize\"] = batch_size\n",
    "                    nn_grid_search_result.loc[Counter, \"AUC_Train\"] = roc_auc_score(y_train, model.predict(X_train_scaled))\n",
    "                    nn_grid_search_result.loc[Counter, \"AUC_Test1\"] = roc_auc_score(y_test1, model.predict(X_test1_scaled))\n",
    "                    nn_grid_search_result.loc[Counter, \"AUC_Test2\"] = roc_auc_score(y_test2, model.predict(X_test2_scaled))\n",
    "                    \n",
    "                    Counter += 1\n",
    "\n",
    "print('Grid search completed')\n",
    "nn_grid_search_result.to_csv('output/nn_grid_search_result.csv')\n",
    "                    \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f4d29b363d2337fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T01:03:43.805810Z",
     "start_time": "2024-10-18T01:03:43.766677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#HL</th>\n",
       "      <th>#Nodes</th>\n",
       "      <th>ActivationFunction</th>\n",
       "      <th>Dropout</th>\n",
       "      <th>BatchSize</th>\n",
       "      <th>AUC_Train</th>\n",
       "      <th>AUC_Test1</th>\n",
       "      <th>AUC_Test2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.937706</td>\n",
       "      <td>0.940149</td>\n",
       "      <td>0.936429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.927040</td>\n",
       "      <td>0.930282</td>\n",
       "      <td>0.925276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936715</td>\n",
       "      <td>0.939418</td>\n",
       "      <td>0.935537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.895927</td>\n",
       "      <td>0.901307</td>\n",
       "      <td>0.895857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936607</td>\n",
       "      <td>0.939496</td>\n",
       "      <td>0.936229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.823929</td>\n",
       "      <td>0.832054</td>\n",
       "      <td>0.819274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936339</td>\n",
       "      <td>0.938840</td>\n",
       "      <td>0.935383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.913145</td>\n",
       "      <td>0.917832</td>\n",
       "      <td>0.912122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.938592</td>\n",
       "      <td>0.940596</td>\n",
       "      <td>0.937435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.931316</td>\n",
       "      <td>0.934847</td>\n",
       "      <td>0.930024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936274</td>\n",
       "      <td>0.938666</td>\n",
       "      <td>0.935157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.882195</td>\n",
       "      <td>0.885170</td>\n",
       "      <td>0.878113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.938300</td>\n",
       "      <td>0.940406</td>\n",
       "      <td>0.937342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.917121</td>\n",
       "      <td>0.920719</td>\n",
       "      <td>0.914666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936164</td>\n",
       "      <td>0.938762</td>\n",
       "      <td>0.935328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.919970</td>\n",
       "      <td>0.921241</td>\n",
       "      <td>0.918030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.937773</td>\n",
       "      <td>0.940074</td>\n",
       "      <td>0.936396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.890957</td>\n",
       "      <td>0.893709</td>\n",
       "      <td>0.890111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936164</td>\n",
       "      <td>0.938984</td>\n",
       "      <td>0.935104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.845415</td>\n",
       "      <td>0.839998</td>\n",
       "      <td>0.841000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.937928</td>\n",
       "      <td>0.940324</td>\n",
       "      <td>0.936587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.925128</td>\n",
       "      <td>0.929282</td>\n",
       "      <td>0.924158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.935846</td>\n",
       "      <td>0.938413</td>\n",
       "      <td>0.935081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.902848</td>\n",
       "      <td>0.905326</td>\n",
       "      <td>0.901235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.938529</td>\n",
       "      <td>0.940395</td>\n",
       "      <td>0.936909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.927956</td>\n",
       "      <td>0.930908</td>\n",
       "      <td>0.926392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936045</td>\n",
       "      <td>0.938583</td>\n",
       "      <td>0.934832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>relu</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.854660</td>\n",
       "      <td>0.865046</td>\n",
       "      <td>0.848798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.938408</td>\n",
       "      <td>0.940861</td>\n",
       "      <td>0.937142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.932010</td>\n",
       "      <td>0.933934</td>\n",
       "      <td>0.929548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>100</td>\n",
       "      <td>0.936299</td>\n",
       "      <td>0.938954</td>\n",
       "      <td>0.935355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>tanh</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10000</td>\n",
       "      <td>0.910234</td>\n",
       "      <td>0.913566</td>\n",
       "      <td>0.906873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    #HL  #Nodes ActivationFunction  Dropout  BatchSize  AUC_Train  AUC_Test1  \\\n",
       "0     2       4               relu      0.0        100   0.937706   0.940149   \n",
       "1     2       4               relu      0.0      10000   0.927040   0.930282   \n",
       "2     2       4               relu      0.5        100   0.936715   0.939418   \n",
       "3     2       4               relu      0.5      10000   0.895927   0.901307   \n",
       "4     2       4               tanh      0.0        100   0.936607   0.939496   \n",
       "5     2       4               tanh      0.0      10000   0.823929   0.832054   \n",
       "6     2       4               tanh      0.5        100   0.936339   0.938840   \n",
       "7     2       4               tanh      0.5      10000   0.913145   0.917832   \n",
       "8     2       6               relu      0.0        100   0.938592   0.940596   \n",
       "9     2       6               relu      0.0      10000   0.931316   0.934847   \n",
       "10    2       6               relu      0.5        100   0.936274   0.938666   \n",
       "11    2       6               relu      0.5      10000   0.882195   0.885170   \n",
       "12    2       6               tanh      0.0        100   0.938300   0.940406   \n",
       "13    2       6               tanh      0.0      10000   0.917121   0.920719   \n",
       "14    2       6               tanh      0.5        100   0.936164   0.938762   \n",
       "15    2       6               tanh      0.5      10000   0.919970   0.921241   \n",
       "16    4       4               relu      0.0        100   0.937773   0.940074   \n",
       "17    4       4               relu      0.0      10000   0.890957   0.893709   \n",
       "18    4       4               relu      0.5        100   0.936164   0.938984   \n",
       "19    4       4               relu      0.5      10000   0.845415   0.839998   \n",
       "20    4       4               tanh      0.0        100   0.937928   0.940324   \n",
       "21    4       4               tanh      0.0      10000   0.925128   0.929282   \n",
       "22    4       4               tanh      0.5        100   0.935846   0.938413   \n",
       "23    4       4               tanh      0.5      10000   0.902848   0.905326   \n",
       "24    4       6               relu      0.0        100   0.938529   0.940395   \n",
       "25    4       6               relu      0.0      10000   0.927956   0.930908   \n",
       "26    4       6               relu      0.5        100   0.936045   0.938583   \n",
       "27    4       6               relu      0.5      10000   0.854660   0.865046   \n",
       "28    4       6               tanh      0.0        100   0.938408   0.940861   \n",
       "29    4       6               tanh      0.0      10000   0.932010   0.933934   \n",
       "30    4       6               tanh      0.5        100   0.936299   0.938954   \n",
       "31    4       6               tanh      0.5      10000   0.910234   0.913566   \n",
       "\n",
       "    AUC_Test2  \n",
       "0    0.936429  \n",
       "1    0.925276  \n",
       "2    0.935537  \n",
       "3    0.895857  \n",
       "4    0.936229  \n",
       "5    0.819274  \n",
       "6    0.935383  \n",
       "7    0.912122  \n",
       "8    0.937435  \n",
       "9    0.930024  \n",
       "10   0.935157  \n",
       "11   0.878113  \n",
       "12   0.937342  \n",
       "13   0.914666  \n",
       "14   0.935328  \n",
       "15   0.918030  \n",
       "16   0.936396  \n",
       "17   0.890111  \n",
       "18   0.935104  \n",
       "19   0.841000  \n",
       "20   0.936587  \n",
       "21   0.924158  \n",
       "22   0.935081  \n",
       "23   0.901235  \n",
       "24   0.936909  \n",
       "25   0.926392  \n",
       "26   0.934832  \n",
       "27   0.848798  \n",
       "28   0.937142  \n",
       "29   0.929548  \n",
       "30   0.935355  \n",
       "31   0.906873  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_grid_search_result = pd.read_csv('output/nn_grid_search_result.csv', index_col=0)\n",
    "nn_grid_search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aece1659b726ff7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
